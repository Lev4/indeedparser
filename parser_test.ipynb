{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import iparser\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import pickle\n",
    "import spacy\n",
    "import tqdm\n",
    "import utils \n",
    "from spacy.lang.en import English\n",
    "from spacy.matcher import Matcher\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Топ профессий:\n",
    "\n",
    " \n",
    "\n",
    "* Java разработчик/Software engineer\n",
    "* Front-end разработчик/Web разработчик\n",
    "* Продуктовый дизайнер\n",
    "* Системный аналитик\n",
    "* Архитектор систем\n",
    "* Agile coach (под вопросом?)\n",
    "* Data Scientist\n",
    "* Data engineer\n",
    "* Бизнес-аналитик\n",
    "* Финансовый аналитик\n",
    "* Кредитный аналитик\n",
    "* Юрист (корпоративный, судебный)\n",
    "* Маркетолог\n",
    " \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Используемый Подход \n",
    "* Парсер с определенной периодичностью запускается и соберает вакансии в базу\n",
    "* Для анализа данные выгружаются из базы в датафрейм \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(iparser)\n",
    "importlib.reload(utils)\n",
    "pdict = utils.patterns_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacancy_db = \"vacancies.sqlite3\"\n",
    "import db_handler \n",
    "importlib.reload(db_handler)\n",
    "db = db_handler.Db_handler(vacancy_db)\n",
    "db.create_tab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for vaca in v.vacancies:\n",
    "#     db.addvacancy(vaca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_ids = [x[0] for x in db.show_vacancy_ids()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['vacancy_id','description','profession','country','city','reqs','skills','date']\n",
    "vtab = pd.DataFrame(db.show_vacancies(), columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49845, 8)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vtab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vacancy_id</th>\n",
       "      <th>description</th>\n",
       "      <th>profession</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>reqs</th>\n",
       "      <th>skills</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/rc/clk?jk=8fb6adb20e0cc7c0&amp;fccid=fe2d21eef233...</td>\n",
       "      <td>7+ years of relevant engineering experience3+ ...</td>\n",
       "      <td>Agile+coach</td>\n",
       "      <td>us</td>\n",
       "      <td>New+York</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>05-06-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/rc/clk?jk=66526d69241caf2c&amp;fccid=48638adc9594...</td>\n",
       "      <td>Innovation, collaboration, and success: at OnD...</td>\n",
       "      <td>Agile+coach</td>\n",
       "      <td>us</td>\n",
       "      <td>New+York</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>05-06-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/rc/clk?jk=9d8e229307c5f80e&amp;fccid=ec00141efcac...</td>\n",
       "      <td>At the NBA, we’re passionate about growing and...</td>\n",
       "      <td>Agile+coach</td>\n",
       "      <td>us</td>\n",
       "      <td>New+York</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>05-06-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/rc/clk?jk=42f82312c8e47d82&amp;fccid=319b94ac5d94...</td>\n",
       "      <td>CLEAR's mission is to strengthen security and ...</td>\n",
       "      <td>Agile+coach</td>\n",
       "      <td>us</td>\n",
       "      <td>New+York</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>05-06-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/rc/clk?jk=437873289bb297a9&amp;fccid=8009d67e7070...</td>\n",
       "      <td>Agile Coach Rock Star - hiring globally - (SO0...</td>\n",
       "      <td>Agile+coach</td>\n",
       "      <td>us</td>\n",
       "      <td>New+York</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>05-06-2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          vacancy_id  \\\n",
       "0  /rc/clk?jk=8fb6adb20e0cc7c0&fccid=fe2d21eef233...   \n",
       "1  /rc/clk?jk=66526d69241caf2c&fccid=48638adc9594...   \n",
       "2  /rc/clk?jk=9d8e229307c5f80e&fccid=ec00141efcac...   \n",
       "3  /rc/clk?jk=42f82312c8e47d82&fccid=319b94ac5d94...   \n",
       "4  /rc/clk?jk=437873289bb297a9&fccid=8009d67e7070...   \n",
       "\n",
       "                                         description   profession country  \\\n",
       "0  7+ years of relevant engineering experience3+ ...  Agile+coach      us   \n",
       "1  Innovation, collaboration, and success: at OnD...  Agile+coach      us   \n",
       "2  At the NBA, we’re passionate about growing and...  Agile+coach      us   \n",
       "3  CLEAR's mission is to strengthen security and ...  Agile+coach      us   \n",
       "4  Agile Coach Rock Star - hiring globally - (SO0...  Agile+coach      us   \n",
       "\n",
       "       city reqs skills        date  \n",
       "0  New+York              05-06-2020  \n",
       "1  New+York              05-06-2020  \n",
       "2  New+York              05-06-2020  \n",
       "3  New+York              05-06-2020  \n",
       "4  New+York              05-06-2020  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vtab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Agile+coach', 'Java+Developer', 'Software+engineer',\n",
       "       'Web+Developer', 'Front-end+Developer', 'Product+Designer',\n",
       "       'System+analyst', 'System+architect', 'Data+Scientist',\n",
       "       'Data+engineer', 'Business-analyst', 'Financial+analyst',\n",
       "       'Credit+analyst', 'Corporate+lawyer', 'Judicial+Lawyer',\n",
       "       'Marketing+Manager', 'Marketing+Specialist'], dtype=object)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vtab.profession.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Dallas', 'Edinburgh', 'Texas', 'New+York', 'London', 'California'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vtab[vtab.profession == 'Data+Scientist'].city.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1833"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vtab[vtab.profession == 'Data+Scientist'].vacancy_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profession</th>\n",
       "      <th>city</th>\n",
       "      <th>vacancy_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data+Scientist</td>\n",
       "      <td>California</td>\n",
       "      <td>802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data+Scientist</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data+Scientist</td>\n",
       "      <td>Edinburgh</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data+Scientist</td>\n",
       "      <td>London</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data+Scientist</td>\n",
       "      <td>New+York</td>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data+Scientist</td>\n",
       "      <td>Texas</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       profession        city  vacancy_id\n",
       "0  Data+Scientist  California         802\n",
       "1  Data+Scientist      Dallas          91\n",
       "2  Data+Scientist   Edinburgh          18\n",
       "3  Data+Scientist      London         307\n",
       "4  Data+Scientist    New+York         416\n",
       "5  Data+Scientist       Texas         199"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vtab[vtab.profession == 'Data+Scientist'].groupby(['profession','city'])['vacancy_id'].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacs_desc = vtab[vtab.profession == 'Data+Scientist']['description'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Analyst I, Statistical (226 Days) -(20191119-019)\n",
       "\n",
       "Description\n",
       "\n",
       "Position Purpose:\n",
       "The position’s main purpose is the development, production, and testing of Dallas ISD’s teacher and principal evaluation metrics, which includes the district’s value-added model. The main functions are statistical research, statistical computing, and documentation. Additional requirements include contributions to the production of E&A publications such as Campus Data Packets and School Profiles and the preliminary calculation of schools’ annual Texas state accountability statistics.\n",
       "\n",
       "Basic Functions:\n",
       "Develop value-added models, or revisions to existing models, for the purpose of evaluating the effectiveness of teacher performance\n",
       "Perform extensive statistical computing using SPSS, SAS, Microsoft Access, and VBA\n",
       "Develop and complete quality control procedures\n",
       "Create, modify, and debug statistical computing programs in various languages/platforms\n",
       "Create and maintain detailed documentation of processes and computer programs\n",
       "Create reports in the form of executive summaries and technical documentation\n",
       "Maintain expert-level status regarding state accountability rules and calculations\n",
       "Create research plans and conduct research (informational and statistical), specifically regarding value-added models in education\n",
       "Maintain organized files and documentation for historical archives and investigations\n",
       "Proactively report progress on assigned tasks\n",
       "Estimate work effort, identify task dependencies and determine optimal solutions\n",
       "Stay abreast of research and applications related to teacher and school evaluations, including but not limited to the application of value-added models in education\n",
       "Perform any additional duties assigned by supervisor\n",
       "\n",
       "Qualifications\n",
       "\n",
       "Bachelors degree from an accredited university; Master’s degree, Ph.D. strongly preferred with a major in statistics, applied mathematics, or educational research/evaluation given preference\n",
       "Majors in psychometrics and the social sciences also considered, pending course work review\n",
       "Two years’ experience related to position’s major responsibilities, specifically requiring:\n",
       "Experience manipulating data and conducting rigorous analyses in a statistical computing language or software such as SPSS, SAS, R, or S (Excel experience is not sufficient)\n",
       "Experience writing code or scripts in a computing language such as C, C++, Java, Python, or Visual Basic for Applications (can be course-based experience)\n",
       "Fluency in SQL and experience with JDBC, PL/SQL, and SQL scripts preferred (can be course-based experience)\n",
       "Ability to create reports in Microsoft Access or Crystal Reports preferred\n",
       "Demonstrated ability to create and maintain detailed technical implementation documentation\n",
       "Exemplary writing and editing skills\n",
       "Exemplary strategic and operational planning skills\n",
       "Ability to work quickly and efficiently and to adapt when deadlines and priorities change\n",
       "\n",
       "Work Locations: Office Of Institutional Research (Oir) 2909 N BUCKNER BLVD 2909 N BUCKNER BLVD Dallas 75228\n",
       "Job: Analyst\n",
       " Full-time\n",
       "Minimum Salary: 61,727.00\n",
       "Job Posting: Nov 19, 2019"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = English()\n",
    "\n",
    "s = vacs_desc[0]\n",
    "doc = nlp(s)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1863484ad2a44429402c8fa93adda46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1833.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "reqs = []\n",
    "for s in tqdm.notebook.tqdm(vacs_desc):\n",
    "    doc = nlp(s)\n",
    "    res = requirements_extractor(doc)\n",
    "    if res:\n",
    "        if len(res) > 4:\n",
    "#             print(\"_\"*10)\n",
    "#             print(res)\n",
    "#             print(len(res))\n",
    "            reqs.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "494"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[requirements include contributions to the production of E&A publications such as Campus Data Packets and School Profiles and the preliminary calculation of schools’ annual Texas state accountability statistics.\n",
       " ,\n",
       " requirement. • Worked with different lines of business in consumer banking like mortgage, credit cards, loans and ready credit. • Preparing Business Requirement Document/Functional Requirements documents/Minor Development Documents (MDD) • Preparing the data enrichment rules • working with SMEs to get the sign offs for the changes • Data quality checks on feeds received • Good working knowledge in SQL, Data Analysis, Feed Analysis, Data Mapping, Data Reconciliation • Responsible for mapping the attributes required for Optima Retail Reporting with the country specific attributes for the regulatory reports such as CCAR14Q/FDIC/BASEL. • Working with business users across countries and products on the map-gap analysis performed to document the gaps. • Hands on experience in data analysis, data validation, data profiling and data reconciliation. • Responsible for data profiling, data reconciliation, full report validation, production parallel stages validations and UAT testing of the engagement. • Responsible for enhancements and to explain the same to technology team assist UAT testing and provide business approval on resolution. • Liaison with technical teams to resolve business related queries. • co-ordinate with offshore for completing day to day deliverables.\n",
       " ,\n",
       " ideal candidate will have 5+ years of internal or external consulting data engineering experience, specifically in developing and structuring data for use in analysis pipelines. During this time, they will have demonstrated concrete evidence of success across the following 5 categories key to the success of their role.\n",
       " ,\n",
       " qualification, bringing established sales methods to the sales process\n",
       " o Develop organized and differentiated go to market activities\n",
       " o Develop overview materials to support initial meetings/conversations\n",
       " o Lead preparations for formal sales meetings and orals for qualified opportunities\n",
       " o Provide support to core accounts without CREs as needed for critical AI I&E opportunities\n",
       " o Identify opportunities (sole source/up for bid) and bring it to the business (functional) partners, evaluate opportunity alignment with client strategy\n",
       " o Identify and align appropriate firm resources to pursue, win, and manage opportunities\n",
       " o Lead pursuit process, RFP responses, etc.\n",
       " o Develop proposals, SOW, etc.\n",
       " o Contribute to pursuit processes by leveraging relationships for insights and influence, including determining “win” themes, aligning messaging with client needs, supporting proposal/orals materials preparation, and participating in the orals session as appropriate\n",
       " o Support pre-sales efforts leveraging depth of product knowledge / product demonstrations tailored to client environment\n",
       "  Industry Expansion and Relationship Building\n",
       " o Collaborate AI I&E Alliance, Marketing and practice leads on messaging, events and eminence - both internal and external\n",
       " o Identify ways the AI I&E practice can expand/enhance visibility at key events and in the market\n",
       " o Participate in key industry events to build relationships and develop business opportunities\n",
       " o Identify key relationships across the industry which would benefit the AI I&E practice and develop plans to cultivate those relationships\n",
       " o Utilize Deloitte eminence - including thoughtware, events, trainings, conferences, and memberships – to build and enhance relationships\n",
       " o Utilize available offerings to develop and participate in activities and events focused on shared values and mission, e.g., Deloitte Greenhouse events, Client Experience labs etc.\n",
       "  Market offering Support\n",
       " o Support AI I&E market offering leadership in developing account and practice plans during the annual planning process\n",
       " o Participate in AI I&E market offering leadership calls and in person meetings, and assist with planning and preparation as needed\n",
       " \n",
       " ,\n",
       " requirements, then translating those requirements into actionable project initiatives with associated metrics.\n",
       " Play a key liaison and coordinator between the business, product, technology, senior management, vendor teams and other members of the change programs\n",
       " ,\n",
       " requirements of 41 CFR 60-1.4(a), 60-300.5(a) and 60-741.5(a). These regulations prohibit discrimination against qualified individuals based on their status as protected veterans or individuals with disabilities, and prohibit discrimination against all individuals based on their race, color, religion, sex, gender identity, sexual orientation or national origin. Moreover, these regulations require that covered prime contractors and subcontractors take affirmative action to employ and advance in employment individuals without regard to race, color, religion, sex, gender identity, sexual orientation national origin, protected veteran status or disability. Thompson Gray, Inc. welcomes minority and veteran applicants.\n",
       " RPA Analyst\n",
       " ,\n",
       " Requirements:\n",
       " Education/Certifications\n",
       " \n",
       " ,\n",
       " Basic Qualifications:\n",
       " Master’s degree in AI/Computer Vision areas\n",
       " 4+ years of hands-on experience with OpenCV, SOD or an equivalent computer vision library\n",
       " 3+ years of experience in software engineering\n",
       " 3+ years of industrial experience with at least one of the following languages: Python, C++, Java\n",
       " Familiar with at least one machine learning framework: TensorFlow, Keras, Caffe, etc.\n",
       " Strong knowledge of advanced mathematics, image/video processing, computer vision, and AI/machine learning theories\n",
       " ,\n",
       " ideal candidate will have broad experience designing and implementing natural language understanding systems across a range of textual data. You have built operational systems in text processing application areas such as entity recognition, sentiment analysis, terminology detection, information extraction, reference resolution, discourse segmentation, summarization, word sense disambiguation, search, categorization, or others. You have a working knowledge of tools that range from regular expressions to modern natural language processing and machine learning frameworks, and experience applying them to a diversity of text data types, including e-mail, chat, or enterprise documents. You are comfortable mentoring, leading, and delegating to other developers.\n",
       " ,\n",
       " requirements to build complex predictive modelsDevelop Machine Learning pipelinesResearch and experiment with emerging ML and Big Data technologies and toolsAnalyze highly complex business requirements, design and write technical specifications to design or redesign complex applicationsResearch and development for data-driven analysis on structured and unstructured dataCollaborate with other technology teams and architects to define and develop solutions.Translate complex functional and technical requirements into detailed technical designTest prototypes and oversee handover to operational teamsPropose best practices/standards\n",
       " The successful candidate for the position will likely have the following skills and experience:Hands-on development experience developing Machine Learning solutions on large datasetsFluent in Machine Learning techniques: Regression, Trees, Clustering, Neural Networks, Anomaly DetectionFluent in Python, Scala, SQLFluent in TensorFlow, Keras, NLP librariesStrong background in working in a data driven environment and supporting fast paced agile developmentStrong technical background working in a Big Data ecosystem and ability to do data analysis, data engineering, ML design and developmentBe willing to learn and be flexible to changing technologyExperience creating best practices and standards around ML model deployment framework and socializing them with the community to ensure successful delivery of the models\n",
       " ,\n",
       " requirements into technical specifications.\n",
       " Coordinate with BI developers on data modeling and report/dashboard development.\n",
       " Utilize data visualization techniques in the design of BI reporting and dashboards.\n",
       " Work with subject matter experts on BI requirements and user testing.\n",
       " Oversee the design and deployment of the data warehouse/data lake.\n",
       " Make recommendations on the best value propositions for artificial intelligence.\n",
       " Advise and assist on best practices for data security and Segregation of Duties.\n",
       " Make recommendations on database management, i.e. indexing, etc.\n",
       " Assist with back-up documentation and audit requirements.\n",
       " Assist with IT data change management procedures and audit for ERP and PLM.\n",
       " Assist with annual restore and recovery tests.\n",
       " Assist with data-related compliance requirements, such as PCI and GDPR.\n",
       " Assist with data-related IT policy development, including data privacy policy.\n",
       " Develop and update project documentation.\n",
       " ,\n",
       " requirements. You will also be working with AI vendors to ensure vendor AI models pass Wells Fargo model risk policies and requirements including model development documents and reviews.\n",
       " KEY RESPONSIBILITIES INCLUDE:\n",
       " As part of the NLP data science team, you will work within the team to follow and develop AI solutions according to the MDLC process:\n",
       " Design, develop, and deploy AI/ML models using state of the art techniques available in the open stack (Python/PySpark/PyTorch) and/or vendor solutions\n",
       " Partner with LOB leads to frame the problem, explore various ML/DL model architectures and methodologies, generate required artifacts related to model development life cycle (MDLC), author the model development document, and deliver AI models that meet business needs\n",
       " Adhere to corporate model risk policy and ensure compliance with model risk management\n",
       " Working with other data science teams to identify, gather, retain, and publicize modeling artifacts required for approved and repeatable processes\n",
       " Work with AI technology and production teams to operationalize models\n",
       " Work effectively in an agile project management methodologies for data science\n",
       " Knowledge sharing with members of the team and across the organization on topics including machine learning algorithms, hyper-parameter tuning/search, and traversing across multiple big data platforms\n",
       " Contribute to NLP data science team’s group effort to stay current with the cutting edge NLP/ML/DL algorithms, methodologies in the open source community and vendor solutions.\n",
       " DIVISIONAL INFORMATION\n",
       " Data Management and Insights (DMI) is transforming the way that Wells Fargo uses and manages data. Our work enables Wells Fargo to empower and inform our team members, deliver exceptional experiences for our customers, and meet the elevated expectations of our regulators. The team is responsible for designing the future data environment, defining data governance and oversight, and partnering with technology to operate the data infrastructure for the company. This team also provides next generation analytic insights to drive business strategies and help meet our commitment to satisfy our customers’ financial needs.\n",
       " ,\n",
       " requirements and recommend appropriate systems alternatives and/or enhancements to current systems by analyzing business processes, systems and industry standards.\n",
       " Supervise day-to-day staff management issues, including resource management, work allocation, mentoring/coaching and other duties and functions as assigned\n",
       " Appropriately assess risk when business decisions are made, demonstrating particular consideration for the firm's reputation and safeguarding Citigroup, its clients and assets, by driving compliance with applicable laws, rules and regulations, adhering to Policy, applying sound ethical judgment regarding personal behavior, conduct and business practices, and escalating, managing and reporting control issues with transparency\n",
       " ,\n",
       " requirements and assist in mapping data requirements to reporting and analytics use cases\n",
       " Translate data requirements from diverse user groups and design a universal business data mart consisting of end-user consumption layer, reference data, metrics, and lookup tables\n",
       " Build logical and physical data models of the business data mart and incorporate best practices in the areas of data lineage, governance, reconciliation, metadata, access and security\n",
       " Develop SQL scripts for optimal extraction, transformation, and loading of data from multiple source data stores for building the business data mart\n",
       " Utilize SQL Server, SSIS, SSRS and Hadoop tools like Hive/Spark for building data pipelines\n",
       " Provide SME knowledge and technical support to data engineering partners for production implementation of the business data mart\n",
       " Assist in evaluation and proof-of-concept of a suite of candidate BI tools\n",
       " Migrate BI reports and other analytics use cased to the new business data mart\n",
       " Design and build reporting dashboards using Big Data BI tools like Zoomdata/Alteryx\n",
       " Perform end-to-end user acceptance testing and conduct demos for business groups\n",
       " Serve as liaison between business domains, technology partners, data engineers, and end users to drive implementation, adoption, training, and maintenance of developed data mart and BI reporting\n",
       " \n",
       " ,\n",
       " requirements are met\n",
       " Possess strong competencies with SQL (or related query languages) and data transformation tools to understand and prepare data\n",
       " Brings deep expertise in data visualization tools such as QlikSense and techniques in translating business analytics needs into data visualization and semantic data access requirements\n",
       " Automate tasks thru Robotic Process Automation tools\n",
       " Build and refine statistical models to gain better insight (primarily R Studio or Python)\n",
       " Qlik/Tableau experience is a plus\n",
       " ,\n",
       " ideal candidate is located in Dallas, TX, but telecommuting is an option for exceptional candidates with proven remote experience.\n",
       " ,\n",
       " requirements and the expected outcome\n",
       " Collaborate with subject matter experts to select the relevant sources of information\n",
       " Determine project plans, timelines, and/or technical objectives for statistical aspects of healthcare data analytic processes, applying valid statistical techniques and using information obtained from baselines or historical data to structure uncompromised and efficient analyses.\n",
       " Become an expert in our health care datasets\n",
       " Design experiments, test hypotheses, and build models\n",
       " Develop analytic studies with an aim of delivering immediate and actionable insights to business users\n",
       " Work in iterative processes and validates findings\n",
       " Produce new and creative analytic solutions that will become part of our core deliverables\n",
       " Non-Essential Responsibilities:\n",
       " ,\n",
       " ideal candidate brings a contribution mindset as part of a high-performing team in building these innovative data science applications capable of solving complex, global problems.\n",
       " ,\n",
       " requirements into corresponding datasets, analyses, models, and reports\n",
       " Demonstrated proficiency in R or Python required\n",
       " Experience applying Deep Learning and/or NLP techniques (especially using Tensorflow or PyTorch) on large unstructured data highly preferred\n",
       " Demonstrated good communication skills to exchange ideas and convey complex information clearly and concisely\n",
       " Model deployment and project management experience preferred\n",
       " This position is open to candidates in Boston, Dover, Plano, or Seattle. Compensation will vary based on location.\n",
       " ,\n",
       " Requirements\n",
       " At least a quant-based graduate degree such as Computer Science, Electrical Engineering, Math, Statistics, Physics, Economics, or other related fields from a reputed university with course work that includes analytics, coding, statistics, math, and algorithm development. Ph.D. is Preferred\n",
       " Strong in Math, Statistic, Finance, and Econometric\n",
       " Expert Level skills in one or many of the followings:\n",
       " Graph/Network Theory\n",
       " Personalized Recommendation Engine for Next Best Action and Next Best Choice\n",
       " 5+ years of hands on experience in Data Science.\n",
       " Experience in processing and performing multi-faceted analysis with on-line browsing, sales transaction, product, and inventory data.\n",
       " Experience in working in retail space will be a plus.\n",
       " Experience in developing or enhancing models applying machine learning and neural network algorithms, graph/network theory, statistical analysis, and optimization theories.\n",
       " Experience in using Keras, Tensorflow, and scikit-learn\n",
       " Strong coding skills in SQL, Python.\n",
       " Experience in working with distributed computing i.e. Hive, Apache Spark\n",
       " Experience in working on AWS SageMaker, S3, and SnowFlake will be a plus\n",
       " Knowledge of descriptive analytics and data visualization\n",
       " Experience with full lifecycle agile and experimental design methods.\n",
       " Exceptional standards for quality and strong attention to detail\n",
       " Ability to manage multiple projects and on-demand business requests simultaneously\n",
       " Able to work in a fast-paced core team environment with team members from diverse areas such as marketing, creative, strategy, and product.\n",
       " \n",
       " ,\n",
       " ideal candidate should have experience in applying statistics, building and testing models and working with big data solutions in a distributed computing environment. Experience with programming languages including Java, Python, R,& SQL. Candidates will be able to convey complicated technical analysis to senior management via investigation synopses, graphical depictions of attacks, and comprehensive presentations.\n",
       " RESPONSIBILITIES AND QUALIFICATIONS:\n",
       " Job Responsibilities\n",
       " Responsible for the creation of innovative methodologies for extracting key parameters from big data originating from various sensors.Utilize expertise in machine learning, statistical data analytics, and predictive analytics to help implement analytics tied to cyber security and hunting methodologies and applicationsDesign, develop, test and deliver complex analytics in a range of programming environments on large data setsApply latest technologies in machine learning, data mining, and predictive analytics to correlate the big datasets and events, and derive dynamic cybersecurity rules.Generate highly accurate and near real-time security alerts based on the dynamic rules. Collaborate with a global team to continually operate and improve a world-class cyber program by driving the uplift of sensory tools, detection tuning, and access to data sources to increase detection effectiveness by applying data analytics.\n",
       " ,\n",
       " requirements, and federal, state, and private health plans. Seeks advice and guidance as needed to ensure proper understanding.\n",
       " ,\n",
       " Requirements\n",
       " Experience in processing and performing multi-faceted analysis with on-line browsing sales transaction, product, and inventory data.\n",
       " Experience in working in retail space will be a plus.\n",
       " Strong in Math, Statistic, Finance, and Microeconomics\n",
       " Experience in developing or enhancing models applying artificial intelligence/machine learning (AI/ML) algorithms, statistical analysis, and optimization theories. A least three years of work experience in developing AI/ML models\n",
       " Strong coding skills in SQL, Python. A least four years of work experience in using SQL and Python).\n",
       " Experience in working with distributed computing i.e. Hive, Apache Spark. At least two years of experience in Spark\n",
       " Good to have -Experience in working on AWS SageMaker, S3, and SnowFlake\n",
       " Knowledge of descriptive analytics and data visualization\n",
       " Exceptional standards for quality and strong attention to detail\n",
       " Experience with full lifecycle agile application development in supporting analytic requirement\n",
       " Ability to manage multiple projects and on-demand business requests simultaneously\n",
       " \n",
       " ,\n",
       " requirements into technical specifications. Demonstrates solid grasp of software development lifecycle including DevOps and Site reliability engineering. Experience with cloud native methodologies and integrating third-party applications within a complex enterprise application portfolio. Proficiency in traditional application and mobile application development frameworks including exposure to UX/UI design.\n",
       " ,\n",
       " qualification, bringing established sales methods to the sales process\n",
       " Develop organized and differentiated go to market activities\n",
       " Develop overview materials to support initial meetings/conversations\n",
       " Lead preparations for formal sales meetings and orals for qualified opportunities\n",
       " Provide support to core accounts without CREs as needed for critical opportunities\n",
       " Identify opportunities (sole source/up for bid) and bring it to the business (functional) partners, evaluate opportunity alignment with client strategy\n",
       " Identify and align appropriate firm resources to pursue, win, and manage opportunities\n",
       " Lead pursuit process, RFP responses, etc.\n",
       " Contribute to pursuit processes by leveraging relationships for insights and influence, including determining “win” themes, aligning messaging with client needs, supporting proposal/orals materials preparation, and participating in the orals session as appropriate\n",
       " Support pre-sales efforts leveraging depth of product knowledge / product demonstrations tailored to client environment\n",
       " Industry Expansion and Relationship Building\n",
       " Collaborate Alliance, Marketing and practice leads on messaging, events and eminence - both internal and external\n",
       " Identify ways the practice can expand/enhance visibility at key events and in the market\n",
       " Participate in key industry events to build relationships and develop business opportunities\n",
       " Identify key relationships across the industry which would benefit the AI I&E practice and develop plans to cultivate those relationships\n",
       " Utilize Deloitte eminence - including thoughtware, events, trainings, conferences, and memberships – to build and enhance relationships\n",
       " Utilize available offerings to develop and participate in activities and events focused on shared values and mission, e.g., Deloitte Greenhouse events, Client Experience labs etc.\n",
       " Market offering Support\n",
       " Support AI Managed Services market offering leadership in developing account and practice plans during the annual planning process\n",
       " Participate in market offering leadership calls and in person meetings, and assist with planning and preparation as needed\n",
       " \n",
       " \n",
       " \n",
       " \n",
       " ,\n",
       " ideal candidate will have extensive experience with design, development and operations that leverages deep knowledge in the use of services like Amazon Kinesis, Apache Kafka, Apache Spark, Amazon Sagemaker, Amazon EMR, NoSQL technologies and other 3rd parties.\n",
       " ,\n",
       " key requirements and political constraints\n",
       " Experience designing and implementing Enterprise Data Warehouses (EDW) and related technologies\n",
       " Readiness, provisioning, security and governance relating to cloud platforms\n",
       " Experience with core Azure services related to data and analytics – examples: Synapse (DW), Data Lake, Databricks, Data Factory, Power BI\n",
       " Provide thought leadership around modern analytics tools and platforms for mid-sized companies to Fortune 500s\n",
       " Aware of approaches and challenges for an Analytics organization at varying maturities\n",
       " Experience/technical knowledge of the following:\n",
       " Hybrid architectures that include cloud and on-prem solutions\n",
       " Data integration and streaming tools used for both EDW’s and Big Data\n",
       " Cloud ETL tooling for creating data pipelines via traditional endpoints and APIs\n",
       " Data Science and related technologies (Python, R, etc.)\n",
       " Artificial Intelligence (AI), Machine Learning (ML), and Applied Statistics\n",
       " ,\n",
       " requirements and rationalize architecture decisions. During implementation, you will collect, aggregate and analyze structure/unstructured data from multiple internal and external sources and present patterns, insights and trends to decision makers. Your goal is to support the use of data-driven insights to help our clients achieve business outcomes and objectives.\n",
       " ,\n",
       " qualification similar to the above (experience based)\n",
       " ,\n",
       " requirements, promote re-use of software components and facilitates ease of support\n",
       " Staying current with IT, disseminating knowledge to team members and establishing best-practice\n",
       " Demonstrating a good understanding of design patterns and web development management skills\n",
       " ,\n",
       " requirements of large amounts of training data.\n",
       " ,\n",
       " ideal candidate is an experienced ML scientist who has a track-record of performing analysis and applying statistical techniques to solve real business problems, who has great leadership and communication skills, and who is motivated to achieve results in a fast-paced environment. The position offers an exceptional opportunity to grow your technical and non-technical skills and make a real difference to the Amazon Advertising business.\n",
       " ,\n",
       " ideal candidate for this role will be someone that can demonstrate a strong development background, values code quality, is highly innovative, and has an open and curious mindset that wants to challenge the norm. If this sounds of interest we would love to have a chat with you, please get in touch.\n",
       " \n",
       " ,\n",
       " requirements, namely, precision of diagnosis in cancer detection and safety in autonomous driving.\n",
       " Our goal is then to develop data processing algorithms that effectively capture common information across multimodal data, leverage these structures to improve reconstruction, prediction, or classification of the costlier (or all) modalities, and are verifiable and robust. We do this by combining learning-based approaches with model-based approaches. Over the last years, learning-based approaches, namely deep learning methods, have reached unprecedented performance, and work by extracting information from large datasets. Unfortunately, they are vulnerable to so-called generalization errors, which occur when the data to which they are applied differs significantly from the data used in the learning process. On the other hand, model-based methods tend to be more robust, but have poorer performance in general. The approaches we propose to explore use learning-based techniques to determine correspondences across modalities, extracting relevant common information, and integrate that common information into model-based schemes. Their ultimate goal is to compensate cost and quality imbalances across the modalities while, at the same time, providing robustness and verifiability.\n",
       " Key duties and responsibilities\n",
       " The appointed RA will design advanced optimization and machine learning algorithms to process multimodal data. They will work on aspects of the project together with the PI and collaborators. The RA is expected to publish scientific articles and present their work at conferences, workshops, and seminars. Furthermore, they are expected to co-supervise undergraduate and PhD students working in similar projects. There will also be opportunities to develop teaching experience, and to disseminate the research to the specialist communities via, e.g., the organization of a workshop, and to the wider public via outreach activities.\n",
       " Education, qualifications and experience\n",
       " Essential Criteria Applicants should hold (or about to obtain) a PhD in mathematics, electrical engineering, or computer science. A record of high-quality publications in international journals and conferences. Experience in the design and analysis of optimization algorithms and familiarity with imaging applications.\n",
       "  Basic knowledge of machine learning techniques, including deep learning, and familiarity with Python/Matlab/Julia packages for machine learning. Strong mathematical background and the ability to contribute with theoretical work. Excellent communication skills, written and oral.\n",
       " ,\n",
       " ideal candidate will have proven experience employing cutting-edge machine learning to real-world problems to deliver results. Strong computer science and algorithmic skills, knowledge on web security, exposure to internet-scale businesses, working in cross-functional teams, and a track record of peer-reviewed publication in a relevant area are desirable.\n",
       " ,\n",
       " requirements of local care delivery organizations needs and serves as an escalation point for complex issues. The Principal Integration Developer, Data Services will serve as a key resource of information technology for the organization, by providing guidance, assistance and consultation to others and has the capability to work on the full technology stack.\n",
       " ,\n",
       " requirements, as well as relevant DoD and Institute regulations and guidance\n",
       " Develops and maintains records of research activities, maintains research study regulatory readiness and assists in regulatory audits/inspections.\n",
       " Manages research activities within a defined budget\n",
       " Leads a team of software developers, clinicians and researchers; provides scientific research leadership and mentoring to junior researchers and fellows on team.\n",
       " Participates in investigator/study and Task Area team meetings.\n",
       " Data Collection and Analysis\n",
       " Serves as a Primary or Associate Investigator on research protocols that involve multiple Task Areas and projects (collaborative efforts).\n",
       " Collects data, documents experimental findings, summarizes data, prepares figures through use of available computer resources, and conducts preliminary analysis.\n",
       " Develop schema templates and relational database repositories and utilize statistical processes and applications including JMP, SAS, Prism, and R-Studio for data input formats.\n",
       " Writes code in Python, Java, SQL, Oracle Database, Java, R-language programming languages to support further development on artificial intelligence and clinical decision support tools\n",
       " Possesses skills and familiarity utilizing computer dataset tools: Python, SQL, Oracle Database, Java, R-language\n",
       " Performs appropriate statistical computations on raw data to determine significance, summarize results and draws appropriate conclusions.\n",
       " Data Dissemination\n",
       " Participates in the interpretation of results and prepares reports, abstracts, presentations and manuscripts for publication.\n",
       " Prepares figures, tables, methodological text, photography, graphics, and image production, for study presentations and publications.\n",
       " Participates in lectures, seminars, and conferences.\n",
       " Presents research findings at military and scientific conferences.\n",
       " Facilitates the gathering and sharing of relevant intellectual knowledge, expertise and data with clinical and research groups within the federal government, private sector and research facilities.\n",
       " Prepares periodic and status reports, as required by investigators, administrators, funding agencies, and/or regulatory bodies.\n",
       " Assists in the preparation for patent applications, intellectual property protections, invention disclosures, technology transfer etc…\n",
       " Assists in the transition of TA developed technologies toward Advanced Development.\n",
       " ,\n",
       " requirements through documentation, audits, and corrective action and follows GLP (good laboratory practice).\n",
       " Given detailed instruction, can complete additional tasks assigned by lead, supervisor, or manager in a timely manner.\n",
       " Comply with all company and department policies and procedures. This role works with PHI on a regular basis both in paper and electronic form and have an access to various technologies to access PHI (paper and electronic) in order to perform the job\n",
       " Employee must complete training relating to HIPAA/PHI privacy, General Policies and Procedure Compliance training and security training as soon as possible but not later than the first 30 days of hire.\n",
       " Must maintain a current status on Natera training requirements.\n",
       " Employee must pass post offer criminal background check.\n",
       " Performs other duties as assigned.\n",
       " QUALIFICATIONS\n",
       " 1-2-year experience as an ASCP-certified Medical Technologist in a clinical laboratory environment with knowledge in molecular diagnostics.\n",
       " Bachelor degree or equivalent in Medical Technology or a life science related field.\n",
       " Current ASCP board certification in Medical Technology or California State CLS or CGMBS license (Clinical Genetics Molecular Biologist Scientist).\n",
       " KNOWLEDGE, SKILLS, AND ABILITIES\n",
       " Good organizational skills\n",
       " Good communication skills, both written and verbal\n",
       " Proficiency in Microsoft Office Suite\n",
       " Knowledge of computer skills, quality control, calibration, and instrument maintenance\n",
       " Knowledge of various DNA sequencing methods preferred.\n",
       " The ability to produce accurate work under pressure, while handling changing volumes of work, and tight deadlines. The ability to organize time and prioritize tasks.\n",
       " PHYSICAL DEMANDS AND WORK ENVIRONMENT\n",
       " This position requires the ability to use a computer keyboard, communicate over the telephone and read printed material. Duties may require working outside normal working hours (evenings and weekends) at times.\n",
       " Duties typically performed in office setting.\n",
       " Standing or sitting for long periods of time may be necessary.\n",
       " OUR OPPORTUNITY\n",
       " ,\n",
       " requirements.\n",
       " Designs and develops scalable solutions that leverage machine learning and deep learning models to meet enterprise requirements.\n",
       " Works closely with data scientists and data engineers to develop machine learning algorithms\n",
       " Works on Optimization of Neural Net and Deep Learning models for inference learning algorithms into production-level code.\n",
       " Collaborates with development teams to test and deploy machine learning models\n",
       " Creates metrics to continuously evaluate the performance of machine learning solutions.\n",
       " Maintains and improves the performance of existing machine learning solutions.\n",
       " Ensures adherence to performance standards and compliance to data security requirements.\n",
       " Keeps abreast with new tools, algorithms and techniques in machine learning and works to implement them in the organization\n",
       " Keeps abreast with new tools, algorithms and techniques in machine learning and works to implement them in the organization\n",
       " ,\n",
       " ideal candidate is adaptable and resourceful - someone who understands that real data and problems are messy and cares more about making an impact than using the most cutting edge methods. Good business sense and an aptitude for framing and answering questions analytically is key in this role.\n",
       " WHAT YOU'LL DO:\n",
       " Collaborate with business stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions\n",
       " Mine and analyze data from analytics databases to drive optimization and improvement of commercialization tactics, agency operations, marketing techniques, product team planning and other business strategies through advanced forecasting and statistical methodology\n",
       " Assess the effectiveness and accuracy of new data sources and data gathering techniques\n",
       " Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes\n",
       " Consult and guide team members on A/B testing best practices and test model quality\n",
       " Coordinate with different functional teams to implement models and monitor outcomes\n",
       " Develop processes and tools to monitor and analyze model performance and data accuracy (confidence intervals, accuracy rates, etc.)\n",
       " Write maintainable, clean model code using best practices from software engineering where applicable\n",
       " Translate complex analytical results into insights to drive business development, and communicate them throughout the organization\n",
       " REQUIREMENTS / QUALIFICATIONS:\n",
       " Bachelor’s degree in a quantitative field, or equivalent applied professional experience\n",
       " 2-5+ years experience as a data scientist, decision scientist, data analyst, data engineer or other adjacent roles\n",
       " Experience manipulating data sets and building statistical models\n",
       " Solid mathematical foundation and knowledge of a variety of statistical methods (e.g. regression, classification, clustering, experimental design, advanced forecasting)\n",
       " Strong proficiency in SQL and either Python or R\n",
       " Strong proficiency in data visualization\n",
       " Excellent written and verbal communication skills for coordinating across teams\n",
       " A drive to learn and master new technologies and techniques\n",
       " EXPERIENCE THAT WILL IMPRESS THE HECK OUT OF US:\n",
       " MS or PhD with quantitative focus or relevant applied research/experience\n",
       " Experience with modern software engineering workflows and best practices (e.g. writing reproducible code, Git)\n",
       " Experience as a data scientist or analyst in a product driven ecommerce company and collaborating with business leaders\n",
       " Familiarity with research design / experimental methods (i.e. solid understanding of confounding, sources of bias in data, methods to infer causality, etc.)\n",
       " BENEFITS + PERKS:\n",
       " Competitive Compensation & Stock Option Offering\n",
       " Health, Dental, Vision & Disability Coverages\n",
       " HSA offering + employer contribution\n",
       " Unlimited PTO + flexibility to enjoy it\n",
       " Paid Parental Leave Program\n",
       " Commuter Benefits (up to $100/month)Wellness perk ($100/month)\n",
       " Learning & Development Stipends\n",
       " Onsite Full Service Barista\n",
       " Wednesday Catered Lunch + Fully Stocked Fridges\n",
       " Opportunity to join Employee Resource Groups (ERGs) or drive our diversity & inclusion stance by creating your own\n",
       " Join a team that truly lives their values, and values their lives (outside of the office. Cliche, we know… but we really mean it)\n",
       " ABOUT THE ZEBRA\n",
       " ,\n",
       " Requirements\n",
       " Minimum 6 years? experience. 8 or more years? experience preferred.\n",
       " Mastery knowledge of one or more specialized areas of operations research sufficient to apply new analytical developments, methodologies, and research findings to broad studies of an unprecedented nature\n",
       " Mastery knowledge of research techniques and ability to obtain information concerning subject studies to perform sound analyses\n",
       " Skill in coordinating extensive projects in assigned areas of responsibility. Projects are characterized by high visibility, unusual urgency, or program criticality\n",
       " Ability to identify the significant variables and determine their underlying relationships\n",
       " Ability to use advanced techniques and the modification and extension of theories, precepts, and practices of operations research and related sciences and disciplines\n",
       " Ability to design, build, and use very complex, sophisticated models to simulate real-world environments of many variables\n",
       " Work may occasionally require travel away from the normal duty station\n",
       " Must exhibit a high degree of judgment, resourcefulness, originality, and the ability to foresee the impact of changing technology\n",
       " Ability to obtain a TS/SCI government security clearance\n",
       " ,\n",
       " Requirements\n",
       " What we’re looking for:\n",
       " Create Statistical and/or Machine Learning based models to generate insights from billions of datapoints\n",
       " Identify potential paid & public sources of data and assess their value to the team’s projects\n",
       " Write systems to acquire & format external data sources for use in analytics projects\n",
       " Develop and iteratively improve tools to facilitate reporting and automate data acquisition/analysis\n",
       " Work with the larger data science team to analyze large data sets to uncover trends, patterns, and insights\n",
       " Leverage analytical tools and data science techniques the analysis of large data sets to uncover business insights\n",
       " Maintain existing, essential business processes to ensure data quality and process function\n",
       " Collaborate with non-technical stakeholders to ideate, prioritize and report on data sources and analyses\n",
       " Present approach and findings to technical & non-technical audiences across the company.\n",
       " \n",
       " ,\n",
       " REQUIREMENTS\n",
       " Environment:\n",
       " ,\n",
       " requirements – and have code changes integrated upstream\n",
       " Collaborate and interact with internal GPU library teams to analyze and optimize training and inference for deep learning\n",
       " Work in a distributed compute setting to optimize for both scale-up (multi-GPU) and scale-out (multi-node) systems\n",
       " Work with cutting-edge compiler technologies, technical depth in tensor code generation\n",
       " Optimize the entire deep learning pipeline\n",
       " Apply your knowledge of software engineering best practices\n",
       " \n",
       " ,\n",
       " requirements, propose AI software solutions to meet the business requirements, deliver and present AI software to clients\n",
       " Understand the data set used for the modeling, prepare and preprocess data sets, train and test models and perform model feature engineering\n",
       " Document data dictionary, data understanding, modeling strategy and approaches, and build company’s knowledge base of data and models\n",
       " Communicate effectively with team members, management, and clients\n",
       " Requirements\n",
       " Proven ability to work with large structured and unstructured datasets\n",
       " Demonstrable, hands-on experience in developing advanced analytics algorithms/models, including time series forecasting, machine learning and deep learning, image processing, natural language processing, and speech recognition\n",
       " Excellent hands-on code development skills in Python\n",
       " Good Knowledge of Machine Learning frameworks and packages, including Keras, TensorFlow, MXnet, Scikit-Learn and cloud technology (Amazon, Azure, etc.)\n",
       " Experiences in Machine Learning, Deep Learning, Computer Vision, and Natural Language Processing\n",
       " PhD degree in Mathematics, Statistics, Computer Science, or related disciplines\n",
       " At least 3 years of Artificial Intelligence\n",
       " At least 3 years of Machine Learning\n",
       " Background in Property and Casulity Insurance a big plus!\n",
       " You must be able to work out of our Houston office\n",
       " Additional Qualifications\n",
       " Parallel and distributed processing experience is a plus\n",
       " Expertise in data Extraction Transformation and Loading (ETL) is a strong plus (Spark, Hadoop, SQL) in big data environments.\n",
       " Domain knowledge in financial and insurance industries is a big plus\n",
       " The candidate must be able to work out of the Houston Texas office but remote work will be considered for extremely strong candidate\n",
       " Relocation reimbursement is available for the right candidate\n",
       " ,\n",
       " Basic Qualifications:\n",
       " 1+ years of experience with Tableau, including desktop, prep builder, and server\n",
       " Experience with Microsoft Excel\n",
       " Experience with data science coding languages, including R or Python\n",
       " Ability to obtain a security clearance\n",
       " BA or BS degree\n",
       " ,\n",
       " requirements\n",
       " Designs and develops scalable solutions that leverage machine learning and deep learning models to meet enterprise requirements\n",
       " Works closely with data scientists and data engineers to develop machine learning algorithms\n",
       " Works on Optimization of Neural Net and Deep Learning models for inference\n",
       " Translates machine learning algorithms into production-level code\n",
       " Collaborates with development teams to test and deploy machine learning models\n",
       " Creates metrics to continuously evaluate the performance of machine learning solutions\n",
       " Maintains and improves the performance of existing machine learning solutions\n",
       " Ensures adherence to performance standards and compliance to data security requirements\n",
       " ,\n",
       " requirements, research and data analysis to support partner alignment, business development, program development, and program evaluation and performance measurement. Work will include, but will not be limited to, preparing data for analysis, automating data staging as appropriate; creating data visualizations and maps; analyzing data outputs to compose written reports that respond to data requests; creating program evaluation plans and writing program evaluation reports; and presenting data analysis and findings to leadership and external stakeholders.\n",
       " Responsibilities:\n",
       " Essential Duties (at least 5 that are non-negotiable duties and are absolutely pertinent to successfully completing the job without accommodations):Prepares data from multiple and various large datasets for analysis, automating data prep when possibleCreates data visualizations using available applications (e.g. Tableau, MS Excel, ArcGIS)Analyzes trends, determines accuracy and relevancy of data information and present solutions and alternatives to issues when neededApplies inductive reasoning to combine separate pieces of information, or specific answers to problemsLeverages literature (e.g. journal articles, white papers, etc.) and other publicly available data resources related to data requests to inform analysis when appropriatePrepares accurate and meaningful reports that describe and interpret findings of analyses for upper management decision makingPresents data analysis and findings to leadership and external stakeholdersCreates population density and other data driven maps using ArcGIS that may stand alone or be included in analysesCreates program evaluation plans and conducts program evaluations with a final deliverable that includes a written report of evaluation findings and presentation of said findings to stakeholdersProtects the confidentiality of patient records, information, and activities that involve patient health informationSupports other quantitative and qualitative data-related activities as neededPerforms other duties as assigned\n",
       " ,\n",
       " requirements established to maintain consistent application, usage and reporting structure. Please reach out to your HR Business Partner for additional information on specific requirements prior to posting and/or employee placement into this job.\n",
       " This position will entail campaign measurement and testing.\n",
       " Provide decision support for business areas across the enterprise. Staff in this area will be responsible for applying mathematical and statistical techniques and/or innovative /quantitative analytical approaches to draw conclusions and make 'insight to action' recommendations to answer business objectives and drive change. The essence of work performed by the Decision Science Analyst involves gathering, manipulating and synthesizing data (e.g., attributes, transactions, behaviors, etc.), models and other relevant information to draw conclusions and make recommendations resulting in implementable strategies. Serves as a coach and mentor; and provides guidance to cross-functional team members to ensure success in achieving business objectives.\n",
       " ,\n",
       " requirements.\n",
       " Travel Required\n",
       " 25% or less - Temporary Duty travel 25% of the time.\n",
       " Supervisory status\n",
       " No\n",
       " Promotion Potential\n",
       " 13\n",
       " Job family (Series)\n",
       " 1515 Operations Research\n",
       " Requirements\n",
       " ,\n",
       " requirements, functional design, process design (including scenario design, flow mapping), prototyping, testing, training, defining support procedures.\n",
       " Formulate planning, budgeting, forecasting and reporting strategies.\n",
       " Manage full life cycle implementations.\n",
       " Develop statements of work and/or client proposals.\n",
       " Identify business opportunities to increase usability and profitability of information architecture.\n",
       " Experience with program leadership, governance and change enablement.\n",
       " Develop and manage vendor relationships.\n",
       " Lead workshops for client education.\n",
       " Manage resources and budget on client projects.\n",
       " Assist and drive the team by providing oversight.\n",
       " ,\n",
       " requirements, data discovery and extraction, model development and evaluation, to production pipeline implementation.\n",
       " Providing technical subject matter expertise in OSS and Microsoft AI and Data technologies, ranging from helping our product teams understand our gaps, through to navigating our customers to the right technology choices for their business.\n",
       " Qualifications\n",
       " Qualifications\n",
       " Required Qualifications:\n",
       " 2+ years of real-world experience with machine learning algorithms for classification, regression, clustering, reinforcement learning, dimensionality reduction with expertise one or more application domains of NLP, image processing, time series analysis including some knowledge of the concepts of taking projects to scale in the cloud.\n",
       " Fluency in English\n",
       " ,\n",
       " requirements listed below are representative of the qualifications necessary to successfully perform the job.\n",
       " ,\n",
       " Requirements:\n",
       " Bachelor’s degree in Computer Science, Information Management, Data Science, Analytics or related field or equivalent experience.\n",
       " 6 or more years of experience as a data engineer on enterprise-level data solutions.\n",
       " Experience in SQL and scripting for automation with Python, Perl or Ruby.\n",
       " Experience working with relational and unstructured databases and enterprise data warehouses, including MySQL, PostgreSQL, MongoDB, SQL Server or Oracle.\n",
       " ,\n",
       " requirements as outlined by Cerebri and Client legal and information security guidelines, law enforcement, and privacy legislation, including data anonymization, encryption, and security in transit and at rest, etc.\n",
       " Train and mentor junior team members\n",
       " Acts as a Subject Matter Expert and a Thought Leader, continuously following industry trends, the latest competitive developments, and delivering papers and presentations at major industry conferences and events.\n",
       " ,\n",
       " Requirements\n",
       " What you can expect/Accountabilities:\n",
       " Build machine learning systems to understand the cross-channel grocery ecosystem\n",
       " Perform statistical analysis across diverse datasets to drive and measure performance\n",
       " Work with PepsiCo’s strategic partners to expand their technical capabilities, thereby creating a more robust data environment\n",
       " Utilize natural language understanding techniques to uncover insights from contextual data\n",
       " Develop scalable tools to drive automation and optimize business operations\n",
       " As a Senior Data Scientist, you will play a critical role in executing the global ecommerce growth agenda. You will be tasked with identifying, designing, and implementing data science/machine learning solutions to business problems. You will collaborate with the larger data science and analytics teams to create a robust, shared codebase; on which PepsiCo will build automated eCommerce systems. You will work with internal business stakeholders and strategic partners to identify opportunities for collaborative development and foster a data-driven culture between relevant teams.\n",
       " \n",
       " \n",
       " \n",
       " ,\n",
       " ideal candidate is knowledgeable in research and statistical analysis, a strong SAS programmer, detail-oriented, self-driven, and works well in a team environment as well as independently.\n",
       " ,\n",
       " requirements. Collaborating with WF AI Tech, AI business, and LOB leads, you and your team will develop, deliver, and deploy AI/ML models on the Wells Fargo AI open source platform, scale them up, and operationalize them for business use. You and your team expect to follow and contribute to the Model Development Life Cycle that focuses on generating standardized processes, repeatable modules, and required artifacts to scale up model development, model review, and validation. You will work with Wells Fargo model risk governance and validation teams to ensure the modeling processes and procedures meet corporate model risk policy and requirements. You will also be managing work efforts with AI vendors to ensure vendor AI models pass Wells Fargo model risk policies and requirements including model development documents and reviews.\n",
       " KEY RESPONSIBILITIES INCLUDE:\n",
       " Build and lead a team of highly skilled data scientists to design, develop, and deploy AI/ML models using state of the art techniques available in the open stack (Python/PySpark/PyTorch) and/or vendor solutions\n",
       " Partner with LOB business executives to frame the problem, manage the model development process, and business relationship\n",
       " Manage a portfolio of the data science projects including the following responsibilities:\n",
       " Finalize project scope\n",
       " On-going touch-base with business partners and governance stakeholders\n",
       " Define priorities in partnership with the business partners during on-going development\n",
       " Ensure project quality and delivery timelines\n",
       " Adhere to corporate model risk policy and ensure compliance with model risk management\n",
       " Working with other data science teams to identify, gather, retain, and publicize modeling artifacts required for approved and repeatable processes\n",
       " Work with AI technology and production teams to operationalize models\n",
       " Review vendor models and solutions and/or models developed outside of AI MD CoE\n",
       " Work effectively in a collaborative environment with agile project management methodologies for data science\n",
       " Provide technical advice to other members of the team and across the organization on topics including machine learning algorithms, hyper-parameter tuning/search, and traversing across multiple big data platforms\n",
       " Identify and lead the evaluation of new software techniques and technologies, including delivery of results\n",
       " Identify new applications for machine learning across the company and work with business partners to pilot\n",
       " Adhere to and implement a documentation and artifact review process for model documentation and artifacts, created as part of the model development work performed by model development teams\n",
       " People management responsibilities such as hiring, performance management, routine travel and equipment/ software related approvals\n",
       " As a Team Member Manager, you are expected to achieve success by leading yourself, your team, and the business. Specifically you will:\n",
       " Lead your team with integrity and create an environment where your team members feel included, valued, and supported to do work that energizes them.\n",
       " Accomplish management responsibilities which include sourcing and hiring talented team members, providing ongoing coaching and feedback, recognizing and developing team members, identifying and managing risks, and completing daily management tasks.\n",
       " ,\n",
       " requirements\n",
       " Ensure unit test is completed and meets the test plan requirements, system testing is completed, and system is implemented correctly\n",
       " Create and maintain thorough documentation of system architecture and processes\n",
       " Identify and present potential pipeline integrity process improvements and follow-through with implementation once stakeholder/management agreement for the improvement is obtained\n",
       " Provide support for other aspects of integrity related programs, processes, and procedures as required\n",
       " **Position may be filled at various levels depending on years of experience.\n",
       " Position Requirements\n",
       " \n",
       " ,\n",
       " requirement of the role, due to COVID-19, non-essential travel has been suspended until further notice.)\n",
       " ,\n",
       " requirements\n",
       " Designs and develops scalable solutions that leverage machine learning and deep learning models to meet enterprise requirements\n",
       " Works closely with data scientists and data engineers to develop machine learning algorithms\n",
       " Works on Optimization of Neural Net and Deep Learning models for inference\n",
       " Translates machine learning algorithms into production-level code\n",
       " Collaborates with development teams to test and deploy machine learning models\n",
       " Creates metrics to continuously evaluate the performance of machine learning solutions\n",
       " Maintains and improves the performance of existing machine learning solutions\n",
       " Ensures adherence to performance standards and compliance to data security requirements\n",
       " Keeps abreast with new tools, algorithms and techniques in machine learning and works to implement them in the organization\n",
       " ,\n",
       " requirements\n",
       " Assist in the preparation of time estimates for project schedules\n",
       " Troubleshoot production problems within area of expertise\n",
       " Utilize and stay current in programming languages and software technology\n",
       " Qualifications:\n",
       " Master’s Degree in Statistics, Applied Mathematics, Operations Research or a related analytical field – Ph.D. desired\n",
       " 2+ years of commercial experience in a data science, machine learning, or predictive analytics role, formulating and implementing predictive analytics models\n",
       " A demonstrable scientific foundation and understanding of concepts of predictive analytics and data science such as theoretical statistics, estimation theory, simulation, consumer choice modeling, machine learning, etc.\n",
       " Solid programming skills in a general-purpose language and expertise in Python or R\n",
       " Exceptional analytical, decision-making, and problem-solving skills as well as solid communication and presentation skills with technical and non-technical audiences\n",
       " Experience and understanding of software development practice concepts and technology obtained through formal training and/or work experience\n",
       " ,\n",
       " requirements. Extract data from multiple data warehousing sources to generate and design standard and ad-hoc reports.\n",
       " Required Experience:\n",
       " Minimum of 5 years of demonstrated experience in statistics and statistical software (R, SAS, Python, SQL)\n",
       " Exposure and understanding of Data Science/Machine Learning Techniques (isolation forest, k-means clustering, anomaly detection, and principal component analysis, Baysian, etc.)\n",
       " 1-2 years of experience with data visualization software (Tableau, Qlik, PowerBI)\n",
       " Expert knowledge in Microsoft Office products and Sharepoint\n",
       " Demonstrated experience in preparing and editing technical documentation\n",
       " Required Experience:\n",
       " \n",
       " ,\n",
       " requirements. This fellowship will provide an opportunity to work with a broad range of technical health data related to population studies, disease prevention, managed care, medical readiness, health promotion, clinical preventive services, customer service, and other highly complex, highly technical health service related data analysis, BI and decision support.\n",
       " Appointment Length\n",
       " This appointment is a twelve month research appointment, with the possibility to be renewed for additional research periods. Appointments may be extended depending on funding availability, project assignment, program rules, and availability of the participant.\n",
       " Participant Benefits\n",
       " Participants will receive a stipend to be determined by DHA. Stipends are typically based on the participant’s academic standing, discipline, experience, and research facility location. Other benefits may include the following:\n",
       " Health Insurance Supplement. Participants are eligible to purchase health insurance through ORISE.\n",
       " Relocation Allowance\n",
       " Training and Travel Allowance\n",
       " ,\n",
       " requirements, functional design, process design (including scenario design, flow mapping), prototyping, testing, training, defining support procedures.\n",
       " Formulate planning, budgeting, forecasting and reporting strategies.\n",
       " Manage full life cycle implementations.\n",
       " Develop statements of work and/or client proposals.\n",
       " Identify business opportunities to increase usability and profitability of information architecture.\n",
       " Experience with program leadership, governance and change enablement.\n",
       " Develop and manage vendor relationships.\n",
       " Lead workshops for client education.\n",
       " Manage resources and budget on client projects.\n",
       " Assist and drive the team by providing oversight.\n",
       " The team\n",
       " Analytics & Cognitive\n",
       " In this age of disruption, organizations need to navigate the future with confidence, embracing decision making with clear, data-driven choices that deliver enterprise value in a dynamic business environment.\n",
       " ,\n",
       " requirements\n",
       " Cover letter with application packet\n",
       " Knowledge of statistical theory\n",
       " Experience in empirical practice\n",
       " Programming experience in low-level languages, such as C or FORTRAN\n",
       " Programming experience in statistical packages\n",
       " Good communication skills, including the ability to write and speak fluently in English\n",
       " A PhD or equivalent knowledge and job experience in statistics, biostatistics, economics, or another science-related field\n",
       " (Do not read into the order in which fields are listed. The degree is not a requirement; the knowledge is.)\n",
       " \n",
       " ,\n",
       " requirements, propose AI software solutions to meet the business requirements, deliver and present AI software to clients\n",
       " Understand the data set used for the modeling, prepare and preprocess data sets, train and test models and perform model feature engineering\n",
       " Document data dictionary, data understanding, modeling strategy and approaches, and build company’s knowledge base of data and models\n",
       " Communicate effectively with team members, management, and clients\n",
       " Requirements\n",
       " Proven ability to work with large structured and unstructured datasets\n",
       " Demonstrable, hands-on experience in developing advanced analytics algorithms/models, including time series forecasting, machine learning and deep learning, image processing, natural language processing, and speech recognition\n",
       " Excellent hands-on code development skills in Python\n",
       " Good Knowledge of Machine Learning frameworks and packages, including Keras, TensorFlow, MXnet, Scikit-Learn and cloud technology (Amazon, Azure, etc.)\n",
       " Experiences in Machine Learning, Deep Learning, Computer Vision, and Natural Language Processing\n",
       " PhD degree in Mathematics, Statistics, Computer Science, or related disciplines\n",
       " At least 3 years of Artificial Intelligence\n",
       " At least 3 years of Machine Learning\n",
       " Background in Property and Casulity Insurance a big plus!\n",
       " Additional Qualifications\n",
       " Parallel and distributed processing experience is a plus\n",
       " Expertise in data Extraction Transformation and Loading (ETL) is a strong plus (Spark, Hadoop, SQL) in big data environments.\n",
       " Domain knowledge in financial and insurance industries is a big plus\n",
       " The candidate must be able to work out of the Houston Texas office but remote work will be considered for extremely strong candidate\n",
       " Relocation reimbursement is available for the right candidate\n",
       " ,\n",
       " Requirements\n",
       " Bachelor’s degree or foreign equivalent in Computer Engineering, Computer Science, Mathematics, Statistics, Machine Learning, or related quantitative field and 5 years of related technical experience in position offered or acceptable alternate occupation. Full term of experience (5 years) must include each of the following: implementing data pipelines and creating architectural stack using bigdata technologies, including HDFS, MapReduce, Hive, Flume and Oozie; experience in NoSQL data modeling such as HBase. Must possess 2 years of experience with each of the following: working on strategy or full-life cycle big data engineering; writing Spark jobs to read/transform/write from different sources (Kafka, RabbitMQ) and destinations (NoSql, DataLake); hands-on experience working within data science capacity with big data (Hadoop, Spark); and experience in a technical lead position. Must possess 1 year of experience with each of the following: advanced statistical capabilities and statistical models, including: consumer predictive value, churn, segmentation and profiling, association models; Extracting existing trends and unnoticed insights using Data Mining techniques like Anomaly detection, data transformations, missing values treatments, and dimension reduction techniques; natural language processing; working with machine learning libraries (OpenCV, Scikit-Learn); using SAS, Python and R for Data Curation; and with Visualization on using Tableau, Matplotlib, plotly, ggplot2, and D3.js. Up to 20% international and domestic travel.\n",
       " Additional Information\n",
       " Location: Austin, Texas\n",
       " 40 hours/week\n",
       " Employee referral fee: $1,500\n",
       " If offered employment must have legal right to work in U.S. EOE.\n",
       " Mail resumes to Resideo Technologies, Inc./Ademco, Inc. HR, 8308 Wehland Ct., Laurel, MD 20723. Ref JD/mk.\n",
       " About Us: Resideo is a leading global provider of critical comfort and security solutions primarily in residential environments and distributor of low-voltage electronic and security products. Building on a 130-year heritage, Resideo has a presence in more than 150 million homes, with 15 million systems installed in homes each year. We continue to serve more than 110,000 professionals through leading distributors, including our ADI Global Distribution business, which exports to more than 100 countries from more than 200 stocking locations around the world. Resideo is a $4.8 billion company with approximately 13,000 global employees. For more information about Resideo, please visit www.resideo.com.\n",
       " \n",
       " ,\n",
       " ideal candidate will utilize their previous research experience and technology to develop and maintain Research using the following languages and technologies; C++, Java, Python, Big Data, Data Science, OpenMP, and GPGPU such as CUDA and OpenCL.\n",
       " ,\n",
       " requirements.\n",
       " Perform detailed exploration of new internal and external source data to perform source-to-target mapping to inform the development of new data pipelines/flows.\n",
       " Work in close collaboration with your data-minded colleagues focused on back-end (microservice) development, business intelligence reporting, machine learning and artificial intelligence models.\n",
       " Investigate the root cause of data-related issues and implement viable, sustainable solutions to correct issues.\n",
       " Perform database administration activities such as refreshes, updates, migrations, etc. in support of data pipeline maintenance.\n",
       " ,\n",
       " nice to have” rather than must-have.)\n",
       " ,\n",
       " key requirements and political constraints\n",
       " Experience designing and implementing Enterprise Data Warehouses (EDW) and related technologies\n",
       " Readiness, provisioning, security and governance relating to cloud platforms\n",
       " Experience with core Azure services related to data and analytics – examples: Synapse (DW), Data Lake, Databricks, Data Factory, Power BI\n",
       " Provide thought leadership around modern analytics tools and platforms for mid-sized companies to Fortune 500s\n",
       " Aware of approaches and challenges for an Analytics organization at varying maturities\n",
       " Experience/technical knowledge of the following:\n",
       " Hybrid architectures that include cloud and on-prem solutions\n",
       " Data integration and streaming tools used for both EDW’s and Big Data\n",
       " Cloud ETL tooling for creating data pipelines via traditional endpoints and APIs\n",
       " Data Science and related technologies (Python, R, etc.)\n",
       " Artificial Intelligence (AI), Machine Learning (ML), and Applied Statistics\n",
       " ,\n",
       " requirements, wrangling data, approaching business problems with analytic rigor, developing reusable data products and visualizing data to surface insights that drive business value and impact.\n",
       " Outstanding oral and written communication and interpersonal skills to successfully build long-term relationships with colleagues and business partners.\n",
       " Strong understanding of how analytics supports a large organization including ability to successfully articulate the linkage between business decisions, business objectives, and analytical approaches & findings.\n",
       " Works effectively across organization boundaries\n",
       " Focuses on delivering results accurately and timely by overcoming obstacles and developing tools to improve efficiencies\n",
       " Able to make trade-offs to deliver effective solutions to business partners in a timely fashion\n",
       " Even Better\n",
       " ,\n",
       " requirements, propose AI software solutions to meet the business requirements, deliver and present AI software to clients\n",
       " Understand the data set used for the modeling, prepare and preprocess data sets, train and test models and perform model feature engineering\n",
       " Document data dictionary, data understanding, modeling strategy and approaches, and build company’s knowledge base of data and models\n",
       " Communicate effectively with team members, management, and clientsx\n",
       " Requirements\n",
       " Proven ability to work with large structured and unstructured datasets\n",
       " Demonstrable, hands-on experience in developing advanced analytics algorithms/models, including time series forecasting, machine learning and deep learning, image processing, natural language processing, and speech recognition\n",
       " Excellent hands-on code development skills in Python\n",
       " Good Knowledge of Machine Learning frameworks and packages, including Keras, TensorFlow, MXnet, Scikit-Learn and cloud technology (Amazon, Azure, etc.)\n",
       " Experiences in Machine Learning, Deep Learning, Computer Vision, and Natural Language Processing\n",
       " PhD degree in Mathematics, Statistics, Computer Science, or related disciplines\n",
       " At least 10 years of industrial research experience\n",
       " Experience in Machine learning\n",
       " Background in Property and Casulity Insurance a big plus!\n",
       " Additional Qualifications\n",
       " Parallel and distributed processing experience is a plus\n",
       " Expertise in data Extraction Transformation and Loading (ETL) is a strong plus (Spark, Hadoop, SQL) in big data environments.\n",
       " Domain knowledge in financial and insurance industries is a big plus\n",
       " The candidate must be able to work out of the Houston Texas office but remote work will be considered for extremely strong candidate\n",
       " Relocation reimbursement is available for the right candidate\n",
       " ,\n",
       " ideal candidate for this position has the adaptability to keep up with changing requirements and timelines and can communicate effectively across various teams and departments. They have the maturity, flexibility, and curiosity to wear many hats and take on additional responsibility.\n",
       " ,\n",
       " requirements, procedures, and problems to automate processing or to improve existing systems. May supervise the work of others. Works under minimal supervision, with considerable latitude for the use of initiative and independent judgment.\n",
       " ,\n",
       " requirements, and guidance to software engineers for algorithm implementation for solution/product development.\n",
       " Decide when a model is ready for deployment and monitor its accuracy over time to see when it needs to be retrained or replaced.\n",
       " Oversee the AI Ops process with periodic or continuous model maintenance\n",
       " Collaborate and communicate between data scientists and operations professionals to help manage production machine learning lifecycle.\n",
       " Enhance existing platform and solutions by adding and improving features\n",
       " ,\n",
       " requirements and be able to translate them into technical implementations\n",
       " Ability to mix deep technical expertise with simple, everyday language to deliver a story that is memorable, educational and useful\n",
       " Highly organized, detail-oriented, excellent time management skills and able to effectively prioritize tasks in a fast-paced, high-volume, and evolving work environment\n",
       " Ability to approach customer and sales requests with a proactive and consultative manner; listen and understand user requests and needs and effectively deliver\n",
       " Comfortable managing multiple and changing priorities, and meeting deadlines in an entrepreneurial environment\n",
       " Motivated self-starter who loves to troubleshoot and solve challenging problems and feels comfortable working directly with customers\n",
       " ,\n",
       " ideal candidate will have:\n",
       " ,\n",
       " Requirements\n",
       " Bachelor's degree or equivalent experience in IT, Computer Science, STEM or a related field\n",
       " Experience in Linux (Ubuntu) as an user\n",
       " Strong technical documentation skills\n",
       " Excellent communication and interpersonal skills\n",
       " Ability to use command line interfaces\n",
       " Basic automotive electrical or computer system understanding\n",
       " Reliable and safety oriented\n",
       " Willing to be flexible on work schedule and open to learning new technology\n",
       " Up to 75% Travel (Hotel and Meals Provided by Company)\n",
       " Responsibilities\n",
       " Basic troubleshooting of hardware and software issues\n",
       " Accurately set up, collect, verify and analyze data\n",
       " Document technical notes and tag events\n",
       " Conduct pre and post trip inspections of the autonomous system\n",
       " Perform data offloads and post trip system shutdowns\n",
       " Spend extended periods of time testing and documenting in vehicle\n",
       " Interface with testing teams in Tucson to discuss performance and upcoming changes\n",
       " You will spend long hours in a commercial vehicle hauling freight with a commercial driver\n",
       " ,\n",
       " Requirements (Education, certifications and experience):\n",
       " ,\n",
       " ideal candidate will develop, maintain, test and evaluate big data solutions, and possess a high level of confidence and comfortability in wrestling with problems associated with database integration and messy, unstructured data sets. This position will report to the CEO.\n",
       " ,\n",
       " requirements, i.e., retention, availability, performance\n",
       " Escalate issues as required to the Data Governance team\n",
       " Promote the importance and awareness of an enterprise data program within their business function\n",
       " ,\n",
       " requirements\n",
       " Flexibility to work outside of normal business hours and a willingness to learn\n",
       " Sound analytical skills as well as problem-solving aptitude\n",
       " Must be an exceptional communicator and able to make connections across the organization\n",
       " Educational requirements: the ideal candidate will have a Master’s degree in Data Science, Computer Science, Actuarial Science, Mathematics, Statistics or related field, or the equivalent education and/or experience. A Ph.D. would be preferred.\n",
       " The Tokio Marine HCC Group of Companies offer a competitive salary and employee benefit package. We are a successful, dynamic organization experiencing rapid growth and are seeking an energetic and confident individual to join our team of professionals. The Tokio Marine HCC Group of Companies are equal-opportunity employers. Please visit www.tmhcc.com for more information about our companies.\n",
       " ,\n",
       " requirements and the expected outcome\n",
       " Manage multiple projects in parallel and oversee their completion from start to finish, setting goals and project milestones\n",
       " Conceptualize and plan leading-edge analytic and quantitative tools and modeling techniques to help 7Park Data’ clients gain insights and improve decision-making\n",
       " Review internal and external analytical techniques, identify what data is available and relevant and source the necessary data\n",
       " Collaborate with the Engineering team to deploy solutions to production\n",
       " Make strategic recommendations to technology, product, and senior management\n",
       " Be the voice of data science internally and represent 7Park externally\n",
       " ,\n",
       " requirements to develop analytic capabilities, platforms, and pipelines.Apply statistical or machine learning knowledge to specific business problems and data.\n",
       " Explore / Enlighten\n",
       " Formalize assumptions about how our systems are expected to work, create statistical definition of the outlier, and develop methods to systematically identify these outliers. Work out why such examples are outliers and define if any actions needed.Given anecdotes about anomalies or generate automatic scripts to define anomalies, deep dive to explain why they happen, and identify fixes.\n",
       " Make Decisions or Recommendations\n",
       " Build decision-making models and propose solution for the business problem you definedConduct written and verbal presentation to share insights and recommendations to audiences of varying levels of technical sophistication.Utilize code (python or another object oriented language) for data analyzing and modeling algorithms\n",
       " ,\n",
       " requirements, propose AI software solutions to meet the business requirements, deliver and present AI software to clients\n",
       " Understand the data set used for the modeling, prepare and preprocess data sets, train and test models and perform model feature engineering\n",
       " Document data dictionary, data understanding, modeling strategy and approaches, and build company’s knowledge base of data and models\n",
       " Communicate effectively with team members, management, and clients\n",
       " Requirements\n",
       " Must have at least 1+ year NLP experience in a professional or research capacity\n",
       " Must have NLP Expertise and practical knowledge with preprocessing (Spacy or NLTK), Topic modeling (Gensim), POS-tagging, word embedding. Spacy, nltk, genism are the related software\n",
       " Proven ability to work with large structured and unstructured datasets\n",
       " Demonstrable, hands-on experience in developing advanced analytics algorithms/models, including time series forecasting, machine learning and deep learning, image processing, natural language processing, and speech recognition\n",
       " Excellent hands-on code development skills in Python\n",
       " Good Knowledge of Machine Learning frameworks and packages, including Keras, TensorFlow, MXnet, Scikit-Learn and cloud technology (Amazon, Azure, etc.)\n",
       " Experiences in Machine Learning, Deep Learning, Computer Vision, and Natural Language Processing\n",
       " PhD degree in Mathematics, Statistics, Computer Science, or related disciplines\n",
       " At least 3 years of Artificial Intelligence\n",
       " At least 3 years of Machine Learning\n",
       " Background in Property and Casualty Insurance a big plus!\n",
       " You must be able to work out of our Houston office\n",
       " Additional Qualifications\n",
       " Parallel and distributed processing experience is a plus\n",
       " Expertise in data Extraction Transformation and Loading (ETL) is a strong plus (Spark, Hadoop, SQL) in big data environments.\n",
       " Domain knowledge in financial and insurance industries is a big plus\n",
       " The candidate must be able to work out of the Houston Texas office but remote work will be considered for extremely strong candidate\n",
       " Relocation reimbursement is available for the right candidate\n",
       " ,\n",
       " ideal candidate will be a customer focused data scientist with advanced technology skills that seeks opportunities to get their hands dirty while confidently working with clients to design and build solutions that will best demonstrate Bloomberg content and technology in conjunction with modern data science tools and workflows.\n",
       " ,\n",
       " ideal candidate will have significant experience using R, R Shiny, R Markdown, and Python (with a preference for fluency in all) in multiple analytical applications, such as geo-informatics, non-linear time series analysis, machine learning (e.g. binomial/regression models, ensemble models), deep learning (e.g. NN, CNN and RNN) and probability and statistics. As with any successful analytics project, it all starts with the data, and as such you should have experience extracting and transforming data from relational databases (e.g. Oracle, SQL Server). Time-series database experience (e.g. OSI PI) is a plus.\n",
       " ,\n",
       " requirements; design, analyze, and review data; manage internal customer expectation in terms of deliverables. Follow up on pending items and troubleshoot as needed\n",
       " Serve as the Project Manager on several projects to ensure accuracy and timely completion and submission of all deliverables\n",
       " Collaborate with Information Technology and TEF to develop a standard reporting tool to report accurate data for the trustees’ reports from all Funds, using data from the internal database\n",
       " Provide ad-hoc reporting for information that is not reported by, or available in the internal database, using business intelligence tools; Qlikview, MS Access, Excel and SSRS\n",
       " Perform additional duties and projects as assigned by management\n",
       " \n",
       " ,\n",
       " ideal candidate thrives on solving hard problems at Amazon scale and has prior research experience in computer vision and machine learning, ideally applied to 3D data structures.\n",
       " ,\n",
       " requirements, select analytics methods, identify gaps in existing methods, and develop new methods as necessary\n",
       " Work independently and with a minimum of supervision\n",
       " Qualifications\n",
       " ,\n",
       " requirements\n",
       " Select appropriate datasets and data representation methods\n",
       " Run machine learning tests and experiments\n",
       " Perform statistical analysis and fine-tuning using test results\n",
       " Train and retrain systems when necessary\n",
       " Extend existing ML libraries and frameworks\n",
       " Keep abreast of developments in the field\n",
       " ,\n",
       " requirements to build complex predictive modelsDevelop Machine Learning pipelinesResearch and experiment with emerging ML and Big Data technologies and toolsAnalyze highly complex business requirements, design and write technical specifications to design or redesign complex applicationsResearch and development for data-driven analysis on structured and unstructured dataCollaborate with other technology teams and architects to define and develop solutions.Translate complex functional and technical requirements into detailed technical designTest prototypes and oversee handover to operational teamsPropose best practices/standards\n",
       " The successful candidate for the position will likely have the following skills and experience:Hands-on development experience developing Machine Learning solutions on large datasetsFluent in Machine Learning techniques: Regression, Trees, Clustering, Neural Networks, Anomaly DetectionFluent in Python, Scala, SQLFluent in TensorFlow, Keras, NLP librariesStrong background in working in a data driven environment and supporting fast paced agile developmentStrong technical background working in a Big Data ecosystem and ability to do data analysis, data engineering, ML design and developmentBe willing to learn and be flexible to changing technologyExperience creating best practices and standards around ML model deployment framework and socializing them with the community to ensure successful delivery of the models\n",
       " ,\n",
       " requirements to inform the next set of features for the platform\n",
       "  Design solutions for problems such as elastic load distribution, GPU sharing and guaranteed scheduling\n",
       "  Automate operation and improve telemetry of data science platform components in our infrastructure stack\n",
       " ,\n",
       " ideal candidate will be a hands-on analyst who enjoys both the detailed work involved in algorithm/model development but who can also abstract this work to the goal of building a scalable platform. This position is US-based with a preferred location in our NYC headquarters or the Boston-DC corridor.\n",
       " ,\n",
       " requirements, problem solving and offering new solutions or enhancements to external and internal customers. This internship will expose you to the full gamut of the TV One sales support staff.\n",
       " RESPONSIBILITIES:\n",
       " Provide analysis of business requirements, processes and workflows with suggestions for improvement\n",
       " Gain exposure across the TV One sales support spectrum including but not limited to P&I, Operations\n",
       " Gain an understanding of the processes and functions provided by the current systems\n",
       " Assist with developing test schedules, review testing plans and tracking testing results\n",
       " Assist with data extraction and analysis pertaining to TV One\n",
       " Attends and participates in meetings and brainstorming sessions as directed.\n",
       " Assists with other administrative duties and media projects as assigned.\n",
       " ,\n",
       " requirements, and delivering high quality software on tight schedules.\n",
       " ,\n",
       " requirements for reporting and / or business intelligence tools.\n",
       " Identifies necessary data, data sources and methodologies.\n",
       " Collects, organizes, integrates, analyzes and interprets data.\n",
       " Leverages advanced statistical analysis methods to create insightful recommendations and conclusions that may be communicated to the stakeholder.\n",
       " Identifies and addresses expected and unforeseen data complexities to mitigate their impact on the analytic outcome and associated business decisions. Works to improve data quality where possible within created analytical models. Feeds data quality issues back to IT or identified data stewards to facilitate creation of high quality metrics.\n",
       " Develops and may present reports, analyses and findings to senior management and others as scheduled or requested.\n",
       " Responsible for one or more of the following stakeholder groups:\n",
       " Contracting and Commercialization – May assist in the modeling and forecasting contract scenarios, measuring ongoing performance and identify trends in performance to inform our clinical or contracting staff to improve contract outcomes.\n",
       " Care Management – Helps to identify, understand and prioritize at-risk members in need of care management. Helps stratify our membership to optimally use resources to focus on the patients most in need, currently or in the future.\n",
       " Medical Directors – Helps to identify utilization trends and variations across the different categories of health care services to assist the Medical Directors to focus their efforts to maximize contract performance and clinical effectiveness.\n",
       " Quality and Documentation – Helps to link payer quality and documentation opportunities into operational analytic processes to maximize our quality scores, top line revenue and optimize the use of resources in concert with MS Health System contracts.\n",
       " I.T. / High Performance Computing in any ongoing projects.\n",
       " Takes a proactive role as liaison/analyst for internal stakeholders, understands their needs and translates them into reporting and analytic solutions.\n",
       " Effectively communicates with stakeholders and customers and ensures all requests are properly triaged, recorded and tracked.\n",
       " Adheres to corporate standards for performance metrics, data collection, data integrity, query design, and reporting format to ensure high quality, meaningful analytic output.\n",
       " Helps identify and understand data from internal and external sources for competitive, scenario and performance analyses, and financial modeling to gain member/provider insight into new and existing processes and business opportunities.\n",
       " Works closely with IT on the ongoing improvement of Mount Sinai’s integrated data warehouse, driven by strategic and business needs, and designed to ensure data and reporting consistency throughout the organization.\n",
       " Develops and maintains project work plans, including critical tasks, milestones, timelines, interdependencies and contingencies. Tracks and reports progress. Keeps stakeholders apprised of project status and implications for completion.\n",
       " Provides technical support to data analytics functions as they relate to varied business units, and technical expertise on the selection, development and implementation of various reporting and BI tools tied to business unit reporting requirements. Creates new BI reports and interactive dashboards as required.\n",
       " Prepares clear, well-organized project-specific documentation, including, at a minimum, analytic methods used, key decision points and caveats, with sufficient detail to support comprehension and replication.\n",
       " Ensures customers are adequately trained to use self-service BI tools and dashboards.\n",
       " Shares development and process knowledge with other analysts in order to assure redundancy and continuously builds a core of analytical strength within the organization.\n",
       " Demonstrates advanced level proficiency with the principles and methodologies of process improvement. Applies these in the execution of responsibilities in support of a process focused approach.\n",
       " Other duties as assigned\n",
       " ,\n",
       " requirements to technical architectures and designs\n",
       " Comfortable communicating with stakeholders (internal technical and nontechnical members, product managers, C-level management)\n",
       " ,\n",
       " requirements with respect to scalability\n",
       " Work effectively within a team\n",
       " Qualifications\n",
       " ,\n",
       " requirements and explain/discuss implementation details of complex statistical analyses to both technical and non-technical audiences.\n",
       " Requirements:\n",
       " Expertise/experience in the following:\n",
       " Planning and executing statistical analysis by authoring parts of and/or providing significant input in the SAP, implementing the SAP using SAS, ensuring quality via validation, and explaining implementation details to technical and non-technical audiences.\n",
       " Statistical programming methods including knowledge of CDISC standards as it relates to the following areas:\n",
       " Medical Affairs analyses using the clinical database for scientific meetings, publications, and internal decision-making (generally based on previously conducted randomized clinical trials).\n",
       " Health Economics and Outcomes Research analyses including patient reported outcomes (including development/validation), HTA/reimbursement/ value dossiers, and real world studies.\n",
       " Designing and developing statistical programming infrastructure including statistical programming standards, analysis/display standards, and building SAS macro libraries.\n",
       " ,\n",
       " requirements to plans with well-defined objectives, timelines and responsibilities for the team and successfully execute against them\n",
       " Think critically about data and the appropriate pairings of uses cases and data to drive the collection and manipulation of new data and the refinement of existing data sources\n",
       " Collaborate with our Data Engineering team to select the appropriate tools for each project, and fully exploit methods and algorithms developed for other tools and projects\n",
       " Manage multiple priorities across a mix of ad hoc and operational projects\n",
       " Qualifications/Requirements\n",
       " ,\n",
       " requirements, technical analysis, and design\n",
       " Document business and functional requirements, design decisions, and rationales for AI/ML models\n",
       " Contribute to the definition of the future state of the system architecture\n",
       " When product and architecture experience are gained, you will mentor and direct more junior developers\n",
       " Your Skills and Experience:\n",
       " Bachelor’s Degree or higher in computer science, artificial intelligence, machine learning, statistics, robotics, computational biology or engineering\n",
       " Hands on experience in Java, Anaconda, PyCharm, Spark, Flink, Fabric and experience with machine learning techniques\n",
       " Strong hands-on experience of Python, Spark, Hadoop, Flink, Jupyter Notebook, or other data science packages\n",
       " Strong hands-on experience of AI, ML, math and algorithms/complexity\n",
       " Experience building machine learning models for recommending products and actions\n",
       " Our values define the working environment we strive to create - diverse, supportive and welcoming of different views. We embrace a culture reflecting a variety of perspectives, insights and backgrounds to drive innovation. We build talented and diverse teams to drive business results and encourage our people to develop to their full potential. Talk to us about flexible work arrangements and other initiatives we offer.\n",
       " ,\n",
       " Nice to haves:\n",
       " You have proficiency with NLP python libraries such as NLTK; Hadoop or Apache Spark; D3.js or R.\n",
       " You are on top of industry trends in big data, machine learning, deep learning, and AI.\n",
       " You have previous data science or engineering teaching experience, through a course, workshop, team training, etc.\n",
       " \n",
       " ,\n",
       " requirements to develop analytic capabilities, platforms, pipelines and metrics then using them to analyze trends and find root causes of forecast inaccuracyFormalizing assumptions about how demand forecasts are expected to behave, creating definitions of outliers, developing methods to systematically identify these outliers, and explaining why they are reasonable or identifying fixes for themUtilizing code (Python, R, Scala, SQL etc.) for analyzing data and building statistical and machine learning models and algorithms\n",
       " Amazon.com is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation\n",
       " ,\n",
       " requirements, functional design, process design (including scenario design, flow mapping), prototyping, testing, training, defining support procedures.\n",
       " Formulate planning, budgeting, forecasting and reporting strategies.\n",
       " Manage full life cycle implementations.\n",
       " Develop statements of work and/or client proposals.\n",
       " Identify business opportunities to increase usability and profitability of information architecture.\n",
       " Experience with program leadership, governance and change enablement.\n",
       " Develop and manage vendor relationships.\n",
       " Lead workshops for client education.\n",
       " Manage resources and budget on client projects.\n",
       " Assist and drive the team by providing oversight.\n",
       " ,\n",
       " requirements and customer needs to a scientific problem.Align the research direction to business requirements and make the right judgments on research/development schedule and prioritization.Research, design and implement scalable machine learning (ML), natural language, or computational models to solve problems that matter to our customers in an iterative fashion.Mentor and develop junior applied scientists and developers who work on data science problems in the same organization.Stay informed on the latest machine learning, natural language and/or artificial intelligence trends and make presentations to the larger engineering and applied science communities.\n",
       " ,\n",
       " requirements and IS capabilities.\n",
       " 8. Assists in ensuring that systems are implemented to support Health System initiatives and goals to improve the quality of patient care, to maximize patient safety, and to provide operational efficiencies.\n",
       " 9. Serves as a resource to the Director of Quality Informatics and Program Director of Data Science.\n",
       " 10. Demonstrates familiarity with current hospital information systems.\n",
       " 11. Performs other duties as assigned.\n",
       " ADA Essential Functions\n",
       " \n",
       " ,\n",
       " Requirements:\n",
       " 5+ years as a data scientist\n",
       " 5+ years working with SQL\n",
       " 5+ years using various machine learning tools\n",
       " 3+ years of experience in programming with Python or R\n",
       " \n",
       " ,\n",
       " ideal candidate will have an interest in working on a start-up team in an entrepreneurial team within APCO Insight to help develop new products and methodologies to sell to clients and prospects around reputation management, corporate branding, thought leadership and/or public affairs issues management.\n",
       " Founded in 1984, APCO Worldwide is an award-winning, independently owned global communication and business strategy firm with offices in major cities throughout North America, Europe, the Middle East, Africa and Asia. APCO combines a global perspective with local expertise to help clients around the world manage challenges, opportunities, perceptions and reputations. APCO clients include corporations and governments; industry associations and nonprofit organizations; and six of the top 10 companies on the Fortune 500. The firm is a majority women-owned business.\n",
       " APCO Worldwide, named “Public Affairs Agency of the Decade” by The Holmes Report and one of the “Top Places to Work in PR” by PRNews, offers a collegial work environment, countless training and development opportunities, and a competitive compensation and benefits package.\n",
       " EOE M/F/V/D\n",
       " ,\n",
       " requirements for this roleMeets/exceeds Amazon’s functional/technical depth and complexity for this role\n",
       " Benefits\n",
       " ,\n",
       " need to have:\n",
       "  A strong statistical background in ML, NLP, deep learning models along with familiarity in probabilistic information retrieval and optimization methods\n",
       "  Professional experience of building and deploying ML apps to production\n",
       "  2+ years of hands-on experience in Python/C/C++ development and knowledge of distributed, scalable architectures and CICD tooling\n",
       "  A solid understanding of data structures, algorithms and software design concepts\n",
       "  Strong communication skills and interest in learning financial product domains\n",
       "  BA, BS, MS, PhD in Computer Science, Data Science or related technology field\n",
       " We’d love to see:\n",
       "  Knowledge of advanced concepts such as weakly supervised learning, reinforcement learning and active learning\n",
       "  Familiarity with SQL and NoSQL data modeling and exploratory data visualization\n",
       "  Professional experience as a technology lead or architect\n",
       "  Authored research publications, participation in ML competitions, working demos/repos\n",
       " ,\n",
       " requirements\n",
       " Collaborate with scrum team members on complex projects requirements\n",
       " Perform extensive data validation/quality assurance analysis within large datasets\n",
       " Troubleshoot and investigate data anomalies and issues along with working directly with the developers to follow through and resolve issues in data lineage and consistency\n",
       " Work with business analysts to clarify business rules and requirements\n",
       " Translate business data import and export needs into a maintainable integrations platform\n",
       " Ensure adherence to corporate development and mortgage industry requirements\n",
       " ,\n",
       " requirements in the AWS Cloud. The team interacts with security researchers to codify our own learnings and best practices and make them available for customers. We are building massively scalable and globally distributed security systems to power next generation services.\n",
       " ,\n",
       " ideal candidate will have a strong scientific background in computational sciences with experience developing interatomic potentials. Previous experience in professional software development is not required, but an interest in adopting best engineering practices is.\n",
       " ,\n",
       " qualification, bringing established sales methods to the sales process\n",
       " o Develop organized and differentiated go to market activities\n",
       " o Develop overview materials to support initial meetings/conversations\n",
       " o Lead preparations for formal sales meetings and orals for qualified opportunities\n",
       " o Provide support to core accounts without CREs as needed for critical AI I&E opportunities\n",
       " o Identify opportunities (sole source/up for bid) and bring it to the business (functional) partners, evaluate opportunity alignment with client strategy\n",
       " o Identify and align appropriate firm resources to pursue, win, and manage opportunities\n",
       " o Lead pursuit process, RFP responses, etc.\n",
       " o Develop proposals, SOW, etc.\n",
       " o Contribute to pursuit processes by leveraging relationships for insights and influence, including determining “win” themes, aligning messaging with client needs, supporting proposal/orals materials preparation, and participating in the orals session as appropriate\n",
       " o Support pre-sales efforts leveraging depth of product knowledge / product demonstrations tailored to client environment\n",
       "  Industry Expansion and Relationship Building\n",
       " o Collaborate AI I&E Alliance, Marketing and practice leads on messaging, events and eminence - both internal and external\n",
       " o Identify ways the AI I&E practice can expand/enhance visibility at key events and in the market\n",
       " o Participate in key industry events to build relationships and develop business opportunities\n",
       " o Identify key relationships across the industry which would benefit the AI I&E practice and develop plans to cultivate those relationships\n",
       " o Utilize Deloitte eminence - including thoughtware, events, trainings, conferences, and memberships – to build and enhance relationships\n",
       " o Utilize available offerings to develop and participate in activities and events focused on shared values and mission, e.g., Deloitte Greenhouse events, Client Experience labs etc.\n",
       "  Market offering Support\n",
       " o Support AI I&E market offering leadership in developing account and practice plans during the annual planning process\n",
       " o Participate in AI I&E market offering leadership calls and in person meetings, and assist with planning and preparation as needed\n",
       " \n",
       " ,\n",
       " nice to have but not required\n",
       " Experience maintaining code repositories in git\n",
       " Sharp problems solving skills and strong statistics skills\n",
       " Strong fundamentals and intuition in applied statistics for both prediction and explanation\n",
       " Able to build, optimize, and test prediction and forecasting models\n",
       " Familiarity with basic Linux tools\n",
       " Able to quickly understand business problems and implement experimental designs\n",
       " Able to balance analytical rigor against meeting deadlines\n",
       " Knowledge of causal analysis methods\n",
       " Excellent presentation, writing, and data visualization skills\n",
       " Experience using AWS to implement data science workflows is a plus\n",
       " Experience working with product managers and business stakeholders to build products driven by prediction models and insights from data analysis\n",
       " Ability to convey machine learning and statistics concepts to non-experts\n",
       " ,\n",
       " requirements and resource requirements within the therapeutic area(s). The incumbant works with management to identify, develop and implement departmental standards, applications, processes, and training. Works with the Biostatistics group to ensure programmer needs are met regarding therapeutic analysis specifications, application and computing environment support. Works with management to ensure implementation of departmental standards and process, and to identify resource needs based on project milestones and deliverables. The incumbent is responsible for screening and interviewing viable candidates for positions within the programming group, both contract and permanent, and is responsible for goal setting and performance management. May be asked to oversee special projects / work with clinical task force.\n",
       " ,\n",
       " requirements and then work closely with other data engineering and analytic professionals to execute those plans.\n",
       " ,\n",
       " ideal candidate is an accomplished expert with deep technical credibility and implementation skills – he/she designs, prototypes, develops, and fields predictive models and analytical approaches that power a critical business function.\n",
       " ,\n",
       " requirements, focusing on mortality and auto-adjudication (8%). Develop advanced models utilizing SparkBeyond feature engineering to predict mortality or longevity and the risk evaluation of life events associated (8%). Develop auto-adjudication schemes to speed processes in the underwriting of life insurance (8%). Develop advanced predictive models to achieve business efficiency using model algorithm in areas other than mortality or longevity, auto-adjudication, and life event risk (6%). Develop and deploy analytical methods to deliver cutting-edge approaches through first-of-a-kind solutions to transform decision-making processes surrounding mortality and auto-adjudication (10%). Lead the delivery of mortality or longevity models, auto-adjudication, risk evaluation of life events analytics projects (35%). Develop associate data scientist talent and advise on current project work (10%). Lead awareness and advisory services in projects utilizing new technology (5%). Assist in the determination of necessary technology to transform MetLife (10%).\n",
       " ,\n",
       " requirements; document and program to create the analysis datasets.\n",
       " Research clinical trials in clinicaltrials.gov, PubMed and other references to identify studies that meet client requirements.\n",
       " Participate in reviewing standardizations across hundreds of trials from multiple sponsors and make recommendations.\n",
       " Document and summarize analysis results for statisticians, data engineers, and project managers.\n",
       " Perform ad hoc queries on raw data for selected baseline characteristics\n",
       " Perform ad hoc quality analysis on clinical trials data\n",
       " Assists junior team members on ADaM development related activities and deliveries\n",
       " Coordinates with vendors for ADaM development and oversees their deliverables\n",
       " Your Education & Experience:\n",
       " Bachelor's or Master’s degree in life science or a quantitative discipline required.\n",
       " Minimum 7 to 10 years experience working with EDC data from variety of clinical trials including hands-on work in, and deep knowledge of, all of the following:\n",
       " Analysis of subject-level clinical trials data\n",
       " Writing SDTM specifications and programming\n",
       " Writing/reviewing ADaM specifications and programming including efficacy domains\n",
       " Ability to read protocols, SAP, explore clinical datasets and make sophisticated judgments about meaning of, and patterns in, data.\n",
       " Requires strong skills in SAS base and macros.\n",
       " Good documentation, communication, analytical and interpersonal skills.\n",
       " Prefer having SQL and Python programming experience\n",
       " Prefer experience in oncology trials\n",
       " Prefer experience with pooled clinical trials data and/or Integrated analysis (ISS, ISE etc)\n",
       " Prefer experience with clinical data from multiple sponsors (eg: consulting to multiple sponsors or working at multiple pharmaceutical companies).\n",
       " ,\n",
       " Requirements:\n",
       " EDUCATION AND EXPERIENCE:\n",
       " ,\n",
       " requirements based on business needs\n",
       " Identifies critical and emerging technologies that will support and extend quantitative analytic capabilities\n",
       " Collaborates with business subject matter experts to select relevant sources of information\n",
       " Develops expertise with multiple machine learning algorithms and data science techniques, such as exploratory data analysis and predictive modeling, graph theory, recommender systems, text analytics and validation\n",
       " Develops expertise with Healthfirst datasets, data repositories, and data movement processes\n",
       " Assists on projects/requests and may lead specific tasks within the project scope\n",
       " Prepares and manipulates data for use in development of statistical models\n",
       " Other duties as assigned\n",
       " Minimum Qualifications:\n",
       " Bachelor's Degree\n",
       " Preferred Qualifications:\n",
       " Master’s degree in Computer Science or Statistics\n",
       " Familiarity with major cloud platforms such as AWS and Azure\n",
       " Healthcare Industry Experience\n",
       " Minimum Qualifications:\n",
       " Bachelor's Degree\n",
       " Preferred Qualifications:\n",
       " Master’s degree in Computer Science or Statistics\n",
       " Familiarity with major cloud platforms such as AWS and Azure\n",
       " Healthcare Industry Experience\n",
       " WE ARE AN EQUAL OPPORTUNITY EMPLOYER. Applicants and employees are considered for positions and are evaluated without regard to mental or physical disability, race, color, religion, gender, national origin, age, genetic information, military or veteran status, sexual orientation, marital status or any other protected Federal, State/Province or Local status unrelated to the performance of the work involved.\n",
       " If you have a disability under the Americans with Disability Act or a similar law, and want a reasonable accommodation to assist with your job search or application for employment, please contact us by sending an email to careers@Healthfirst.org or calling 212-519-1798 . In your email please include a description of the accommodation you are requesting and a description of the position for which you are applying. Only reasonable accommodation requests related to applying for a position within Healthfirst Management Services will be reviewed at the e-mail address and phone number supplied. Thank you for considering a career with Healthfirst Management Services.\n",
       " \n",
       " ,\n",
       " ideal candidate is a highly motivated problem-solver capable of applying big picture thinking with a passion for using data to assist our clients in making better investment decisions.\n",
       " ,\n",
       " requirement of the role, due to COVID-19, non-essential travel has been suspended until further notice.)\n",
       " ,\n",
       " ideal candidate will have a strong grasp of software development fundamentals, along with an interest in learning more about both new cutting-edge technologies and the Chemistry, Biology, and Physics problems that our software helps to solve.\n",
       " ,\n",
       " need to have a strong background in supervised learning techniques such as decision trees, random forests and logistics regressions, and unsupervised learning such as clustering, and dimensionality reduction.\n",
       " The Senior Data Scientist Consultant will also need to have a foundation in Machine Learning, statistical modeling and optimization such as gradient descent and variants. The Consultant will work alongside database developers Electrical Engineers and other IT professionals to understand the context of the project, to focus initially focusing on how to best establish an application architecture and subsequently recommending improvements that can support the application and database's scalability.\n",
       " The Data Scientist must have a strong background in scripting programming languages such as Python and statistical computing packages such as R. Must be familiar with open source platforms such as Hadoop, map-reduce and Hive and Pig. The Senior Data Scientist will work to test the application/DB components as per the test cases and ensure quality product with high system performance, reliability, and scalability.\n",
       " The Senior Data Analyst will need the ability to tell a story with the Data, and engage with Senior Management, to translate the data insights into decisions and actions. Must collaborate and guide the front end and backend application developers. Must understand business requirements and technical design and specifications and combine into a cohesive strategy.\n",
       " The Consultant must be passionate about data, and have the communication skills to propose, defend, and demonstrate new ideas, solutions, and modifications. The Consultant must provide support to production systems, troubleshoot production issues, perform root cause analysis and implements fixes. Must have a professional and positive approach, be self-motivated, and strong in building relationships, a true team-player. Must demonstrate strong oral and written communication skills.\n",
       " This is an hourly position with opportunity for overtime.\n",
       "  **All Candidates Must be Authorized to Legally Work in the US Without Sponsorship**\n",
       " Mandatory Education/Experience Qualifications:\n",
       " Education:\n",
       " Multiple Data Science Certifications AND 10 Years of relevant work experience OR\n",
       " Associate's Degree in Computer Science or related technical field AND 7 Years of relevant work experience OR\n",
       " Bachelor's Degree in Computer Science or related technical field AND 5 Years relevant work experience\n",
       " Preferred Education/Experience:\n",
       " Master's Degree in computer science or related technical field\n",
       " ,\n",
       " requirements you will effectively apply the Ayasdi integration process to meet customer needs within the realm and scope of the Statement of Work (SOW). You will work on all aspects of the implementation process including participation in the sales process in developing scope of work and requirements gathering, managing the client relationship, project management, and coordinating technical resources.\n",
       " ,\n",
       " Nice to have:\n",
       " ,\n",
       " Requirements:\n",
       " Deep technical expertise in Data Science, Product and Business Analysis or related fields.\n",
       " Recognized leader with over 10 years of successful Data Science and/or analytical team management in dynamic start up growth environments (ideally tech / media companies)\n",
       " You have the ability to instill a user-focused attitude within the data science organization, making sure we deeply understand our users, experiment and validate hypotheses before building\n",
       " Executive-level presence and decision making experience\n",
       " Experience balancing the demands and expectations of a broad and diverse set of partners, and have worked collaboratively at multiple levels of the organization to get things done\n",
       " Strong recruiting and people management skills, as well as experience mentoring teams and managers to high performance\n",
       " Ability to articulate a compelling vision for the future of data science, the trends within Medium’s user model, and the skills to guide the team to execute on this vision\n",
       " Expert-level communication and collaboration skills; you model behavior by leading by example through and resolving inter-team conflict\n",
       " Lead within a lean, highly effective organization, making strategic trade-offs, and prioritize effectively\n",
       " Interested? We would love to hear from you.\n",
       " ,\n",
       " requirements.\n",
       " Knowledge of machine learning frameworks and tooling, for example Spark, PyTorch, SciKit learn, etc.\n",
       " Comfortable building prototypes from scratch\n",
       " Experience working with a microservice based architecture.\n",
       " Experience with AWS development.\n",
       " PhD or MS in Computer Science/Machine Learning or equivalent (PhD is preferred) and 8+ years experience is preferred.\n",
       " \n",
       " ,\n",
       " ideal candidate is someone who can work well within a highly collaborative environment, in close partnership with staff across these affiliated groups.\n",
       " ,\n",
       " Ideal candidates will be able to work cross functionally across multiple stakeholders, synthesize the science needs of our business partners, develop models to solve business needs, and implement solutions in production.\n",
       " ,\n",
       " requirements, provide analytical support, and communicate feedback.Presenting critical data in a format that is immediately useful to answer questions about the inputs and outputs of Forecasting systems and improving their performance.\n",
       " Amazon is an Equal Opportunity Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation.\n",
       " ,\n",
       " Requirements: Excellent knowledge of English, as well as writing, presentation, and communication skills. Fluency in other UN languages is an asset\n",
       " ,\n",
       " BASIC QUALIFICATIONS:\n",
       " job.Qualifications\n",
       " ,\n",
       " ideal candidate will have experience with and interest in collaborating with Software Engineers to deploy a reliable, customer-facing product. As our team is growing quickly, we’re keenly interested in candidates who understand how to design systems that scale and still know how to deliver results on a deadline when necessary.\n",
       " ,\n",
       " requirements to develop analytic capabilities, platforms, pipelines and metrics then using them to analyze trends and find root causes of forecast inaccuracyFormalizing assumptions about how demand forecasts are expected to behave, creating definitions of outliers, developing methods to systematically identify these outliers, and explaining why they are reasonable or identifying fixes for themUtilizing code (Python, R, Scala, SQL etc.) for analyzing data and building statistical and machine learning models and algorithms\n",
       " Amazon.com is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation\n",
       " ,\n",
       " Requirements\n",
       " The successful candidate must not be subject to employment restrictions from a former employer (such as a non-compete) that would prevent the candidate from performing the job responsibilities as described.\n",
       " Disclaimers\n",
       " Guidehouse is an Equal Employment Opportunity / Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, national origin, ancestry, citizenship status, military status, protected veteran status, religion, creed, physical or mental disability, medical condition, marital status, sex, sexual orientation, gender, gender identity or expression, age, genetic information, or any other basis protected by law, ordinance, or regulation.\n",
       " ,\n",
       " ideal candidate will be skilled in developing complex ingestion and transformation processes with an emphasis on reliability and performance. In collaboration with other data engineers, database administrators, and developers, the candidate will empower the team of analysts and data scientists to deliver data driven insights and applications to company stakeholders.\n",
       " ,\n",
       " requirements for internally and externally developed software in a clinical, allied health, non-allied health, behavioral health, information technology, information services, business, analytics or related area; or, one year of experience in a relevant clinical and/or healthcare administration role/function; or\n",
       " 2. A Baccalaureate Degree from an accredited college or university and five years of experience as described above; or\n",
       " 3. A satisfactory combination of education, training, and experience.\n",
       " 4. Specialty certification(s) issued by a national commercially available program, state, professional society, academic or technical institution in an area(s) listed above, may be credited on a month-to-month basis toward the required work experience for a total of one year.\n",
       " ,\n",
       " requirements from our portfolio companies; forming creative data driven hypotheses to solve these needs; using a range of statistical and machine learning methods using a range of different data sources in order to build models that prove or disprove these hypotheses; communicate findings to management and work with software engineers to craft solutions based on the models you build.\n",
       " ,\n",
       " ideal candidate will have an engineering or data science background they can draw upon to evaluate the technical operations of TSV portfolio companies and identify opportunities to improve them, either by advising them directly or by partnering them with relevant people and resources from the broader Two Sigma organization. The Program Manager will hold regular check-in meetings with the technical leaders of TSV’s portfolio companies and will serve as the project manager for all engagements with portfolio companies that involve providing engineering and data science support. In addition, the Program Manager will be responsible for identifying common challenges across the portfolio and designing and implementing offerings that scale to multiple companies.\n",
       " ,\n",
       " ideal candidate for this position has the adaptability to keep up with changing requirements and timelines and can communicate effectively across various teams and departments. They have the maturity, flexibility, and curiosity to wear many hats and take on additional responsibility.\n",
       " ,\n",
       " ideal candidate believes in the creativity of data. Having a curious-minded approach to research, problem solving and supporting multiple client work streams will lead to success on this team and in this agency.\n",
       " ,\n",
       " REQUIREMENTS\n",
       " Preferred Experience:\n",
       " 4+ years of relevant work experience in or across data analytics, management consulting, or product management\n",
       " A year or more in healthcare, preferably at a healthcare provider or health system\n",
       " BS in Mathematics, Economics , Finance, or another business related discipline. Advanced business or analytical degree is a plus\n",
       " ,\n",
       " requirements, functional design, process design (including scenario design, flow mapping), prototyping, testing, training, defining support procedures.\n",
       " Formulate planning, budgeting, forecasting and reporting strategies.\n",
       " Manage full life cycle implementations.\n",
       " Develop statements of work and/or client proposals.\n",
       " Identify business opportunities to increase usability and profitability of information architecture.\n",
       " Experience with program leadership, governance and change enablement.\n",
       " Develop and manage vendor relationships.\n",
       " Lead workshops for client education.\n",
       " Manage resources and budget on client projects.\n",
       " Assist and drive the team by providing oversight.\n",
       " The team\n",
       " Analytics & Cognitive\n",
       " In this age of disruption, organizations need to navigate the future with confidence, embracing decision making with clear, data-driven choices that deliver enterprise value in a dynamic business environment.\n",
       " ,\n",
       " requirements and outcomes\n",
       " 2. Analyze ecosystem metrics across linear, TVE and DTC, producing automated dashboards for media partners while identifying larger consumer shifts and business opportunities\n",
       " 3. Interpret paid and owned media performance across platforms and channels to define audience opportunities, media mix model strategies and multi-touch methodologies\n",
       " ,\n",
       " requirement.\n",
       " Some experience with scripting languages such as Python or Ruby, or a desire and aptitude to learn.\n",
       " Be nice, and value collaboration.\n",
       " Working at Relevant\n",
       " ,\n",
       " ideal candidate for this position has the capacity, knowledge, and experience to develop a holistic understanding of our autonomous system and operations. They can comfortably lead and mentor junior engineers, project/program managers, and a traditional technical communications team. They are comfortable adapting to changing requirements and timelines and have the ability to communicate effectively throughout all levels of the company.\n",
       " ,\n",
       " ideal candidate has strong statistical reasoning skills and experience with operations-intensive companies\n",
       " ,\n",
       " Requirements:\n",
       " 3+ years of industry experience using machine learning to solve real-world problems with large datasets (multi-terabyte+, 100MM+ daily transaction volumes)\n",
       " A graduate degree in artificial intelligence, machine learning or equivalent experience\n",
       " Fluent in one or more object oriented languages like Java, Scala, C#, C++\n",
       " Knowledgeable of core CS concepts such as data structures and algorithms\n",
       " Experience with standard software engineering practices (e.g. unit testing, code reviews, design documentation)\n",
       " Extensive experience building scalable machine learning systems and data-driven products working with cross functional teams\n",
       " Experience with handling large scale data using MapReduce-based architectures such as Scalding, Pig, Hive\n",
       " Experience with adtech ecosystem is a plus\n",
       " ,\n",
       " requirements: (a) be enrolled in a graduate school programme (second university degree or equivalent, or higher); or (b) be enrolled in the final academic year of a first university degree programme (minimum Bachelor's level or equivalent); or (c) have graduated with a university degree (as defined above) and, if selected, must commence the internship within a one year period of graduation;\n",
       " ,\n",
       " ideal candidate must be willing to effectively project-manage and prioritize across multiple tasks, exhibit strong problem-solving skills and be ready to jump into a fast-paced, dynamic and fun environment.\n",
       " ,\n",
       " Requirements:\n",
       " Posses a Ph.D. (strongly preferred) or Master’s Degree in operations research, applied statistics, data mining, machine learning, physics or a related quantitative discipline.\n",
       " Deep understanding of statistical and predictive modeling concepts, machine-learning approaches, clustering and classification techniques, and recommendation and optimization algorithms.\n",
       " 3+ years of experience delivering world-class data science outcomes, the data scientist will solve complex analytical problems using quantitative approaches with their unique blend of analytical, mathematical and technical skills.\n",
       " Passionate about asking and answering questions in large datasets, and will be to communicate that passion to product managers and engineers.\n",
       " Keen desire to solve business problems, and live to find patterns and insights within structured and unstructured data.\n",
       " Propose analytics strategies and solutions that challenge and expand the thinking of everyone around you.\n",
       " Expert in analyzing large, complex, multi-dimensional datasets with a variety of tools.\n",
       " Expert in the use of statistical analysis environments such as R, MATLAB, SPSS or SAS.\n",
       " Experienced with BI tools.\n",
       " Experience with relational databases as you are with Hadoop-based data mining frameworks.\n",
       " Experience with SQL, Python, Java and C/C++.\n",
       " Education:\n",
       " ,\n",
       " requirements for a set of dependent data products derived from a large portfolio of integrated data feeds\n",
       " Contribute to data sourcing strategy across multiple industry data verticals supporting our prediction efforts\n",
       " Generate a series of economic insights research reports relating trends in our indicators & predictions to investment themes\n",
       " ,\n",
       " Requirements\n",
       " Experience in design and implementation of Machine Learning/AI/Deep Learning solutions.\n",
       " At least 5 years of working experience managing data science project life cycle and actively involved in all the phases of project life cycle including data ingestion, data engineering, features engineering, statistical modelling (decision trees, regression models, neural networks, SVM, clustering,..)\n",
       " Developing models in Machine learning with NLP, Neural Networks, Recommendation engines, Reinforcement Learning,\n",
       " Exposure to AI and analytics platforms, such as Azure ML Studio, Google AI Engine, etc.\n",
       " Work experience on structured/unstructured data, SQL and NoSQL big data storage solutions, cloud computing, REST API, and cloud microservices\n",
       " Experience in building solutions such as computer vision, NLP, time series forecasting, general prediction models\n",
       " Analyse large, complex, multi-dimensional datasets with a variety of open source tools\n",
       " Implement Anomaly Detection and Optimization Techniques\n",
       " ,\n",
       " ideal candidate is an experienced full stack engineer who enjoys building end-to-end systems and building them from the ground up. The candidate will collaborate with our software developers, data engineers, and data scientists on projects ranging from ad hoc research to deploying and monitoring production machine learning models.\n",
       " ,\n",
       " requirements gathering to client work executions\n",
       " \n",
       " ,\n",
       " ideal candidate will be:\n",
       " Well rounded team player - you understand that we succeed or fail as a team. You are always ready to step up beyond your core responsibilities and go the extra mile for the project and your team. You nimbly overcome barriers to deliver the best products more quickly than expected.\n",
       " A Perpetual Student – You seek knowledge and insight. You challenge yourself to turn moments into master’s classes. Whether closing a gap, developing a new skill, or staying ahead of your industry, you revel in the joy of learning and growing.A Skilled Communicator – You excel when interacting with business and technical partners whether you are chatting, sending a written message, or conducting a presentation.A Trusted Advisor – You work closely with stakeholders to define key business needs and deliver on commitments. You enable effective decision making by retrieving and aggregating data from multiple sources and compiling it into a digestible and actionable format.An Inventor at Heart – You innovate on behalf of your customer by proactively implementing improvements, enhancements, and customizations. Your customers marvel at your creative solutions to challenges they had not yet identified.A Fearless Explorer – You are drawn to take on the hardest problems, navigate ambiguity, and battle skepticism. You never settle, even in the face of overwhelming obstacles.\n",
       " Your responsibilities will include:\n",
       " Build and develop the cross-functional Fraud Prevention team in a new location.Build strong partnerships with internal stakeholders globally.Combine deep technical skills and business savvy to interface and drive change or deliver solutions to all levels internally and externally including our advertiser’s organizations (including Dir/VP/CMOs, tech and non-tech). Track record in building consensus among discordant views.Work and Deliver end-to-end projects independently including ability to lead teams to quickly adapt to changing priorities and generate innovative solutions in an extremely fast-paced environment.Be self sufficient in data analysis (such as R, Python and Matlab) and big data technologies (such as Map Reduce, Spark and Hive).Familiarity with various data visualization tools such as Tableau, Qlickview and QuickSight.Developer teams to produce successful Data Science solutions that deliver significant benefit to business\n",
       " ,\n",
       " Basic Qualifications:\n",
       " Have experience in building highly concurrent distributed systems for online services at scale6+ years of work experience in software developmentHave project Lead experienceHave knowledge of Object-Oriented Design, data structures, algorithm design, and complexity analysisHave strong proficiency in, at least, one modern programming language such as C, C++, C#, Java, Python, Scala or PerlBachelor’s Degree or higher in Computer Science or related fieldExperience mentoring junior engineers\n",
       " ,\n",
       " ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The candidate will collaborate with our software developers, database architects, and data scientists on projects ranging from ad hoc research to deploying and monitoring production machine learning models.\n",
       " ,\n",
       " requirements, lead functional and technical design discussions and work with delivery and engineering teams to deliver the project.\n",
       " Work hand in hand with data science team to identify new approaches and algorithms to solve customer experience challenges\n",
       " Monitor the health of projects at all times along with the associated risks and implications to timelines; lead the resolution of cross-functional issues\n",
       " Provide business and technical expertise on how to identify and apply ML solutions to the consumer experience (e.g. profiling, personalization, recommendations, search)\n",
       " Evangelize and educate broader CNN digital teams on AI and related data technologies in order to increase organizational awareness and knowledge\n",
       " The Essentials\n",
       " 5+ years consumer product management experience, preferably developing user discovery or personalization features using machine learning solutions\n",
       " 3+ years of experience in a technical product or data science/advanced analyst role\n",
       " Proven track record of roadmap execution partnering with data science teams\n",
       " Passionate data evangelist with ability to inspire others to learn and apply ML solutions\n",
       " Ability to lead through influencing in a matrixed organization (i.e. people follow without having hierarchal direct control/reports)\n",
       " Led one or more projects to implement a recommendation engine or other related ML based discovery or personalization feature\n",
       " Strong academic background in a quantitative field such as mathematics, physics, computer science, engineering, statistics (advanced degrees a plus)\n",
       " Demonstrated ability to manipulate, analyze, and interpret large amounts of data, organize findings, and translate into actionable insights\n",
       " Quick learner, with the ability to work independently in a matrixed environment; adaptability and a strong self-teaching ethic are highly valued\n",
       " Experienced in making hard data-informed decisions (A/B testing and experimentation, user testing, data analysis, defining metrics)\n",
       " Good instincts matched with deep analytical and systems-level thinking to focus on the things that matter most and build long-lasting platform products\n",
       " Highly effective communicator with proven ability to influence and motivate cross-functional teams\n",
       " Comfortable in a rapidly changing landscape while also good at sorting out ambiguity\n",
       " Proven know-how to inspire, motivate and support a team to get things done\n",
       " ,\n",
       " Requirements:\n",
       " Bachelor’s degree in an analytical field (e.g., computer science, business information systems) required; year of work experience may be substituted\n",
       " 8+ years of experience as a Data Analyst\n",
       " Experience in writing complex SQL queries and scripts. Experience working on MYSQL / SQL Server is a plus\n",
       " Experience with cloud databases is a plus\n",
       " Experience with other specialty stores, like document or graph data stores is a plus.\n",
       " Data Profiling and Data Validation skills. Data Governance is a plus\n",
       " Experience in an Agile development methodology\n",
       " Experience with multi-dimensional data models\n",
       " Knowledge and familiarity with database security concepts and standard methodologies\n",
       " Experience with clinical or healthcare data a plus\n",
       " Deep understanding of data management best practices, including Analytics, SQL, data management, file management, reference data management, etc.\n",
       " Familiarity with Data Warehouse modeling concepts\n",
       " Ability to analyze and interpret data from variety of functional sources\n",
       " Produce ad hoc reports to answer business questions quickly and accurately\n",
       " Implement new processes: evaluate existing processes, and recommend optimal solutions and improvements\n",
       " Partner with business process owners and management on strategic initiatives\n",
       " Problem-solving using methodical and logical approach\n",
       " Research best business practices within and outside the organization to establish benchmark data\n",
       " Excellent communication skills, both written and oral- comfortable recommending and presenting solutions to senior managers\n",
       " Problem-solving and critical thinking skills\n",
       " Ability and willingness to work in a team environment and adopt a culture of ownership and initiative, and promote such within the team\n",
       " Ability to run small projects from inception to completion in multi-functional environment\n",
       " Dedicated, innovative, and creative in meeting client/customer needs. Always keeping a “Can do!” attitude\n",
       " Company Benefits:\n",
       " Very competitive salary & equity compensation.\n",
       " Excellent health, dental, vision coverage.\n",
       " 401k benefits with employer matching contribution; immediately vested.\n",
       " Awesome people to work with.\n",
       " Becoming a part of a movement in telemedicine and building something that matters.\n",
       " ,\n",
       " requirements as it relates to data assets\n",
       " Requirements:\n",
       " Master's degree completed by start date and 8+ years of business analytics, statistics, data mining, applied mathematics, engineering, computer science or related field experience\n",
       " ,\n",
       " Requirements:\n",
       " BA./S. CompSci or CompEng or comparable Engineering degree.\n",
       " 3 years of applied machine learning experience.\n",
       " Fluency in Python.\n",
       " Expertise in at least one modern ML framework such as Keras, TensorFlow, or PyTorch.\n",
       " Why Ocrolus?\n",
       " We’re a seasoned team of engineers and operators, that understand the value of clean high quality data gathering. You will never feel alone in the trenches during the course of your work.\n",
       " We have a very mature data gathering operation already in place. Disseminating training materials and collection methodology is painless.\n",
       " There is a high degree of variety in the problems that are available to tackle.\n",
       " Our size and culture means a high degree of personal autonomy inherent in the day to day.\n",
       " Flexibility. We’re not married to an approach, framework, or provider. We’re willing to change when provided with compelling data.\n",
       " \n",
       " ,\n",
       " ideal candidate will have previous Data Modeling experience. Strong preference will be given to candidates with an actuarial background in the property and casualty insurance space.\n",
       " ,\n",
       " Qualification Requirements :\n",
       " Selected candidates must be enrolled in a degree bearing program\n",
       " ,\n",
       " ideal candidate is a strong, creative and highly-motivated Scientist with hands-on experience in leading multiple research and engineering initiatives. You balance technical leadership with strong business judgment to make the right decisions about technology, tools, and methodologies. You excel in translating broader business objective into Machine Learning science formulations, research for potential solutions or invent new solutions for the objective. You strive for simplicity, demonstrate high judgment backed by sound statistical reasoning and robust machine learning models to deliver creative solutions. You do independent research and develop non-trivial Machine Learning solutions. You mentor and lead scientists and engineers, contribute to Amazon's Intellectual Property through patents and/or external publications.\n",
       " ,\n",
       " need to have:\n",
       " \n",
       "  ,\n",
       " requirements, constraints, third party, and technology\n",
       " Execute predictive modeling lifecycle from ideation and hypotheses generation, data extraction and exploration, model building and validation, results communication, and production to optimize go-to-market strategy.\n",
       " Understand new data sources and process pipelines, and catalog/document them. Display drive and curiosity to understand the business process to its core. Network with domain experts to better understand the business mechanics that generated the data.\n",
       " Have deep knowledge of fundamentals of Predictive modeling, data mining and machine learning, and extensive experience applying these methods to real world problems.\n",
       " Have extensive experience in model testing, such as cross-validation and A/B testing.\n",
       " Promote collaboration with other analytics / data science teams within the COEs and Organization. Train business teams on basic data science principles and techniques.\n",
       " Keep abreast of the latest developments in Data Science field by continuous learning and proactively champion promising new methods relevant to the problems at hand.\n",
       " ,\n",
       " ideal candidate understands human behavior and knows what to look for in the data.\n",
       " Hours, Location & Info\n",
       " Primary Location - New York\n",
       " Schedule - Full-time\n",
       " Job Type - Standard\n",
       " Shift - Day Job\n",
       " Travel - up to 50%\n",
       " Responsabilities\n",
       " Analyze, visualize, and model job search related data\n",
       " Build and implement machine learning models to make timely decisions\n",
       " Have access to unparalleled resources to grow and develop both personally and professionally\n",
       " Qualifications\n",
       " Ph.D. or M.S. in a quantitative field such as Computer Science, Operations Research, Statistics, Econometrics or Mathematics\n",
       " Expertise in machine learning and statistical modeling\n",
       " 2+ years professional or research experience in data science\n",
       " Passion to answer Product/Engineering questions with data\n",
       " Technical skills\n",
       " Have full stack experience in data collection, aggregation, analysis, visualization, productization, and monitoring of data science products\n",
       " Can do small data modeling work: R, Python, Julia, Octave\n",
       " Can do big data modeling work: Hadoop, Pig, Scala, Spark\n",
       " Can fish for data: SQL, Pandas, MongoDB\n",
       " Can deploy data science solutions: Java, Python, C++\n",
       " Can communicate concisely and persuasively with engineers and product managers\n",
       " ,\n",
       " requirements\n",
       " Machine Learning model building, training, validation and tuning\n",
       " Explore & Visualize the data to gain better insights and identifying differences in data distribution to address the model performance challenges\n",
       " Researching, evaluating and exploring various ML algorithms\n",
       " Validating model inputs/ outputs & accuracy\n",
       " Deploying models to production\n",
       " Working with India and U.S.-based teams to deliver models\n",
       " ,\n",
       " requirements:\n",
       " You have a track record of applying machine learning techniques in addressing real-world problems\n",
       " You have focused expertise in one of the following fields: natural language processing, reinforcement learning, deep learning, or computer vision.\n",
       " You have solid software development skills. You are comfortable with using git, Linux environments, dockers, and other tools for writing robust, production-ready code.\n",
       " ,\n",
       " requirements and works side by side with domain experts in business groups to frame the business problem, integrate the needed data, and determine the best way to provision that data on demand.Maintains, upgrades or enhances existing user systems; troubleshoots and provides continuing user support, assists integrating diverse data sets for data management and modeling.\n",
       " Develops and drives automation by working with analytical tools (and alongside business and analysts) to automate repeatable and error-prone data integration and data preparation flows.Organizes and performs unit and integrated testing, designing and utilizing test bases; assists users in acceptance testing.Develops training and educates subject matter experts and the business on data understanding and use, as well as IT resources on new data integration and data ingestion techniques.Develops disaster recovery plans and ensures appropriate planning and training of those responsible.Researches and collaborates across business and IT to promote better understanding of data and analytics.Facilitates communications between OIM and its clients for good client relations. Serves as coordinator in the development of Service Level Agreements (SLAs) between the client and OIM, for either specific IT services or general technology support, including any charge back mechanisms.Handles all aspects of contract administration including establishment of service level agreements with vendors and chargeback policy for users.Provides guidance to, and may supervise, new/junior staff, consultants, etc.\n",
       " Competencies\n",
       " • Professionalism: Knowledge of information technology/information management related to data management and data governance, particularly in data analysis, managing large data sets within a cloud environment and programming. Knowledge of several high-level programming languages and significant exposure to and demonstrated proficiency in all aspects of programming and analysis, including data warehouse cloud environments, relational systems, scripting and query languages, document design and management. Strong analytical and problem-solving skills, to include proficiency in the development and implementation of data management systems of moderate size/complexity. Knowledge of transforming and normalizing data utilizing streamlined tagging features within a data model cloud environment. Shows pride in work and in achievements; demonstrates professional competence and mastery of subject matter; is conscientious and efficient in meeting commitments, observing deadlines and achieving results; is motivated by professional rather than personal concerns; shows persistence when faced with difficult problems or challenges; remains calm in stressful situations. Takes responsibility for incorporating gender perspectives and ensuring the equal participation of women and men in all areas of work.\n",
       " Communication: Speaks and writes clearly and effectively; listens to others, correctly interprets messages from others and responds appropriately; asks questions to clarify and exhibits interest in having two-way communication; tailors language, tone, style and format to match audience; demonstrates openness in sharing information and keeping people informed.Teamwork: Works collaboratively with colleagues to achieve organizational goals; solicits input by genuinely valuing others’ ideas and expertise; is willing to learn from others; places team agenda before personal agenda; supports and acts in accordance with final group decision, even when such decisions may not entirely reflect own position; shares credit for team accomplishments and accepts joint responsibility for team shortcomings.\n",
       " Education\n",
       " Advanced university degree (Master’s degree or equivalent) in computer science, information systems, mathematics, statistics or related field. A first-level university degree in combination with two additional years of qualifying experience may be accepted in lieu of the advanced university degree. A financial analytics certification, such as FRM, CAIA, CFA or equivalent is desirable. Familiarity with Machine learning, artificial intelligence and neural network concepts is desirable.\n",
       " Work Experience\n",
       " A minimum of five years of progressively responsible experience in planning, design, development, implementation and maintenance of financial computer information systems or related area is required.\n",
       " Experience with data management solutions supporting the investment management cycle, in fixed income, equity, private equity and derivative asset classes, is required.\n",
       " At least three years of experience programming (utilizing a combination of Python, SQL, R Studio, and Tableau/Power BI) to manage large data sets, within a financial data warehouse cloud environment (Oracle, Microsoft Data server and Bloomberg CDE) is required.\n",
       " Experience with transforming and normalizing data utilizing streamlined tagging features within a data model cloud environment and managing secure feeds and API’s is desirable.\n",
       " Languages\n",
       " English and French are the working languages of the UN Secretariat. For this position, fluency in English is required. Knowledge of another UN official language is an advantage.\n",
       " Assessment\n",
       " Evaluation of qualified candidates may include an assessment exercise which may be followed by competency-based interview.\n",
       " Special Notice\n",
       " • Staff members are subject to the authority of the Secretary-General and to assignment by him or her. In this context, all staff are expected to move periodically to new functions in their careers in accordance with established rules and procedures.\n",
       " \n",
       " ,\n",
       " Ideal candidates will be able to work cross functionally across multiple stakeholders, synthesize the science needs of our business partners, develop models to solve business needs, and implement solutions in production. In addition to being a strongly motivated IC, you will also be responsible for mentoring junior scientists and guiding them to deliver high impacting products and services for Amazon customers and sellers.\n",
       " ,\n",
       " requirements to other team members and project stakeholders.\n",
       " \n",
       "  ,\n",
       " Requirements:\n",
       " We look for people that are smart, humble, motivated and who are always looking to improve. Ideally, you’ll have:\n",
       " ,\n",
       " requirement development, estimation, solution design and implementation\n",
       " Strong experience in the management of risks, issues and dependencies\n",
       " Industry recognised Project Management certifications such as Prince II, PMI, PMP\n",
       " Experience in delivering to a contract and able to hold commercial conversations with internal and external stakeholders\n",
       " Excellent communication skills with experience including stakeholder management, commercial negotiation, business writing and delivery of presentations\n",
       " Background experience in a technical discipline such as software development, data warehouse implementations or data science\n",
       " Exposure to delivering cloud based data solutions, preferably Microsoft Azure\n",
       " Experience in the delivery of advanced analytics / Business Intelligence projects\n",
       " Experience managing technology migration\n",
       " Strong education to degree level\n",
       " Additional Information:\n",
       " ,\n",
       " requirements\n",
       " Balancing best of breed technical implementation with the commercial / business schedule and work within budget imperatives\n",
       " Stakeholder engagement and influencing\n",
       " Strong technical architectural and design skills\n",
       " ,\n",
       " ideal candidate will have extensive experience in Science work, business analytics and have the aptitude to incorporate new approaches and methodologies while dealing with ambiguities in sourcing processes. Excellent business and communication skills are a must to develop and define key business questions and to build data sets that answer those questions. You should have a demonstrated ability to think strategically and analytically about business, product, and technical challenges. Further, you must have the ability to build and communicate compelling value propositions, and work across the organization to achieve consensus. This role requires a strong passion for customers, a high level of comfort navigating ambiguity, and a keen sense of ownership and drive to deliver results.\n",
       " ,\n",
       " requirements from the relevant stakeholders across the business\n",
       " Participate in the team activities (agile ceremonies, journal club, engineering whiteboard sessions etc)\n",
       " Requirements\n",
       " Masters degree or Ph.D. in computer science, maths, statistics, economics or related disciplines\n",
       " Solid experience in Data Science/Machine Learning\n",
       " Proven ability to design machine learning solutions to solve business problems using best practices (data cleansing, model development)\n",
       " Ability to contribute ideas to feed the product roadmap\n",
       " Experience writing production-grade code\n",
       " Knowledge of ways to optimise algorithms and their limitations\n",
       " Ability to communicate complex problems to technical and non-technical audiences\n",
       " Ability to research machine learning techniques and develop prototype\n",
       " Passion for learning new skills and staying up-to-date with ML algorithms\n",
       " Be a team player in our collaborative and cross-functional environment\n",
       " \n",
       " ,\n",
       " Requirements:\n",
       " 5+ years with demonstrated experience in similar roles;\n",
       " ,\n",
       " ideal candidate is an enthusiastic and flexible team player with a solid technical skill set and strong analytical mind, is an excellent communicator, and thrives in a fast-paced commercial environment.\n",
       " \n",
       " ,\n",
       " requirements\n",
       " Working with data scientists to understand and interpret complex data-sets\n",
       " Working with project managers and support teams to meet delivery targets\n",
       " Mentoring and coaching more junior members of the development team\n",
       " Assisting with the provision of task breakdown and estimates\n",
       " Quickly becoming knowledgeable on Finance and Risk Functions in Card, Loan, Mortgage products.\n",
       " Utilize in-depth knowledge and skills across multiple Applications Development areas to provide technical oversight across systems and applications\n",
       " Review and analyze proposed technical solutions for projects\n",
       " Contribute to formulation of strategies for applications development and other functional areas\n",
       " Develop comprehensive knowledge of how areas of business integrate to accomplish business goals\n",
       " Provide evaluative judgment based on analysis of factual data in complicated and unique situations\n",
       " Impact the Applications Development area through monitoring delivery of end results, participate in budget management, and handling day-to-day staff management issues, including resource management and allocation of work within the team/project\n",
       " Ensure essential procedures are followed and contribute to defining standards negotiating with external parties when necessary\n",
       " Appropriately assess risk when business decisions are made, demonstrating particular consideration for the firm's reputation and safeguarding Citigroup, its clients and assets, by driving compliance with applicable laws, rules and regulations, adhering to Policy, applying sound ethical judgment regarding personal behaviour, conduct and business practices, and escalating, managing and reporting control issues with transparency, as well as effectively supervise the activity of others and create accountability with those who fail to maintain these standards.\n",
       " Qualifications:\n",
       " 6-10 years of relevant experience preferably in the Financial Service industry\n",
       " Experience as senior level in an Applications Development role\n",
       " Experience in architecting technical solutions\n",
       " Expertise in evaluation of software tools and provide recommendations.\n",
       " Demonstrated leadership skills\n",
       " Strong knowledge of industry practices and standards\n",
       " Consistently demonstrates clear and concise written and verbal communication\n",
       " Knowledge/Experience:\n",
       " Confident engineer with an authoritative knowledge of Java or other OO language\n",
       " Comfortable working with large data volumes and be able to demonstrate a firm understanding of logical data structures and analysis techniques\n",
       " Capable of assisting with the design of solutions and mentoring other developers within the same team\n",
       " Experienced with Linux/Unix platform\n",
       " Experienced with automated build and test processes\n",
       " Able to demonstrate an expertise in identifying and resolving data quality issues – in data sets at rest and in flight\n",
       " Familiar with the financial services industry and/or regulatory environments\n",
       " Experience in data governance tools would be an added advantage.\n",
       " Skills & Technologies:\n",
       " Java, Scala, Spark and related programming technologies\n",
       " Hadoop , AWS, Snowflake\n",
       " Python, related scripting technologies\n",
       " ETl/SQL related technologies\n",
       " Linux/Unix\n",
       " Kafka or other equivalent messaging services\n",
       " Development Value:\n",
       " Hands-on design and development experience on a production implementation of Hadoop with massive data volumes\n",
       " Opportunities to demonstrate leadership ability as you mentor and guide junior team members\n",
       " Potential to contribute to projects involving complex feature-based data algorithms\n",
       " Exposure to data science, Finance & Risk functions in a dynamic and challenging industry with regular close collaboration with our Data Governance team\n",
       " Qualifications:\n",
       " A graduate Engineer holding degree in any of the Engineering streams. Exceptional candidates who do not meet these criteria may be considered for the role provided they have the necessary skills and experience.\n",
       " Competencies:\n",
       " Adept written and verbal communicator\n",
       " Highly adaptable and be willing to mentor and train more junior team members\n",
       " Organized and prepared to manage multiple parallel pieces of work\n",
       " Prior experience working with remote teams\n",
       " ,\n",
       " Requirements\n",
       " Minimum 12-18 months experience in a commercial Data Science role\n",
       " Solid understanding of standard NLP models and experience implementing them in a practical business context.\n",
       " Sound understanding of machine learning and other Data Science principles.\n",
       " Good software engineering and coding skills in Python and preferably a second language, like C++\n",
       " Good knowledge of and experience with Numpy, Pandas, Scikit, NLTK, SpaCy, Scikit-learn, TensorFlow.'\n",
       " Developing and testing machine learning models using the latest data mining, statistical and machine learning techniques.\n",
       " Experience with putting machine learning models into production\n",
       " Good interpersonal ability and are able to communicate your findings to the wider business including executives and stakeholders.\n",
       " Let us know if:\n",
       " You’re an ‘evangelist’ for Data Science, you love spending time writing blogs, contributing to projects and attending events in the Data Science community (We do too!)\n",
       " You’re familiar with any other programming languages\n",
       " You have pursuits outside of work that you believe would be useful in our mission (No wrong answers!)\n",
       " ,\n",
       " Requirements:\n",
       " Required Skills & Qualifications:\n",
       " ,\n",
       " Requirements\n",
       " BSc, MSc, or PhD in Computer Science, Software Engineering, or equivalent experience in another quantitative field.\n",
       " Strong understanding of machine learning techniques and algorithms.\n",
       " Hands-on experience designing, building, and evaluating predictive models.\n",
       " Proficiency in Python preferred. Java/C++/Go/Ruby experience is also welcome.\n",
       " Bonus points for strong understanding of natural language processing techniques and algorithms.\n",
       " Bonus points for familiarity with TensorFlow, PyTorch, or Keras.\n",
       " Bonus points for experience building and deploying products that include a web-based user interface.\n",
       " Experience with data visualisation tools, such as D3.js, GGplot, etc.\n",
       " Proactive and excited to tackle open-ended problems independently.\n",
       " Statistical thinking.\n",
       " Strong attention to detail.\n",
       " ,\n",
       " requirements, based on your availability and on students' enrollment.\n",
       " ,\n",
       " YOU HAVE THESE ESSENTIALS?\n",
       " Bachelor’s, MS or PhD in computer science or related quantitative field.\n",
       " Expertise in using Python, C++, or other programming language\n",
       " Substantial experience with unstructured data sources, especially in areas such as spatiotemporal data, video/image, speech or text data\n",
       " Proficiency in, at least, one modern deep learning engine such as Tensorflow, PyTorch etc.\n",
       " Proven track record of innovation in creating novel algorithms and advancing the state of the art\n",
       " Passion for creating new technologies with high product impact within sport.\n",
       " \n",
       " ,\n",
       " requirements;\n",
       " Experience of cloud based and distributed data computing;\n",
       " Advanced coding skills in either Python or R and strong SQL skills (experience with PostgreSQL preferred);\n",
       " Comfortable on the command line in Windows and Linux environments;\n",
       " Knowledge of dynamic data visualisation (Javascript, Tableau, PowerBI);\n",
       " Knowledge of toolsets for Big Data analysis and when to use them (Hadoop, Apache Spark, MapD, RAPIDS AI, Dask);\n",
       " Commercial and business development experience.\n",
       " ,\n",
       " Requirements:\n",
       " Strong grasp of fundamentals: linear algebra, finite state machines, discrete and continuous optimization, supervised and unsupervised methods, generative and discriminative methods.\n",
       " Masters Degree in Computer Science or other relevant area.\n",
       " Expertise in one or more focus areas or their subfields: acoustic modelling, language modelling, audio-visual ASR, deep learning, graphical models, search, model compression, multi-task learning, etc.\n",
       " Extensive experience with deep learning frameworks Tensorflow, Caffe, PyTorch, Theano, etc (any of them)\n",
       " Excellent software engineering skills with working experience in Python, C++ or Rust (at least two).\n",
       " Proven track record of experience in relevant areas (significant industry experience and/or strong publication record at top venues like ICASSP, Interspeech, ICML, NeurlIPS, …)\n",
       " Extensive experience and understanding of speech frameworks (not the ability to run the recipes): Kaldi (both user and developer perspectives)\n",
       " Ability to quickly prototype state-of-the-art algorithms following recent literature developments.\n",
       " Ability to write high quality code\n",
       " \n",
       " ,\n",
       " Requirements\n",
       " Must haves:\n",
       " MSc or PhD in a STEM subject.\n",
       " Broad statistical knowledge including familiarity with Frequentist and Bayesian approaches, Causal Reasoning methods and Graphical Models.\n",
       " A demonstrated ability for developing innovative experimentation and analysis methods to infer insights from complex sets of data.\n",
       " Experience using Tableau or a similar BI tool for data visualisation and reporting.\n",
       " Advanced knowledge of SQL.\n",
       " Practical object-oriented programming experience in Python with knowledge of relevant packages including Pandas, Numpy, SciPy, Matplotlib, Scikit-learn, Statsmodels.\n",
       " Knowledge of at least one deep-learning framework (e.g. Tensorflow, Pytorch, Keras).\n",
       " Experience in writing clean and maintainable code for collaborative working and using code versioning tools.\n",
       " Excellent communicator - You are comfortable talking with programmers, marketers, surgeons, business leaders, and everyone in-between.\n",
       " Nice to haves:\n",
       " Experience working with tools used to handle big data.\n",
       " Experience working with clinical data sets.\n",
       " Knowledge of data compliance including GDPR, HIPAA and SOC2 compliance policies.\n",
       " Benefits\n",
       " We’re in a really lucky position to operate like a small team, with all of the benefits of a big company. Following our acquisition by Medtronic in February 2020, our benefits have had an impressive face lift. ; Our benefit package aims to help support your health, build wealth, grow in your career and share in the success of Digital Surgery and Medtronic. We are in the healthcare business and so in order to look after our people we provide:\n",
       " Private healthcare via AXA PPP - £100 excess\n",
       " 30 days’ holiday + 8 bank holidays\n",
       " Pension scheme (we double your personal contribution of up to 6%, by contributing 12%)\n",
       " Annual bonus scheme\n",
       " Annual meal allowance\n",
       " Life insurance (4 x annual salary*)\n",
       " Group Income Protection (67% of insured salary payable until pensionable age)\n",
       " Personal Accident Cover ( 3 x annual salary)\n",
       " Maternity - 20 weeks’ full pay + 15% returner’s bonus\n",
       " Paternity - 2 weeks’ full pay\n",
       " Employee Assistance Programme (support line for counselling, legal or financial advice)\n",
       " Not to mention all of the other bells and whistles such as free daily breakfast, employee recognition programs, cash for referring a friend and a whole host of other wellness benefits.\n",
       " As part of being Family Friendly, we encourage flexible working so you choose when you start and finish. Slack is one of our collaboration tools to help share information on what our teams are doing. You could even join the #coffee_buddies Slack channel to be matched up with someone for a face to face coffee.\n",
       " So what’s it like working at Digital Surgery?\n",
       " Part of the Medtronic family we benefit from a small company feel, within the world's leading medical device company. We have 130 people globally, with teams across the UK, US and Canada. The majority are based in our London HQ in Old Street. The company is made up of several teams covering Engineering, Product, Studio, Innovation, Marketing, HR, Operations, Finance and Sales. We care about our employees’ career and development, offering training internally as well as external courses and attending global conferences. We believe that helping you grow will help our company grow too.\n",
       " We have our Family Meeting on Friday afternoons with beer, wine and cold drinks - it’s a great chance to meet new joiners, share success stories and hear what’s been going on in the company that week.\n",
       " The Office\n",
       " We have a really open plan office, think New York loft style with break out areas, sofas as well as more formal meeting rooms when you need some privacy. Open kitchen full of healthy snacks, naughty biscuits, tea, Nespresso coffee machines - we also provide breakfast every day for everyone. Ooh, and dogs. Bring your dog to work if you want. One of our Co-Founders has 2 dogs, (named after batman characters) but they’re not on payroll !\n",
       " Our Values\n",
       " ,\n",
       " requirement development, estimation, solution design and implementation\n",
       " ,\n",
       " ideal candidate will have the following skills and experience -\n",
       " Python ExperienceData Science experienceR-SkillsSSASNHS Experience (Desirable not essential)\n",
       " If this position is of interest to you then please do get in touch with me at surj.kang@badenochandclark.com\n",
       " ,\n",
       " requirements, translate into data science problems and deliver high value outputs that show clear business value.\n",
       " Confidently make data tell a story through data presentation / visualisation tools and techniques.\n",
       " \n",
       " ,\n",
       " need to have:\n",
       "  experience in AI, NLP, ML, Optimization, or related fields\n",
       "  experience programming in C++, Python or Java, and\n",
       "  a master’s degree (PhD preferred) with industrial experience\n",
       " ,\n",
       " requirements into solutions\n",
       " Possession of outstanding oral and written communication skills\n",
       " Empathic listener and persuasive speaker\n",
       " Planning, managing and executing the delivery of projects\n",
       " Demonstrable understanding of data science concepts particularly where focused on a business need\n",
       " Demonstrable understanding of statistics\n",
       " Excellent understanding of machine learning techniques and algorithms\n",
       " Proficient understanding of data and business intelligence tools (Alteryx, VBA, SQL, Tableau etc.)\n",
       " Understanding of Agile delivery methods\n",
       " We recognise that it takes a team to deliver AI and so we seek individuals with demonstrable skills in a selection of the below for a number of roles\n",
       " Consulting experience in a strategy house, a Big 4 firm or an in-house strategy/consulting function of a data-driven company\n",
       " Industry Experience in one of our target sectors (e.g. Financial services)\n",
       " Strong academic excellence in a business and/or analytics related degree (e.g. Economics, Business Intelligence and Analytics)\n",
       " Exposure to cloud environments (Azure, GCP, AWS etc)\n",
       " Exposure to programming is desirable but not essential\n",
       " Exposure to business or financial modelling\n",
       " ,\n",
       " requirements gathering through data modelling and processing; carrying out segmentation or building predictive models; performing deep insight; presenting findings to stakeholders and building reusable data products through close collaboration with the relevant data engineering teams.\n",
       " You could have a background in data sciences, consulting, computer science, customer insight or elsewhere, but you will be passionate about turning large volumes of data into actionable insight and have the blend of commercial and technical skills required to do so.\n",
       " Primarily based in London, but a global role supporting colleagues in Europe, the US and Japan.\n",
       " Delivery of analytical activities, such as customer behaviour segmentation or predictive modelling\n",
       " Apply appropriate statistical techniques to answer product questions and understand consumer behaviour\n",
       " Design, build and support reusable data analysis structures within the technical environment; enabling self-service analytical capability for key technical stakeholders\n",
       " Work with Product Managers in DSO to gather requirements from stakeholders, prepare and present analysis results\n",
       " Communicate findings to other technical and non-technical teams\n",
       " Facilitate cultural adaption to enable a data driven business\n",
       " Act as an ambassador for DSO; maintain and enhance DSO reputation and profile within the business by building strong relationships with stakeholders and positively contributing to DSO delivering the highest possible value from people and technical resources available.\n",
       " Some global travel may be required, usually to Sony offices in California or Tokyo.\n",
       " ,\n",
       " Requirements:\n",
       " Strong record of academic achievement, likely to have studied MSc or PhD level in Computer Science, Engineering or Mathematics\n",
       " Ability to develop prototypes and PoCs with Python; experience with Keras, PyTorch, TensorFlow and Scikit-learn\n",
       " Good knowledge of Data Structures, Data Modelling and software architectureGood understanding of Linear Algebra, Probability and Bayesian statistics\n",
       " Collaborative and keen to make an impact\n",
       " ,\n",
       " requirements from multiple team to define data to be collected from the game for analysis\n",
       " Analyse key performance indicators such as retention, player lifetime value and acquisition cost\n",
       " Design and analysis of A/B tests to estimate the effect on key metrics and provide recommendations\n",
       " Build and maintain dashboards for product, marketing and senior management teams\n",
       " Develop models for predicting player behaviour\n",
       " Answer in-depth analytics questions from the team and create reports of the results\n",
       " Identify and report actionable insights to internal stakeholders, suggest recommendations and influence the direction of the business by effectively communicating results\n",
       " Develop and improvise models for player behavioural patterns\n",
       " Requirements\n",
       " Relevant degree or equivalent in a quantitative discipline involving mathematics and statistic studies\n",
       " Demonstrable experience in a Data Scientist or Analyst role in a live service product\n",
       " Proficiency in Amplitude\n",
       " Desired Experience\n",
       " Expert knowledge of SQL\n",
       " Proficiency in statistical programming languages (R, Python, etc.)\n",
       " Knowledge of major cloud providers and their offerings for analytics (EMR, S3, Kinesis, BigQuery, etc.)\n",
       " Experience in interpreting and visualising data to provide actionable insight and conclusions on user/product behavior\n",
       " Solid communication skills. Being able to compile and translate data, numbers and analyses into normal English, and present findings to non-technical audiences\n",
       " Passion for games and fitness\n",
       " How you’ll be measured\n",
       " Quality of insights\n",
       " Team player\n",
       " Data visualisation, Communication and report writing skills\n",
       " Our principles of play (Values)\n",
       " Commitment - We are joined in our mission and support and motivate each other to achieve great things.\n",
       " Independence - We’ll leave it up to you to use your own judgment and do your job the way you know best.\n",
       " Open Mindedness - We continually question the status quo\n",
       " Communication - Effective communication is crucial to our success\n",
       " Respect - We listen to and learn from each other, and recognise how our own beliefs and actions affect the wider team.\n",
       " Benefits️ Flexible office hours (core working hours typically 10-4)\n",
       "  Competitive compensation\n",
       " Stock options\n",
       "  brand new equipment and VR headsetHealth insurance\n",
       "  Unlimited leave policy, thats right\n",
       " \n",
       "  ,\n",
       " Key Requirements;\n",
       " 3-8 years’ experience within a data analyst / scientist role\n",
       " Interest in data, AI and machine learning\n",
       " Experience in quantitative analysis (stochastic calculus, PDEs, Monte Carlo methods, and numerical methods) would be advantageous\n",
       " Prior experience within the Energy sector, (or a clear interest in energy)\n",
       " Python proficiency\n",
       " Familiarity with an SQL-based language\n",
       " Familiarity with Time Series databases\n",
       " ,\n",
       " requirements and defining the product vision\n",
       " Translate business objectives into action by successfully delivering on execution strategy\n",
       " Collaborate with the engineering team, among others, to develop technical requirements and to define, build and maintain products critical to growth, engagement and retention\n",
       " Work with customers and all customer-facing organizations to plan and prioritize features and feature requests\n",
       " Develop a comprehensive understanding of the competitive landscape and evaluate market trends to inform product development better\n",
       " Partner with Product Marketing to develop comprehensive go-to-market strategies for impactful product launches\n",
       " Continue to recruit, train and develop a team of world-class product managers\n",
       " ,\n",
       " Requirements\n",
       " Minimum Qualifications:\n",
       " Ph.D in NLP or Computational Linguistics or equivalent experience (MSc with 4+ years of research experience)\n",
       " Strong programming/software engineering background enabling rapid codebase acquisition and scalable development\n",
       " Fluency in fundamental NLP pipeline algorithms and tools (e.g. preprocessing and normalization, POS, dependency parsing, NER)\n",
       " Experience with common NLP and Machine Learning libraries (e.g. nltk, spacy, scikit-learn)\n",
       " Fluency with at least one of the modern distributed ML frameworks (e.g. TensorFlow, PyTorch)\n",
       " Experience in dealing with a vast amount of textual data (optimization, performance enhancement)\n",
       " Ability to drive technical projects autonomously and work in a diverse and collaborative environment\n",
       " Proficiency in Python or similar scripting language\n",
       " ,\n",
       " Requirements:\n",
       " We welcome applications from anyone with a track-record of super-powering decisions with data and an ambition to have practical impact. We're looking for people with a creative and robust approach to solving problems with experience of managing small teams of Analysts.\n",
       " ,\n",
       " Nice to have but not essential\n",
       " Experience with NoSQL, SQL databases\n",
       " AWS experience\n",
       " ,\n",
       " requirements into solutions\n",
       " Possession of outstanding oral and written communication skills\n",
       " Empathic listener and persuasive speaker\n",
       " Planning, managing and executing the delivery of projects\n",
       " Demonstrable understanding of data science concepts particularly where focused on a business need\n",
       " Demonstrable understanding of statistics\n",
       " Excellent understanding of machine learning techniques and algorithms\n",
       " Proficient understanding of data and business intelligence tools (Alteryx, VBA, SQL, Tableau etc.)\n",
       " Understanding of Agile delivery methods\n",
       " We recognise that it takes a team to deliver AI and so we seek individuals with demonstrable skills in a selection of the below for a number of roles\n",
       " Consulting experience in a strategy house, a Big 4 firm or an in-house strategy/consulting function of a data-driven company\n",
       " Industry Experience in one of our target sectors (e.g. Financial services)\n",
       " Strong academic excellence in a business and/or analytics related degree (e.g. Economics, Business Intelligence and Analytics)\n",
       " Exposure to cloud environments (Azure, GCP, AWS etc)\n",
       " Exposure to programming is desirable but not essential\n",
       " Exposure to business or financial modelling\n",
       " ,\n",
       " requirements for current and future prototype requirements.\n",
       " Using your background in data mining, machine learning, and statistical models to extract useful information and turn it into insights.\n",
       " Investigating and assessing multiple approaches to a problem in order to support the selection and recommendation of the highest quality and most commercially effective approach.\n",
       " Creating analytical models to understand player engagement and in-game behaviours as well as novel analyses specific to various prototypes.\n",
       " ,\n",
       " requirement.\n",
       " Working alongside data engineers and developers to create production-ready data pipelines.\n",
       " ,\n",
       " requirements for this role you will need to have resided in the UK for a minimum of 3 out of the past\n",
       " ,\n",
       " Requirements:\n",
       " Extensive experience with deep learning frameworks Tensorflow, Caffe, PyTorch, Theano, etc (any of them)\n",
       " Excellent software engineering skills with working experience in Python, C++ or Rust (at least two).\n",
       " Understanding of basic ML models (SVM, regression, random forests)\n",
       " \n",
       " ,\n",
       " ideal candidate would have experience with Forensic Data Analytics and SAP/ERP.\n",
       " ,\n",
       " requirements from stakeholder groups inside and outside of LiveRamp to prioritize capabilities and deliver a winning product across customer segments and business functions\n",
       " Build relationships and work closely with Engineering to ensure alignment\n",
       " Work closely with Marketing to facilitate the Product team's domain expertise flow and support positioning, messaging, and content\n",
       " Align executive stakeholders on product vision and strategy\n",
       " \n",
       " ,\n",
       " Requirements:\n",
       " Academic Qualifications\n",
       " ,\n",
       " requirements and investigate possible data solutions for the investment team. The internship is a fantastic opportunity to gain business experience in a specialised fund manager and expand understanding of applicable data solutions, including optimisation and AI.\n",
       " DATA SCIENTIST INTERN\n",
       " ,\n",
       " requirements, we'll be excited if you've also:\n",
       " ,\n",
       " requirements, the people strategy and provides a differentiated offering from our competitors\n",
       " Ensure the design and delivery of the people data strategy integrates with the other areas of the People function i.e. Reward, Performance, Inclusion & Diversity, Talent and Recruitment.\n",
       " Engage with the business and HRLT to facilitate the provision of analytical advice that is relevant and critical to strategic decision-making\n",
       " Generating data from multiple sources that is easily consumable and actionable and communicating your findings in clear business language, and across various channels\n",
       " Leading a small DI team, providing leadership and clear direction\n",
       " Maintain a rolling programme of HR reporting and review, ensuring resources are aligned to develop responses, achieve sign off and manage outward communications\n",
       " Support the UK Head of People and the Leadership team in the ongoing development of the wider HR strategy\n",
       " Oversight of all People MI and analytics including culture measurement.\n",
       " Take the lead on ensuring any key interventions that the organisation should make in response to the People MI data set are delivered and owning the prioritisation of those interventions.\n",
       " ,\n",
       " ideal candidate for this role will have the following qualifications, skills and experience:\n",
       " Thorough understanding of statistics, data mining, and visualization of biological data types.\n",
       " Advanced computational skills such as operating in a HPC Unix environment, cloud-based computational and/or pipelining platforms, and programming languages such as Python or R.\n",
       " Expertise in pre-processing, integration and analysis of different omic data types (e.g. gene expression, epigenetic data, metabolomics, etc.)\n",
       " ,\n",
       " requirements\n",
       " Experience of business analysis tasks and approaches\n",
       " We recognise that it takes a team to deliver AI and so we seek individuals with demonstrable skills in a selection of the below for a number of roles\n",
       " Strong programming experience in Python\n",
       " Experience of developing in cloud environments (Azure, GCP, AWS)\n",
       " Experience with SQL databases (Postgres, SQL Server, MySQL, Oracle)\n",
       " Experience with NoSQL databases (Elasticsearch, Cassandra, Neo4J)\n",
       " Experience of the Linux ecosystem and container technologies (Docker, Kubernetes)\n",
       " Software engineering experience (Git, Continuous Integration/Deployment, Software Testing)\n",
       " Knowledge of Information Security practices, especially in a Cloud environment\n",
       " Cloud fundamental or architect accreditations\n",
       " Experience with API development\n",
       " Experience working with big data technologies (Apache Spark, Apache Hadoop, Apache Drill, Presto, Redshift or similar)\n",
       " Programming experience in a JVM language (Java, Scala, Kotlin)\n",
       " Demonstrable experience in project management and leading teams\n",
       " A mature understanding of business operations\n",
       " Experience of coaching and developing other members of staff\n",
       " ,\n",
       " Requirements:\n",
       " Minimum Academic Qualifications\n",
       " ,\n",
       " ideal candidate has a proven appreciation and understanding of financial services, asset management, data analysis, and programming knowledge.\n",
       " As a member of this team, the individual will be part of a fast-paced environment where they will model complex business problems, discover key insights and identify opportunities; in order to accomplish this, an academic and practical knowledge of applying statistical, algorithmic, mathematical and technological techniques in an asset management or financial services area is paramount.\n",
       " Primary Responsibilities\n",
       " ,\n",
       " requirements and turn them into reality.\n",
       " ,\n",
       " requirements.\n",
       " Research and develop cutting-edge technology on Text Mining and Natural Language Processing (NLP).\n",
       " Applying NLP technology for medical applications.\n",
       " ,\n",
       " Requirements\n",
       " A Master or PhD in, Computer Science, Mathematics, Computer Vision/Machine Learning or similar related field.\n",
       " Proven ability of results driven application of machine learning.\n",
       " Proven knowledge of at least one of the main deep learning frameworks (Pytorch, Tensorflow, Keras...)\n",
       " Very knowledgeable in Python and relevant numerical libraries (numpy, scikit-learn, opencv, etc.)\n",
       " Computer Vision experience\n",
       " Data visualization experience would also be useful for this role.\n",
       " Benefits\n",
       " We’re in a really lucky position to operate like a small team, with all of the benefits of a big company. Following our acquisition by Medtronic in February 2020, our benefits have had an impressive face lift. ; Our benefit package aims to help support your health, build wealth, grow in your career and share in the success of Digital Surgery and Medtronic. We are in the healthcare business and so in order to look after our people we provide:\n",
       " ,\n",
       " requirements around their video data.\n",
       " What is on offer:\n",
       " Competitive remuneration and benefits\n",
       " Family-friendly flexible working time, home working and remote working in combination with office working in London (Paddington area)\n",
       " ,\n",
       " Requirements:\n",
       " Must Have:\n",
       " ,\n",
       " qualification with extensive research. Some experience in development languages would be ideal.\n",
       " \n",
       " ,\n",
       " requirements and provide analytical supportDirectly contribute to the design and development of automated selection systemsBuild customer-facing reporting tools to provide insights and metrics which track system performanceCommunicate verbally and in writing to business customers and leadership team with various levels of technical knowledge, educating them about our systems, as well as sharing insights and recommendations\n",
       " ,\n",
       " requirements as you are drilling into design with development teams and developing production ready learning models. You consistently bring strong, data-driven business and technical judgment to decisions.\n",
       " ,\n",
       " Requirements:\n",
       " Minimum 2 years of software development experience in industry\n",
       " Proficient knowledge of Tensorflow, PyTorch or similar DL frameworks\n",
       " Deep knowledge of a programming language (e.g. Python, C++11, Go and Rust) in Linux environment; working knowledge of multiple languages\n",
       " Ability to write high quality code\n",
       " Experience in relevant fields, such as Audio-Visual, Speech or Vision, Machine Learning and Deep learning\n",
       " Masters Degree in Computer Science or other relevant area\n",
       " Strong grasp of data structures, algorithms and communication protocols\n",
       " \n",
       " ,\n",
       " requirements and implementation.\n",
       " \n",
       " ,\n",
       " requirements from the relevant stakeholder\n",
       " Develop prototypes, before scaling the solution to work with our 15+ million users and deploy it to production.\n",
       " Optimise and maintain existing solutions to improve performance metrics and increase business impact\n",
       " Create necessary ETLs and data pipelines\n",
       " Participate in the team activities (agile ceremonies, journal club, engineering whiteboard sessions etc)\n",
       " \n",
       " ,\n",
       " requirements, develop detailed product specifications and associated project work plans for infarm's AI/ Machine Learning features and key enhancements requests\n",
       " Identify and track key success metrics for all of your products focusing on a business and user value\n",
       " Be world class with running conclusive experiments quickly to validate hypotheses\n",
       " Manage stakeholders across Infarm, as well as external partner stakeholders\n",
       " \n",
       " ,\n",
       " Requirements\n",
       " What you'll be doing\n",
       " Getting up to speed with our data, processes and tooling, and making these more efficient\n",
       " Regular reviews of claims trends and competitor prices to inform our pricing strategy\n",
       " Monitoring and adapting the performance of our pricing models\n",
       " Taking on more challenging projects, such as exploring new market opportunities and building machine learning models\n",
       " Visualising and presenting data to stakeholders\n",
       " Who you are\n",
       " You are a self-starter who likes to take ownership\n",
       " You are curious and have a can do attitude\n",
       " You are patient and stay calm under pressure\n",
       " You are organised and can be relied upon to get things done\n",
       " You enjoy working as part of a team and owning the work you do\n",
       " You enjoy working in a high growth/ scaling environment\n",
       " You enjoy problem- solving and creating innovative solutions\n",
       " Experiences that will help you succeed\n",
       " A STEM degree\n",
       " 1-3 years of data analyst work in a high growth startup\n",
       " Experience working in a cross-functional team\n",
       " Experience manipulating large data sets and making an impact from the conclusions of analysis\n",
       " Demonstrable experience with modeling in R, Python\n",
       " Strong communication skills\n",
       " Experience building machine learning models\n",
       " Benefits\n",
       " Competitive salary\n",
       " Stock options ‍‍‍\n",
       " 33 day holiday allowance (inc bank holidays) ️\n",
       " Pension\n",
       " Health insurance\n",
       " Cycle to work scheme\n",
       " Learning and training\n",
       " Flexible working\n",
       " Monthly socials\n",
       " ,\n",
       " ideal candidate’s personality and qualifications…\n",
       " Passionate about data\n",
       " Experienced in large data sets and distributed computing\n",
       " Computer Science or similar degree\n",
       " Understanding of business processes and interest in automating processes\n",
       " Keen to work in a start up environment\n",
       " Good people skills, happy to be working on client site\n",
       " Can do approach, willing to roll up sleeves\n",
       " Knowledge of ETL (Extract-Transform-Load) tools, BI tools and reporting software ( Power BI, Tableau etc..)\n",
       " ,\n",
       " qualification in Data Science/Data analysis OR a degree in a research discipline (e.g. Sociology, Psychology)\n",
       " Results orientated, ability to manage deadlines and time effectively\n",
       " Ability to find creative and innovative solutions for complex and varied problems\n",
       " High level knowledge of data wrangling/manipulation techniques in R or Python\n",
       " Good experience in working with database systems and SQL syntax\n",
       " Experience with machine learning and predictive models in R OR Pandas (one is a must)\n",
       " Experience with running segmentations of respondent or customer data is a plus\n",
       " Outstanding attention to detail\n",
       " Good communication skills, oral, written and technical documentation\n",
       " ,\n",
       " requirements into projects, reviewing designs and recommending solutions and managing assurance activity, such as due diligence reviews and penetration tests.\n",
       " A technical degree or relevant professional qualification (e.g. CISSP, CISM or CISSA)\n",
       " Experience in data science techniques and methods (e.g. machine learning, natural language processing, linear regression, and random forest)\n",
       " Essential\n",
       " Knowledge of Cyber Security, Data Privacy and Information Management solutions and how to integrate their operation into business systems and processes\n",
       " Experience in using formalised risk management methodologies\n",
       " Experience in ISO 27001/2, NIST and/or ISF\n",
       " Experience in the use of Python, R or similar to analyse, transform and visualise data\n",
       " Experience in the build, test and deployment of machine learning models\n",
       " Experience of working in an environment where critical services are outsourced\n",
       " All candidates must be capable of obtaining and maintaining UK national security vetting at SC level\n",
       " Desirable\n",
       " Self-motivation and experience of working as a member of a team\n",
       " A proven track record in Cyber Security and either Data Privacy or Information Management\n",
       " Experience in working to ITIL and/or Prince2 requirements\n",
       " Experience of working in a Professional Services or Financial Services environment\n",
       " Good technical knowledge across a range of technologies (e.g. Windows, networks, Linux, cloud, Oracle applications, web...)\n",
       " About the FCA\n",
       " At the FCA, we’re creating a fair and more resilient financial system. We’re establishing more transparent relationships between financial services and their customers, building trust in financial markets and protecting vulnerable consumers.\n",
       " Divisional Information\n",
       " their Consulting team to specialise in delivering data science related consulting. Cyber and Information Resilience has responsibility for the delivery of effective Cyber Security, Data Privacy and Information Management across the organisation, making sure the organisation operates in a secure way and continues to meet its obligations.\n",
       " The Consulting Team within C&IR plays a key role in supporting business led and IT change programmes across the organisation. Acting as a Security, Data Privacy and Information Management stakeholder and providing advice, guidance and policy interpretation across numerous technologies.\n",
       " The Consulting team works closely with other teams within C&IR, in other departments and within our outsourced suppliers to ensure all aspects of Cyber Security, Data Privacy and Information Management are delivered effectively and in compliance with our policies and standards.\n",
       " ,\n",
       " requirements as you are drilling into design with development teams and developing production ready learning models. You consistently bring strong, data-driven business and technical judgment to decisions.\n",
       " ,\n",
       " nice to have skills will focus around the following elements of:\n",
       " Certified GCP developer\n",
       " Machine Learning and AI knowledge\n",
       " Finance experience\n",
       " Mentoring junior team members\n",
       " ,\n",
       " requirements to data collation and analysis, drawing actionable insights from data and communicating this to the client.\n",
       " ,\n",
       " requirements within the team and across stakeholder groups. You are indispensable and own the quantification of business opportunities and identification of project direction prioritizing projects based on greatest return on investment. You consider the needs of day-to-day operations and insist on the standards required to build the network of tomorrow. Your job will straddle day-to-day decisions and strategic vision, you will assist in defining trade-offs and quantifying opportunities for a variety of projects. You will learn current processes, build metrics, educate diverse stakeholder groups, assist science groups in initial solution design, and audit all model implementation. A successful candidate in this position will have a background in communicating across significant differences, prioritizing competing requests, and quantifying decisions made. You will balance the trade-offs between customer experience, network speed, and cost, to measurably improve the network in a 3 to 6-month time-frame.\n",
       " ,\n",
       " ideal candidate will have experience in solving real-world problems with machine learning using a variety of tools. You know how to solve a problem as well as how to deploy it into production, measuring and updating it as needed over time. You love working closely with data engineers and others in cross-functional teams to develop solutions iteratively. Importantly, you are pragmatic and experienced, able to identify and solve common problems swiftly and effectively with tools and libraries and you don’t reinvent the wheel.\n",
       " ,\n",
       " Requirements:\n",
       " Commercial experience as a Data Scientist with experience of applying Machine Learning / Deep Learning methodologiesStrong Python skills with a good knowledge of associated tools / libraries e.g. NumPy, Pandas, Scikit-Learn, TensorFlow, PyTorch, PyMc3Indepth knowledge of at least one RDBMS: Oracle, PostgreSQL, Sybase or SQL ServerDegree educated in relevant disciple (e.g. Mathematics, Computer Science) from a top tier university, likely have gone on to study MSc / PhD\n",
       " ,\n",
       " requirements and turn them into reality.\n",
       " ,\n",
       " requirements\n",
       " Use systems and internal processes efficiently and integrate these in daily work.\n",
       " \n",
       " ,\n",
       " ideal candidate is an enthusiastic and flexible team player with a solid technical skill set and strong analytical mind, is an excellent communicator, and thrives in a fast-paced commercial environment.\n",
       " \n",
       " ,\n",
       " Requirements:\n",
       " Bachelor’s degree or Master’s Degree in Computer Science\n",
       " Comfortable with either Python or GO\n",
       " Strong scripting and debugging skills\n",
       " Working proficiency in verbal and written English\n",
       " ,\n",
       " Nice to haves:\n",
       " Knowledge of Kubernetes, whilst not essential, will really help you stand out.\n",
       " ,\n",
       " qualification in an analytical or science-based discipline e.g. engineering/maths/computer science or equivalent\n",
       " ,\n",
       " ideal candidate for this role will have the following qualifications, skills and experience:\n",
       " Prior experience in regulated GMP/GLP quality systems.\n",
       " Experience applying ALCOA principles upon data capture and report.\n",
       " 3+ years experience working in preformulation, formulation, drug product manufacturing or analytical environments in the biopharmaceutical industry.\n",
       " Knowledge of challenges taking products from research through to development and into clinical manufacture.\n",
       " ,\n",
       " Requirements (Education, certifications and experience):\n",
       " ,\n",
       " requirements, functional design, process design (including scenario design, flow mapping), prototyping, testing, training, defining support procedures.\n",
       " Formulate planning, budgeting, forecasting and reporting strategies.\n",
       " Manage full life cycle implementations.\n",
       " Develop statements of work and/or client proposals.\n",
       " Identify business opportunities to increase usability and profitability of information architecture.\n",
       " Experience with program leadership, governance and change enablement.\n",
       " Develop and manage vendor relationships.\n",
       " Lead workshops for client education.\n",
       " Manage resources and budget on client projects.\n",
       " Assist and drive the team by providing oversight.\n",
       " The team\n",
       " Analytics & Cognitive\n",
       " In this age of disruption, organizations need to navigate the future with confidence, embracing decision making with clear, data-driven choices that deliver enterprise value in a dynamic business environment.\n",
       " ,\n",
       " Requirements:\n",
       " This job is at a cleared site, candidates must be US persons, which include U.S. Citizenship or Permanent Residency.\n",
       " ,\n",
       " requirement documents for efficient model building and deployment.\n",
       " ,\n",
       " requirements of the Company Driving and Safety policy.\n",
       " \n",
       " ,\n",
       " requirements for and adopt new technologies and capabilities\n",
       " Analyze IT industry and market trends to determine impact to enterprise\n",
       " Establish team priorities and assign work to team members.\n",
       " Manage the team to meet balanced scorecard targets by monitoring team progress towards metric targets and actively participating in continuous improvement related initiatives to minimize unfavorable variances.\n",
       " Direct and ensure smooth workflow within the Team by staying informed and in touch with key elements of the organization beyond their Team communicating key messages and updates in a timely manner.\n",
       " Maintain constructive relationships within and outside the Team.\n",
       " Promote the professional development of Team.\n",
       " Manage the Demand Management process by assisting in developing and maintaining future demand projections (i.e., 6-12 months) to identify future staffing requirements and scheduling start and completion dates based on agreed scope of work.\n",
       " Ensure on-time delivery of work, including monitoring of external and internal dependencies, tracking of progress, and monitoring of project milestone accomplishments.\n",
       " Oversee the technical quality of the projects by ensuring that key technical procedures, standards, quality control mechanisms, and tools are properly utilized including performing root cause analysis for technical problems and engaging in work product quality review.\n",
       " Actively participate in the Change Control process by identifying potential scope variances by monitoring work requirements definition, issue resolution, development progress and user sign-off and reviewing change requests.\n",
       " Manage team work budgets.\n",
       " Mitigate risk by following established procedures, spotting key errors and demonstrating strong ethical behavior.\n",
       " ,\n",
       " requirements, functional design, process design (including scenario design, flow mapping), prototyping, testing, training, defining support procedures.\n",
       " Formulate planning, budgeting, forecasting and reporting strategies.\n",
       " Manage full life cycle implementations.\n",
       " Develop statements of work and/or client proposals.\n",
       " Identify business opportunities to increase usability and profitability of information architecture.\n",
       " Experience with program leadership, governance and change enablement.\n",
       " Develop and manage vendor relationships.\n",
       " Lead workshops for client education.\n",
       " Manage resources and budget on client projects.\n",
       " Assist and drive the team by providing oversight.\n",
       " ,\n",
       " requirements under Bona Fide Occupational Qualification rules, valid applicants must be US citizens.\n",
       " Clockwork Solutions is seeking a Principal Data Scientist to join our Services team and help us answer some of the toughest questions facing enterprises with strategic, capital intensive assets. In this role you will direct the delivery of analysis services and products in collaboration with other Data Scientists and under the direction of an Engagement Manager or VP of Services.\n",
       " The ideal candidate must demonstrate a profound knowledge of applied math and statistics and possess expert proficiency in developing new methods to solve problems through modeling and simulation, data analysis and visualization, cost and risk analysis, as well as developing data requirements for mathematical models. In addition, you must demonstrate the ability to effectively and efficiently communicate highly technical methods and results to peers, subordinates, managers and customers.\n",
       " This position requires expert level knowledge and experience in database design, querying, and manipulation as well as exceptional expertise with scripting and programming languages\n",
       " This is an exceptional opportunity to be a part of the core team responsible for delivering world class solutions to enterprises around the world.\n",
       " Responsibilities\n",
       " Works autonomously under the technical direction of an Engagement Manager on client projects and internal projects.\n",
       " Applies the scientific method to evaluate multi-layered processes, assets and operations with abstract models by applying constraints, assumptions and statistical modeling to extract focused insight that supports client decision-making.\n",
       " Applies Clockwork’s simulation platforms, design of experiments, conceptual modelling, natural language processing and machine learning to creatively solve dynamic, difficult problems focused on evolving client challenges.\n",
       " Support client strategic and operational goals by delivering insight to reduce cost, increase readiness, quantify uncertainty, bound risk, reduce waste and add confidence.\n",
       " Deliver internal and external training as an expert in Clockwork’s simulation platforms and predictive analysis techniques.\n",
       " Evaluates simulation analysis output to reveal key insights about unstructured, chaotic, real-world systems.\n",
       " Proposes new or revised analytical methods and projects in the areas of simulation analysis and predictive modeling.\n",
       " Represents Clockwork in interactions with clients, partners and the professional communities of operations research, modeling and simulation, and logistics.\n",
       " Applies programming languages and modeling platforms to write code that represents complex systems with logic for use in high-resolution predictive simulation models.\n",
       " Apply statistical methods and simulation modeling to investigate intrinsic system complexity in time dependent processes including equipment aging, system-wide interactions and the dynamic effects of operations and maintenance.\n",
       " Deliver interim and final reports of simulation analyses to clients and Clockwork leadership.\n",
       " Approve final technical analysis results to be included in deliverables on consulting contracts.\n",
       " Develop specifications, statements of work, evaluation criteria, and proposals.\n",
       " Support the evolution Clockwork’s technical expertise, services and software including participation in product development and testing\n",
       " Propose new or revised analytical methods and projects in the areas of simulation analysis and predictive modeling.\n",
       " Support Clockwork’s Business Development efforts.\n",
       " Support Director of Consulting and Chief Scientist as required.\n",
       " Assignments include but are not be limited to:\n",
       " Research and development of analysis methodologies and the practical application of them\n",
       " Leading data extracting, cleansing and data analysis processes\n",
       " Leading statistical analysis of historical input data and simulation output data\n",
       " Constructing simulation analysis models\n",
       " Developing software to enhance data management tools for use in predictive analysis\n",
       " Leading the Clockwork study management process\n",
       " Preparing and presenting interim and final briefings to clients\n",
       " Requirements\n",
       " Minimum of 5 years utilizing data science skills in industrial asset setting.\n",
       " BS/BA with 10 years of experience, MS with 8 years of experience or PhD with 6 years of experience.\n",
       " Degree fields include Probability & Statistics, Operations Research, Industrial Engineering or closely related scientific or technical discipline.\n",
       " Strong background in statistical modeling, artificial intelligence, machine learning (classification and regression), distribution fitting, design of experiments, numerical optimization.\n",
       " 3+ years’ experience with SQL, database schema development and best practices, familiarity with any common database technologies (MySQL, PostgreSQL, Hive, Oracle, etc.)\n",
       " Expert knowledge of scripting or programming language (Spark, Python, R, S+, Java, etc.)\n",
       " Able to communicate complex ideas through strong technical writing and impactful visualizations\n",
       " Preferred Experience\n",
       " Experience in reliability engineering such as reliability analysis, development/execution of RCM program.\n",
       " Experience with equipment sensor data in a Condition Based Maintenance (CBM) program or setting.\n",
       " Experience in developing, testing and analyzing simulation models\n",
       " Experience in Agile development environment\n",
       " Familiarity with data integration and ETL concepts\n",
       " Occasional travel required (<10%)\n",
       " ,\n",
       " requirements and priorities\n",
       " Maintenance of up-to-date knowledge in the appropriate technical areas\n",
       " Able to work in a global, multicultural environment\n",
       " ,\n",
       " Requirements\n",
       " Tableau experience is preferred\n",
       " ,\n",
       " requirements\n",
       " Cover letter with application packet\n",
       " Knowledge of statistical theory\n",
       " Experience in empirical practice\n",
       " Programming experience in low-level languages, such as C or FORTRAN\n",
       " Programming experience in statistical packages\n",
       " Good communication skills, including the ability to write and speak fluently in English\n",
       " A master's degree or equivalent knowledge and job experience in statistics, biostatistics economics, or another science-related field\n",
       " (Do not read into the order in which fields are listed. The degree is not a requirement; the knowledge is.)\n",
       " \n",
       " ,\n",
       " requirements, document processes, and build business use cases). Working in partnership with functional areas to develop automated reports in the most effective medium and being involved in all aspects of the development life cycle including, assessment, initiation, architecture, development, testing, production, institutionalization, and training. Producing accurate, consistent and timely reporting by extracting information from various applications and systems, manipulating data, and developing user friendly final outputs leveraging SAS, SQL, VBA, Python, Excel, Power BI, etc. Proactively analyze data to answer key questions from stakeholders or out of self-initiated curiosity with an eye for what drives business performance and investigating and communicating areas for improvement in efficiency, quality, and productivity. Producing and maintaining inventories of standard and/or best practice reports and documenting dashboard designs and data sources and ensuring data integrity via validation. Leading other special projects, as needed, to support the reporting team and functional areas.Essential Attributes Critical Thinker: Displays well developed analytical, critical thinking, and problem-solving skills. Articulate: Ability to organize and simplify complex ideas and utilize plain language to create a variety of written documents. Driven: Exhibits initiative and a willingness to take ownership of assignments and go the extra mile. Accurate: Sets and maintains high personal work standards, while demonstrating an attention to detail and a focus on quality High-Performing: Highly functional in a dynamic, challenging environment, with the ability to anticipate and remove obstacles that slow down or prevent programs from delivering on stated objectives. This is a grant funded position subject to cancellation when funds are depleted and/or contract period ends. WORKING CONDITIONS This position is physically comfortable. There are no major sources of discomfort, i.e., essentially normal office environment with acceptable lighting, temperature and air conditions.\n",
       " ,\n",
       " requirements, and translate those requirements into technical solutions\n",
       " - Design data science approach, applying tried-and-true techniques or developing custom algorithms as needed by the business problem\n",
       " - Collaborate with data engineers and platform architects to implement robust production real-time and batch decisioning solutions\n",
       " - Ensure operational and business metric health by monitoring production decision points\n",
       " - Investigate adversarial trends, identify behavior patterns, and respond with agile logic changes\n",
       " - Communicate results of analyses to business partners and executives\n",
       " - Research new technologies and methods across data science, data engineering, and data visualization to improve the technical capabilities of the team\n",
       " ,\n",
       " requirements. Assist in planning, developing, maintenance and production of required documents to include any regulations and/or specifications. Requires the ability to work independently and support multiple tasks as assigned.\n",
       " Qualifications\n",
       " 17+ years' professional experience\n",
       " Knowledgeable and experienced in Data Analytics\n",
       " Experience with Artificial Intelligence and Machine Learning data engineering, deep learning frameworks and related open-loop testing techniques\n",
       " Experience in technical writing\n",
       " Experience designing efficient data science workflows and database architecture for data science purposes\n",
       " Bachelor's degree in Computer Science or related field\n",
       " Knowledge of database systems, big data concepts and cluster computing frameworks (e.g. Spark, Hadoop, or other tools)\n",
       " Must be a U.S Citizen and be able to obtain and maintain a TS/SCI Security clearance. Active Security clearance preferred.\n",
       " \n",
       " \n",
       " ,\n",
       " ideal candidate for this position has the experience and education to advance Internal Audit in the understanding, development and use of these emerging concepts.\n",
       " ,\n",
       " requirement. A passionate audio researcher/engineer/scientist will thrive in this role by collaborating with peers across multiple disciplines. In short, your research and development in algorithm development for voice/audio biometrics will enable the advancement of the world around us connecting seamlessly.\n",
       " We are open to considering experts in all areas of spoken language understanding: ASR, NLU, text-to-speech (TTS), and Dialog Management as it pertains to biometrics.\n",
       " ,\n",
       " requirement. What and how you can contribute is what's most important to us which is why our consideration is not limited by the level of education you have.\n",
       " You have experience with big data technologies such as Spark or AWS; are able to write efficient SQL; and are proficient in one or more of the following programming languages: R, Python, Java, or Scala. Variety of technical challenge is one of the best things about working at The Trade Desk as a data scientist though which is why we do not expect you to know every technology we use when you start. What we care about is that you can learn quickly and solve complex problems using the best tools for the job.\n",
       " ,\n",
       " requirements, find bottlenecks, and implement resolutions.\n",
       " Collaborate with the Analytics Tech lead to establish best practices for repeated application.\n",
       " Help mentor and develop the skillsets of the junior team members within your team or department.\n",
       " Work within a team of data analysts and engineers.\n",
       " REQUIRED\n",
       " 7+ years in data science or similar role in the marketing, finance, forensics or technology fields required.\n",
       " Extensive knowledge of machine learning techniques such as k-NN, Naive Bayes, SVM, Decision Forests, Data Mining, Clustering, and Classification.\n",
       " Experience in pushing models to production and iterating on models in production.\n",
       " Proficiency in statistics such as distributions, predictive modeling, data validation, statistical testing, and regression.\n",
       " 5+ years of experience in machine learning / statistical languages and systems such as Python, Matlab, R.\n",
       " Bachelor's degree in Computer Science or related field, with a strong quantitative background.\n",
       " Ability to develop and maintain good relations and communicate with people at all hierarchical levels.\n",
       " Strong problem-solving skills.\n",
       " Ability to reconcile technical and business perspectives.\n",
       " Autonomy and entrepreneurship.\n",
       " Strong team spirit.\n",
       " Passion for Rockstar Games and our titles.\n",
       " PLUSES\n",
       " ,\n",
       " requirements and explain/discuss implementation details of complex statistical analyses to both technical and non-technical audiences.\n",
       " ,\n",
       " requirements into concrete deliverables and working closely with the software development team to put solutions into production.\n",
       " ,\n",
       " requirements and develop solutions to support GE products and services.\n",
       " Formulate plans for assigned projects and work with customers to track progress toward project deliverables.\n",
       " Develop heat transfer physics-based models to design and analyze the performance of IR thermography imaging systems.\n",
       " Build IR thermography hardware components and write software for data acquisition and analysis.\n",
       " Design and perform experiments to optimize inspection systems and methods and conduct in-plant tests using IR thermography systems to characterize manufacturing process capabilities and issues.\n",
       " Work with GRC and GE businesses to develop and implement actionable multi-generational technology plans for IR thermography.\n",
       " Effectively communicate results by preparing written reports and delivering oral presentations.\n",
       " ,\n",
       " requirement varies depending on level; recent graduates must have had relevant internships).\n",
       " Note: For this role, only candidates with Ph.D.s in the areas above will be considered. If you do not meet that requirement please consider either the Data Scientist or other positions.\n",
       " \n",
       " ,\n",
       " requirements during design and implementation of modeling and analysis projects.\n",
       " Travels to events and vendor meetings as needed (< 10%).\n",
       " ,\n",
       " ideal candidate is a highly motivated problem-solver capable of applying big picture thinking with a passion for using data to assist our clients in making better investment decisions.\n",
       " ,\n",
       " requirements\n",
       " Building reports, dashboards and scorecards using a variety of tools\n",
       " Providing ongoing support to existing clients\n",
       " Building out demonstration scenarios and prototypes\n",
       " Collaborating and working effectively with consultants in other regions and practices\n",
       " ,\n",
       " ideal candidate will be an experienced statistical programmer using R who also has experience working with survey and sales data, refining and developing methodological improvements, and familiarity with or willingness to learn Agile or Lean approaches to developing new product improvements.\n",
       " Responsibilities:\n",
       " Use various modeling approaches to design enhancements to NPD methodologies\n",
       " Quantify improvements to data due to modeling\n",
       " Carry out tests of alternative implementations of these enhancements\n",
       " Making sure code to implement models on an ongoing basis is robust by creating unit tests\n",
       " Investigating unexpected results and brainstorming alternative methodological solutions.\n",
       " Provide peer mentoring of other team members via code reviews, pair programming, unit test/acceptance test reviews, and brainstorming sessions.\n",
       " Adopt and continue to improve usage of development practices and patterns, such as test-driven development, version control, and use of agile management tools.\n",
       " Conduct original research-on-research (e.g., through simulations and/or evaluations of historical data) to improve methodologies, processes, and data integrity for both survey and scanner (point-of-sale) data.\n",
       " Promote consistency in implementation of designed enhancements across different businesses\n",
       " Maintain relationships with Research Science client teams to understand what is working well with NPD methodology and what could be improved\n",
       " Listen to internal customers and build an understanding of their needs before building solutions\n",
       " Communicate results and procedures in a concise and polished manner to diverse internal stakeholders\n",
       " Back up assertions with facts, and design experiments to quantify or reduce uncertainty when dealing with the unknown\n",
       " ,\n",
       " requirement but a perk of the job! We are always looking for opportunities to improve. Our mission is to demystify marketing with data-driven insights, telling the story of how we attract and retain our users to teams, to senior management, and to the community!\n",
       " This role is located in our Brooklyn, NY office.\n",
       " Develop, implement, and refine core marketing measurement frameworks and models, including attribution, churn, CLV, ROI, experiment methodology, and segmentation\n",
       " Play a foundational role in deciding how we can best engage and grow Etsy users by determining and helping execute on opportunities for growth through analysis of behavioral and transactional data\n",
       " Transform raw data into meaningful and impactful analysis characterized by strong data governance, technique transparency, and aggressive documentation\n",
       " Design and analyze rigorous experiments, help teams set great hypotheses, and deliver robust analysis of experiment results\n",
       " Raise the skill level of the entire analytics team through the creation of outstanding work, mentorship, and the introduction of better practices, processes, and tools\n",
       " ,\n",
       " ideal candidate for this role will have strong coding skills (preferably in one of the following languages R-code, Python), a passion for creating technology to improve health care, and an attitude of creativity and continual learning.\n",
       " What you will do:\n",
       " Develops and/or uses algorithms and statistical predictive models.\n",
       " Creates models using ML / AI techniques to predict risk and identify actionable insights.\n",
       " Delivers clean, reusable, and scalable code.\n",
       " Works closely with clinical teams and with Data & Engineering to deploy models.\n",
       " Provides thought leadership on latest analytic techniques, technologies, and methods.\n",
       " Provides mentorship to Junior Data Scientist.\n",
       " Brings clinical insights to inform predictive models is comfortable reading academic clinically oriented literature and collaborating with clinical subject matter experts to inform predictive models.\n",
       " Performs analyses of structured and unstructured data to solve multiple and/or complex business problems using advanced statistical techniques and mathematical analyses and broad knowledge of the organization and/or industry.\n",
       " Collaborates with business partners to understand their problems and goals, develop predictive modeling, statistical analysis, data reports and performance metrics.\n",
       " Develops and participates in presentations and consultations to existing and prospective constituents on analytics results and solutions.\n",
       " Interacts with internal and external peers and managers to exchange complex information related to areas of specialization.\n",
       " Use strong programming skills to explore, examine and interpret large volumes of data in various forms.\n",
       " Evaluate and identify new technologies\n",
       " Works collaboratively with teammates.\n",
       " Mentor junior data scientists, data analysts, and interns\n",
       " Requirements:\n",
       " Bachelor’s Degree in Data Science, Statistics, Computer Science, Applied Mathematics, Operations Research, or related fields, plus 7+ years relevant work experience required\n",
       " Master's Degree or PhD in Epidemiology, Statistics, Computer Science, Math or related field preferred\n",
       " Knowledge of healthcare claims, clinical programs and interventions, health outcomes, population health. Clinically oriented background or professional experience is a plus.\n",
       " Experience with MySQL database and SQL. Experience with R-code is a plus.\n",
       " Experience in using mathematics, statistics, modeling, business analysis, and technology to transform high volumes of complex data into advanced analytic solutions.\n",
       " Anticipates and prevents problems and roadblocks before they occur.\n",
       " Demonstrates strong ability to communicate technical concepts and implications to business partners.\n",
       " Working knowledge of querying complex data structures.\n",
       " Knowledgeable in Data Modeling.\n",
       " Knowledge and familiarity with database security concepts and best practices.\n",
       " Experience in working with both structured and unstructured data to create reports, projections, models, and presentations to support business strategy and tactics.\n",
       " Strong collaboration, multi-tasking, and organization skills.\n",
       " Able to identify multiple approaches to problem solving and recommend the best-case solution.\n",
       " Proven ability to work directly with users and management to gather requirements, provide status updates, and build good relationships and rapport.\n",
       " Must be proactive, innovative, and creative in meeting client/customer needs. Always keeping a “Can do!” attitude.\n",
       " Ability and willingness to work in a team environment and adopt a culture of ownership and initiative, and promote such within the team.\n",
       " Comfortable contributing and debating in a casual and friendly team environment.\n",
       " Experience in working with assignments that involve moderately complex to complex issues using statistical modeling, time-series analysis, and advanced analytics to transform high volumes of complex data into advanced analytic solutions.\n",
       " Ability to make decisions on moderately complex to complex issues regarding technical approach for project components.\n",
       " Demonstrated problem solving, strategic and analytic thinking capabilities.\n",
       " Experience in working with cross-functional teams, organizing, and managing multiple priorities and/or projects.\n",
       " Must be passionate about contributing to an organization focused on continuously improving consumer experience.\n",
       " ,\n",
       " requirements for this role?\n",
       " Bachelors, Masters or Phd in Computer Science, Computer Engineering, Software Engineering, or other related technical field.\n",
       " A minimum of 3 years of experience in a software or data engineering role\n",
       " Excellent teamwork and communication skills\n",
       " Extremely analytical, critical thinking, and problem solving abilities\n",
       " Proficiency in Java\n",
       " Very strong knowledge of SQL and ability to implement advanced queries to extract information from very large datasets\n",
       " Experience in working with very large datasets using big data technologies such as Spark, BigQuery, Hive, Hadoop, Redshift, etc\n",
       " Ability to design, develop and deploy end-to-end data pipelines that meet business requirements.\n",
       " Strong experience in AWS and Google Cloud platforms is a big plus\n",
       " Deep understanding of computer science concepts such as data structures, algorithms, and algorithmic complexity\n",
       " Deep understanding of statistics and machine learning algorithms foundations is a huge plus\n",
       " Experience with Machine Learning big data technologies such as R, Spark ML, H2O, Mahout etc is a plus\n",
       " ,\n",
       " requirements (please note if international): Limited travel, likely <10% but that could include international for conferences, et. al.\n",
       " Hours of work/work schedule/flex-time: Normal Business Hours 8:00-5:00 with additional hours occasionally needed for urgent project demands.\n",
       " ,\n",
       " Requirements\n",
       " Masters in a quantitative discipline (e.g. Stats, Math, Physics, Engineering, etc.)\n",
       " 5+ years of experience in data science/machine learning roles\n",
       " 3+ years of experience working with geospatial data together with spatial risk/catastrophe modeling and/or environmental modeling\n",
       " Advanced knowledge of machine learning methods and statistical principles, including experience in Bayesian statistics, anomaly detection, and/or time series forecasting\n",
       " Well versed in Python or R (and willingness to continue to learn the Python ecosystem)\n",
       " Proven experience designing and delivering solutions using large, real-world datasets to support business decisions\n",
       " Benefits\n",
       " Mission Driven - Some companies use AI to serve better digital ads and trade stocks, we seek to make our communities safer and more resilient.\n",
       " Top Compensation - Competitive compensation package.\n",
       " Best in Class Medical Coverage - 100% benefits and premiums paid.\n",
       " Prime NoHo Location - Our office sits in the heart of NYC's historic NoHo district and is just minutes away from the BDFM and 6 subway lines.\n",
       " Health Perks - Gym reimbursement and citibike membership.\n",
       " Strong Culture - collaborative office focused on teamwork, humility, and hustle.\n",
       " Catered lunch on Thursdays, plus a kitchen filled with snacks and drinks.\n",
       " \n",
       " ,\n",
       " requirements for improving product\n",
       " Present at industry conferences\n",
       " Up to 30% travel\n",
       " Document design, code, benchmarks, PoCs, etc.\n",
       " Requirements\n",
       " BS in Computer Science or related field; MS or PhD in related field preferred\n",
       " 4+ years of industry experience in a data science role\n",
       " Experience building predictive models using machine learning algorithms\n",
       " Fluent with scripting (Python /R); experience with other OO languages preferred\n",
       " Experience with distributed platforms; Hadoop or Spark preferred\n",
       " Strong customer interaction experience\n",
       " Experience with complex customer requirements/organizations\n",
       " Strong knowledge of at least one specific industry (e.g. banking, healthcare, insurance)\n",
       " Excellent communication, organizational, and problem solving skills\n",
       " ,\n",
       " Requirements\n",
       " Basic Requirements:\n",
       " Masters degree in a quantitative, scientific, or engineering field, or > 2 years experience in a data-related work environment\n",
       " Intermediate-to-advanced level proficiency in either R or Python\n",
       " Knowledge of modeling algorithms for supervised learning\n",
       " Familiarity with Linux/Unix operating system, shell environments and using remote machines\n",
       " Beginner-to-intermediate level proficiency of postgres SQL\n",
       " Preferred Skills:\n",
       " Doctoral degree in a quantitative, scientific, or engineering field, or > 4 years experience in a data-heavy work environment\n",
       " Experience with AWS services (Redshift / S3 / EC2)\n",
       " Experience with Databricks\n",
       " Familiarity with git and/or github.com, or any other version control framework\n",
       " Proficiency with Apache Spark (via Scala, Python, R or Java)\n",
       " Past work with survey data, demographic and consumer data, and/or TV viewing data\n",
       " Advanced knowledge of postgres SQL\n",
       " Benefits\n",
       " Comprehensive health and dental insurance for employees and their families\n",
       " Life insurance\n",
       " 401k with match, eligible for match after one year\n",
       " Pre-tax flexible compensation plan for medical, transit, parking or dependent care expenses\n",
       " 15 paid vacation days\n",
       " Sick days—if you’re sick, you stay home\n",
       " Work-from-home Fridays\n",
       " A kitchen stocked with sodas, snacks, yogurt and other goodies\n",
       " A tight-knit startup community who likes to eat! We celebrate everyone’s birthdays, have frequent team lunches, and do events in and out of the office\n",
       " 605 is an active participant in conferences\n",
       " ,\n",
       " requirements for enhancing audience targeting systems and processes\n",
       " 2. Build proofs of concept and prototypes\n",
       " 3. Manage/participate in scrum projects and sprints\n",
       " ,\n",
       " ideal candidate will exhibit strong leadership skills, the ability to work collaboratively in a team, and the flexibility to adapt to the changing needs of a fast-paced environment while maintaining a positive attitude.\n",
       " ,\n",
       " Key requirements\n",
       " Insurance domain expertise required\n",
       " Prior experience of running a practice and its operations is required\n",
       " Ability to work in a dynamic team environment to bring optimal solutions to our clients\n",
       " Experience leading large teams in a remote fashion\n",
       " Ability to attract top talent and grow the practice\n",
       " ,\n",
       " requirements concerning performance, stability, and availability\n",
       " Build, maintain, and expand the features of real-time APIs\n",
       " Collaborate with key business partners across product, editorial, and other engineers\n",
       " You need to have:\n",
       " Expertise in Python and Java\n",
       " 3+ years’ experience in implementing and using Classification techniques, Dimensionality Reduction algorithms, Recommendation Systems, and Optimization Algorithms\n",
       " Experience applying Machine Learning theory to tackle practical problems, while also leading projects from incubation to large scale production deployments\n",
       " 3+ years’ experience of Object Oriented Design working on backend systems\n",
       " 3+ years’ experience working on highly concurrent, real-time applications optimizing for low latency and high scalability\n",
       " Proficient in working with and evaluating open source technologies\n",
       " BA, BS, MS, PhD in Computer Science, Engineering or related technology field\n",
       " We'd love to see:\n",
       " Passion for working with large data sets\n",
       " Experience using Deep Learning techniques for recommendation and click-through rate prediction problems\n",
       " Experience with public cloud platforms like AWS, GCP, and Azure\n",
       " Interest in real-time distributed systems\n",
       " Ability to adapt cutting edge systems to enterprise requirements including high availability and disaster recovery\n",
       " ,\n",
       " qualification, bringing established sales methods to the sales process\n",
       " Develop organized and differentiated go to market activities\n",
       " Develop overview materials to support initial meetings/conversations\n",
       " Lead preparations for formal sales meetings and orals for qualified opportunities\n",
       " Provide support to core accounts without CREs as needed for critical opportunities\n",
       " Identify opportunities (sole source/up for bid) and bring it to the business (functional) partners, evaluate opportunity alignment with client strategy\n",
       " Identify and align appropriate firm resources to pursue, win, and manage opportunities\n",
       " Lead pursuit process, RFP responses, etc.\n",
       " Contribute to pursuit processes by leveraging relationships for insights and influence, including determining “win” themes, aligning messaging with client needs, supporting proposal/orals materials preparation, and participating in the orals session as appropriate\n",
       " Support pre-sales efforts leveraging depth of product knowledge / product demonstrations tailored to client environment\n",
       " Industry Expansion and Relationship Building\n",
       " Collaborate Alliance, Marketing and practice leads on messaging, events and eminence - both internal and external\n",
       " Identify ways the practice can expand/enhance visibility at key events and in the market\n",
       " Participate in key industry events to build relationships and develop business opportunities\n",
       " Identify key relationships across the industry which would benefit the AI I&E practice and develop plans to cultivate those relationships\n",
       " Utilize Deloitte eminence - including thoughtware, events, trainings, conferences, and memberships – to build and enhance relationships\n",
       " Utilize available offerings to develop and participate in activities and events focused on shared values and mission, e.g., Deloitte Greenhouse events, Client Experience labs etc.\n",
       " Market offering Support\n",
       " Support AI Managed Services market offering leadership in developing account and practice plans during the annual planning process\n",
       " Participate in market offering leadership calls and in person meetings, and assist with planning and preparation as needed\n",
       " \n",
       " \n",
       " \n",
       " \n",
       " ,\n",
       " requirements, working with technical resources to ensure timelines are met, collaborating with marketing to develop marketing assets and event planning, working with partner team to track partner relationship progress ensuring key milestones are met\n",
       " Hands on experience with Sales Enablement programs\n",
       " Ability to travel 40-50% of the time depending on customer events and sales team requirements including international travel\n",
       " ,\n",
       " qualification in Computer Science, Biostatistics, or other Quantitative Field from top school (PhD Preferred)\n",
       " Hands-on experience on writing production-level machine learning code\n",
       " Exposure to standard ML tooling – Python, R, and TensorFlow/Torch libraries\n",
       " Excellent communication skills\n",
       " Excellent critical thinking and problem-solving skills\n",
       " High motivation, good work ethic and maturity\n",
       " Role Description\n",
       " Work closely with VP of Data Science and Sales Team to map, execute and track technical AI/ML engagements with large clients in Healthcare, covering Payer, Life Sciences, Medical Technologies, and Provider markets\n",
       " Work in a high growth environment, with the goal of significantly augmenting the capabilities of the data science team, and the implementation of valuable technologies for our partners\n",
       " Lead a team or teams of US based / offshore based Data Scientists building ML solutions end-to-end\n",
       " High visibility role, interacts with execs from major players in healthcare industry\n",
       " Job Responsibilities\n",
       " Establish project scope and roadmap, including data strategy, needed to develop production-level predictive pipelines that solve large scale problems for clients in the space\n",
       " Help develop, implement and document rigorous methodology to plan, track and improve accuracy and relevance of models\n",
       " Lead internal communication with stakeholders, and ensure delivery of the project per commitment\n",
       " Collaborate with clients and other stakeholders to effectively integrate and communicate findings and use cases\n",
       " Provide guidance and project management support to the Associates on the team\n",
       " Experience building predictive models allows you to clearly determine team size and scope work needed to accomplish business goals\n",
       " Knowledge of databases, data modeling, and data harmonization a must\n",
       " Evaluate emerging technologies and alternative datasets that may contribute value to our existing platforms\n",
       " Contribute to the thought leadership of the company by publishing ML research and participating in relevant conferences in the space\n",
       " Healthcare data familiarity, especially around claims and clinical data, is highly desirable\n",
       "  CitiusTech's data science approach is based on 3 focus areas:\n",
       " Data Science Consulting - Creation of an end-to-end AI / ML roadmap for healthcare organizations, including use cases and end-state visuals\n",
       " Model Development - Data pre-processing, data quality improvement and data mining for the development of custom AI / ML models\n",
       " Model Operationalization - Validation, deployment and monitoring of selected data science models, to generate actionable insights\n",
       " About CitiusTech:\n",
       " CitiusTech is a specialist provider of healthcare technology services and solutions to healthcare technology companies, providers, payers and life sciences organizations. With over 3000 professionals worldwide, CitiusTech enables healthcare organizations to drive clinical value chain excellence, across integration & interoperability, data management (EDW, Big Data), performance management (BI / analytics), predictive analytics & data science, and digital engagement (mobile, IoT). CitiusTech helps customers accelerate innovation in healthcare through specialized solutions, healthcare technology platforms, proficiencies and accelerators. Armed with cutting-edge technology & expertise, world-class service quality and a global resource base, CitiusTech consistently delivers best-in-class solutions along with an unmatched cost advantage to healthcare organizations worldwide.\n",
       " ,\n",
       " requirement. What and how you can contribute is what's most important to us which is why our consideration is not limited by the level of education you have.\n",
       " ,\n",
       " Basic Qualifications:\n",
       " 3+ years of industry experience analyzing data sets and applying machine learning to assist decision making and solve industrial problems\n",
       " 3+ years of experience building and deploying scalable A.I. models using state of the art learning algorithms.\n",
       " 3+ years of experience on building models from ground up using python and packages like sklearn, pandas, xgboost, tensorflow and keras as well as tools such as Jupyter notebook\n",
       " Be able to communicate and illustrate developed algorithms to teammates and other teams.\n",
       " What Will Put You Ahead?\n",
       " ,\n",
       " ideal candidate will have a strong scientific background in computational sciences with experience developing interatomic potentials. Previous experience in professional software development is not required, but an interest in adopting best engineering practices is.\n",
       " ,\n",
       " ideal candidate will have the mathematical and statistical expertise you'd expect, but a natural curiosity and creative mind that's not so easy to find. We will rely on you to ask questions, connect the dots, and uncover opportunities that lie hidden within—all with the ultimate shared purpose of increasing user growth and engagement. You will lead a team of Data Scientists and help create new visions for the future.\n",
       " ,\n",
       " ideal candidate is energetic, patient, proactive, organized and passionate about Data Science and how it can be used to for social good and to positively influence organizations and people operations.\n",
       " ,\n",
       " Ideal candidate will be skilled in natural language processing, predictive and classification algos.\n",
       " Technically oriented, proactive, and enthusiastic, with extreme attention to detail.\n",
       " English written/verbal communication skills.\n",
       " ,\n",
       " requirements to develop analytic capabilities, platforms, and pipelines.Apply statistical or machine learning knowledge to specific business problems and data.\n",
       " Explore/Enlighten\n",
       " Formalize assumptions, create statistical definition of the outlier, and develop methods to systematically identify these outliers. Work out why such examples are outliers and define if any actions needed.Given anecdotes about anomalies or generate automatic scripts to define anomalies, deep dive to explain why they happen, and identify fixes.\n",
       " Make Decisions or Recommendations\n",
       " Build decision-making models and propose solution for the business problem you definedConduct written and verbal presentation to share insights and recommendations to audiences of varying levels of technical sophistication.\n",
       " ,\n",
       " ideal candidate is adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action. They must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. They must have a proven ability to drive business results with their data-based insights.\n",
       " \n",
       " ,\n",
       " requirements. Participate in the design process and\n",
       " integration strategy between Demand Planning and data repositories for varying Nestlé businesses.\n",
       " ,\n",
       " ideal candidate will have the academic depth sufficient to understand the implications of new machine learning solutions and directions.\n",
       " ,\n",
       " ideal candidate has worked in depth in identifying business insights through data analysis, including experience extracting and manipulating large scale data set using SQL, leveraging BI services such as QuickSight and Tableau for data analysis, and producing digestible business intelligence and actionable information. The candidate should also have strong communication and project management skills, enabling them to work with key business stakeholders to understand requirements and shape analytical deliverables. He/she should also have a demonstrated ability to think strategically and analytically about business, product, and technical challenges, with the ability to work cross-organizationally.\n",
       " ,\n",
       " requirements.\n",
       " apply expertise in data science to build data models and reports to anticipate customer behavior as well as provide growth forecasting and market predictions to inform strategic planning and business development decisions.\n",
       " further data deliverables through the optimization of data quality, including performing data analysis and data mining and applying predictive modeling theories to recommend solutions to complex business problems.\n",
       " utilize database reporting, programming and analytical tools (SQL, MySQL, R, Python, C, Tableau, Looker, Mixpanel, eCommerce, A/B testing, etc.) to perform data manipulation, data extractions and the merging of large and complex data.\n",
       " implement statistical models using SQL to analyze partner and user related data and understand customer behavior and preferences.\n",
       " interact with data source owners and contribute to the development and implementation of project plans and initiatives.\n",
       " mentor junior Data Scientists to cultivate their reporting and analytical skills.\n",
       " You’re a great fit for our team because...\n",
       " you have a Master’s degree or equivalent in Data Science, Operations Research, Statistics, Industrial Engineering or a related field\n",
       " you have three (3) years of data analytics, software development/engineering or related experience extracting, merging and analyzing data;\n",
       " you have three (3) years of utilizing Python and R to analyze and solve business problems; producing correct and efficient SQL queries;\n",
       " you have three (3) years of implementing statistical models; developing interfaces to help users;\n",
       " you have three (3) years of extracting and building data;\n",
       " you have three (3) years of providing statistical support to experiment design and analysis;\n",
       " you have three (3) years of utilizing various tools/technologies for data analysis including R, SAS, SPSS and Tableau.\n",
       " You’ll love it here because...\n",
       " you‘ll have huge potential to grow with a company that’s a category leader;\n",
       " you’ll have equity in a pre-IPO company backed by top VCs;\n",
       " we offer comprehensive medical, dental, and vision insurance with many plan options;\n",
       " we have lunch catered daily;\n",
       " you can stay on top of your fitness goals with our onsite fitness centers;\n",
       " we offer monthly fitness, phone and internet reimbursement;\n",
       " you can fuel up at our stocked kitchens with endless snacks and drinks;\n",
       " we prize EQ and empathy, and have a culture that emphasizes total wellness, including work-life harmony (read more about Credit Sesame’s Key Values here: https://www.keyvalues.com/credit-sesame).\n",
       " Office Location\n",
       " ,\n",
       " requirements.\n",
       " Performs quality review checks on project deliverables.\n",
       " Performs impact analysis of application changes across various components, holding an end-to-end view of the system.\n",
       " Estimates Rough Order of Magnitude for the level of effort/cost of new application functionality.\n",
       " Specifies / recommends integration and parallel testing criteria.\n",
       " Supports the implementation activities, troubleshooting system environmental issues, as required.\n",
       " Essential Job Functions:\n",
       " Analyze and interpret Customer insights from multiple data sources using statistical techniques.\n",
       " Support the deployment and business activation of new Customer data assets to drive operational efficiencies, improve customer experience, and drive growth.\n",
       " Combine data from structured & unstructured sources to Client and interpret new trends/patterns.\n",
       " Compare and contrast data across trusted sources to surface potential data quality issues.\n",
       " Liaise, collaborate, and support cross-functional stakeholders with their customer data needs.\n",
       " Propose data-driven solutions and strategies to business challenges.\n",
       " Present information using data visualization techniques.\n",
       " Support experimentation and deployment of predictive models that leverage customer data. Identify process improvement and efficiency opportunities.\n",
       " Requirements:\n",
       " High school diploma or equivalent required. Bachelor's degree preferred or equivalent, relevant experience.\n",
       " Recent 3-4 years of hands-on experience in a Data Analyst / Data Scientist role.\n",
       " Recent 3-4 years of hands-on experience performing advanced data analysis using Python.\n",
       " Technical expertise with data models, database design, data access, data mining, and data segmentation techniques.\n",
       " Advanced level knowledge and experience using Python in a Hadoop (HBase, Hive) environment.\n",
       " Advanced level experience using statistical packages for analyzing datasets & interpreting results.\n",
       " Strong analytical skills with the ability to combine, organize, and analyze large amounts of data and to tease-out and disseminate key information with attention to detail and accuracy.\n",
       " Experience with P&C insurance and/or customer data.\n",
       " Experience with data mining and/or machine learning (Client).\n",
       " Experience with SQL, Tableau, Alteryx.\n",
       " Experience developing Big Data capability job-aids for technical / non-technical end user.\n",
       "  To follow up with any questions, please contact Shabana at 408-907-2246\n",
       " ,\n",
       " ideal candidate will have experience with Big Data, Machine learning, Machine Vision, Natural Language Processing, and Data Mining, and also experience building dynamic applications using Python and other languages.\n",
       " ,\n",
       " requirements, find bottlenecks, and implement resolutions.\n",
       " Collaborate with the Analytics Tech lead to establish best practices for repeated application.\n",
       " Help mentor and develop the skillsets of the junior team members within your team or department.\n",
       " Work within a team of data analysts and engineers.\n",
       " REQUIRED\n",
       " 7+ years in data science or similar role in the marketing, finance, forensics or technology fields required.\n",
       " Extensive knowledge of machine learning techniques such as k-NN, Naive Bayes, SVM, Decision Forests, Data Mining, Clustering, and Classification.\n",
       " Experience in pushing models to production and iterating on models in production.\n",
       " Proficiency in statistics such as distributions, predictive modeling, data validation, statistical testing, and regression.\n",
       " 5+ years of experience in machine learning / statistical languages and systems such as Python, Matlab, R.\n",
       " Bachelor's degree in Computer Science or related field, with a strong quantitative background.\n",
       " Ability to develop and maintain good relations and communicate with people at all hierarchical levels.\n",
       " Strong problem-solving skills.\n",
       " Ability to reconcile technical and business perspectives.\n",
       " Autonomy and entrepreneurship.\n",
       " Strong team spirit.\n",
       " Passion for Rockstar Games and our titles.\n",
       " PLUSES\n",
       " ,\n",
       " ideal candidate is excited to help guide the direction of our product and company. They will have a significant amount of ownership of critical technical components. Our team is growing rapidly and we hope you'll grow with us too!\n",
       " ,\n",
       " requirements, and then deliver solutions that either leverage existing academic and industrial research, or utilize your own out-of-the-box pragmatic thinking. In addition to coming up with novel solutions and prototypes, you may even need to deliver these to production in customer facing products.\n",
       " ,\n",
       " Requirements for all data scientists\n",
       " Demonstrable expertise building and supporting machine learning models deployed to production\n",
       " Expert in Python and core libraries used by data scientists (Numpy, Scipy, Pandas, Scikit-learn, Matplotlib/Seaborn, etc.)\n",
       " Experience using Jupyter notebooks\n",
       " Experience working with large or fast moving data sets\n",
       " Qualified for one of the the specializations below\n",
       " Specialization: Machine Learning\n",
       " Scikit-learn expert: This means you have rolled your own transformers and estimators, which you chained together in a pipeline and found optimal hyperparameters via a randomized grid search (or some other method).\n",
       " Pandas and Numpy expert: You have used pandas enough to run into its rough parts. Very likely you read Wes’ book. You are fluent with Numpy and array oriented programming in general.\n",
       " Modern techniques: You are deeply familiar with different validation pitfalls, understand how to effectively ensemble several models, and have experimented with different hyperparameter optimization methods.\n",
       " Modern data: You have built models using unstructured data such as text or images. You have built time series models using econometric approaches as well as machine learning approaches. Deep algorithmic understanding: You know all the nitty-gritty details of your favorite machine learning algorithms.\n",
       " Specialization: Marketing\n",
       " Statistical rigor: You should have a solid foundation of the statistics behind standard statistical design methods such as A/B testing and multivariate testing. For example, you should know how to deal with clustering and should be able to determine the standard errors of different statistics through simulation.\n",
       " Multi-armed bandit models: You know how to implement the technique and how to write a good cost function.\n",
       " Modern techniques: You can build a model that powers an app that serves a unique arrangement of diverse components to each user such that the specific components served were chosen to maximize the specific user’s probability of selecting a call to action (i.e. using machine learning to identify complex heterogenous treatment effects).\n",
       " War stories: You must be able to talk about times you ran experiments in a complex environment and what you learned from the effort\n",
       " Specific experience in marketing optimization is a plus.\n",
       " Specialization: Insurance\n",
       " Industry experience: You have solid P&C experience and have had a significant role in building either pricing or underwriting models.\n",
       " Insurance algorithms: Regulators love GLMs. You must be an expert in GLMs.\n",
       " Modern tools: Maybe you used SAS in the past, but know you should be comfortable building models with Python.\n",
       " More details\n",
       " Salary: We invest in first-rate people and pay top-of-market salaries for most positions, factoring in experience, talent and location. We do not offer equity.\n",
       " Benefits: Medical, dental, vision, 401(k), wellness reimbursement, four weeks of vacation + six weeks of parental leave, and great work-life balance. Our office building offers on-site shower and bike stalls, and panoramic views of San Francisco.\n",
       " Location: Due to COVID-19 our teams are all working remotely through 2020. We provide an in-home office set-up including laptop, monitor, ergonomic desk, chair and other items as needed\n",
       " Location: Post COVID-19: San Francisco, CA near Montgomery Bart Station\n",
       " To apply for this role, you must complete a simple tech challenge based on the specialization you choose. Each specialization has a unique coding exercise.\n",
       " ,\n",
       " Ideal candidates would have experience productionizing Machine Learning models & systems at scale.\n",
       " The MLE’s will optimize and design machine learning solutions that are leveraged by a wide set of applications Search Ranking, Recommendation and Personalization, Computational Advertising, Query Understanding, Image Understanding and many more.\n",
       " Examples of such work could include:\n",
       " Integrating session based embeddings into our reranking models for multiple products.\n",
       " Incorporating real time data streams to produce highly predictive features for our models.\n",
       " Approximate Nearest Service that can be leveraged for candidate set generation.\n",
       " Designing & leveraging a multi-objective framework to optimize models for business constraints.\n",
       " Responsibilities:\n",
       " Design & Build ML (engineering) solutions that unlock new ML modeling capabilities, taking Etsy closer to state of the art machine learning techniques that would help solve various product problems.\n",
       " Collaborate with Applied Scientists to explore & productionize model improvements.\n",
       " Establishing the shared data processing that unlocks feature & knowledge sharing between our models for multiple product lines.\n",
       " Design, prototype and build machine learning systems, frameworks, pipelines and tools that process massive data for ML tasks (training, inference & evaluation).\n",
       " Propose, validate and iterate on ideas that can significantly improve machine learning solutions in terms of multiple system constraints (for example: compute costs).\n",
       " Collaborate with cross-functional teams including different product teams, infrastructure teams and platform teams to identify short-term and long-term plans for a machine learning solution.\n",
       " Guide & mentor junior members of the team.\n",
       " ,\n",
       " Requirements\n",
       " Strong proficiency in Python, SQL\n",
       " Strong foundation in statistics\n",
       " Experience building data visualizations\n",
       " Experience writing software in a professional environment\n",
       " Strong verbal and written communication skills\n",
       " Strong problem-solving skills to help refine problem statements and figure out how to solve them with the available data\n",
       " Smart but humble, with a bias for action\n",
       " \n",
       " ,\n",
       " requirements (online learning, large data sets, reinforcement learning, recommender systems, etc.)\n",
       " Discover, understand, and apply cutting-edge statistical and machine learning techniques with novel applications to e-commerce, marketing, and supply chain problems\n",
       " Assist product management and engineering in building full-featured products based on your research\n",
       " Assist sales, marketing, and client services in taking products based on your research to market and effectively communicating their value to clients and prospects\n",
       " ,\n",
       " requirements\n",
       " Develop state-of-the-art approaches in the areas described above, as applied to our unique problems\n",
       " Projects you might work on\n",
       " Improving the tooling and pipelines that allow us to develop models at scale\n",
       " Developing and optimizing models for multiple tasks of interest\n",
       " Extending models to optimize execution and pull in more functionality such as tracking or motion prediction\n",
       " Developing robust APIs for easy interfacing with internal and external software components\n",
       " People we're looking for have the following required education and experience\n",
       " 5+ years of professional work experience as a machine learning and/or software engineer\n",
       " MS in Computer Science or Engineering, similar degree, or equivalent practical experience\n",
       " Experience with contributing to large and complex software projects\n",
       " Practical experience with machine learning frameworks such as PyTorch and TensorFlow\n",
       " Competencies\n",
       " Deep learning model development\n",
       " Software Engineering\n",
       " C++\n",
       " Python\n",
       " TensorFlow\n",
       " Caffe/Caffe2\n",
       " PyTorch\n",
       " scikit-learn\n",
       " OpenCV\n",
       " Multi-threaded development\n",
       " Excellent communication skills\n",
       " Preferred qualifications\n",
       " Experience producing, deploying, and improving production models\n",
       " Experience with ROS\n",
       " Experience with CUDA\n",
       " Passion for solving problems that make a difference\n",
       " If you're interested in being part of our team, apply now!\n",
       " ,\n",
       " requirements for data/process integrity\n",
       " Coordinate with the IT team to buy or license required tools, data and feeds\n",
       " Work with the IT team as they set up the necessary infrastructure and processes to support predictive analytics, e.g., ETL from the ERP system to data warehouse/lake\n",
       " Determine how and when to take and store “snapshots” of data so that we can go back in time to test new models and approaches\n",
       " ,\n",
       " Requirements:\n",
       " BA/BS degree required with technical focus (Statistics, Econometrics, Computer Science, Physics, Engineering or a related quantitative field); MS/PhD a plusStrong technical skills with SQL, R/ Python for data analysis; demonstrated programming skills either in data science or software development settings a plusExperience building supervised and unsupervised data models in R or PythonDeep understanding of AB testing, experimentation, and causal inference methodologiesSkilled at deriving narrative from data and communicate the results effectivelyPlay games, with a solid understanding of user engagement and monetization strategies in gaming, entertainment/ecommerce service providers, or mobile apps a plusWork experience in cross-functional teams a plusDeep product sense, with a solid understanding of user engagement and monetization strategies in gaming, entertainment/ecommerce service providers, or mobile apps a plus\n",
       " ,\n",
       " ideal candidate loves mining, analyzing, and utilizing data to influence real business outcomes.\n",
       " ,\n",
       " ideal candidate will be able to independently leverage statistics to derive meaningful and actionable insights about our audience of online services.\n",
       " Use of statistics to understand the key drivers for decision making among our customers\n",
       " Help improve the audience experience by giving actionable recommendations based on data analysis\n",
       " Creation of descriptive and predictive data models to describe user behavior and preferences\n",
       " Statistically based viewer segmentation and clustering\n",
       " Leverage predictive analytics to influence business decisions\n",
       " Build micro and macro level forecasts based on past and current data\n",
       " Create meaningful statistical reports and visualizations\n",
       " Give insight to business owners in the form of reports, presentations, and visualizations\n",
       " Ad hoc requests\n",
       " ,\n",
       " ideal candidate will have industry experience in developing recommendation systems and shipping ML models that boost user engagement. You’ll apply quantitative analysis, modeling and data mining to improve our pinners’ and partners’ experience.\n",
       " What you’ll do:\n",
       " ,\n",
       " REQUIREMENTS\n",
       " High School\n",
       " QUALIFICATIONS\n",
       " Proficient in Microsoft OfficeExcellent Excel skills2 years inventory experienceDetail oriented and thorough\n",
       " ,\n",
       " requirements, questions, investigations into a set of queries\n",
       " Ability to search data and meta-data without mature documentation\n",
       " Advanced Excel/Google Sheet/Tableau proficiency to present data as an intuitive story\n",
       " Ability to make data interoperate between different environments/systems (ELT/ETL chops)\n",
       " Mastery in complex CRUD operations for new requirements and also for debugging purposes\n",
       " Bachelor's degree or higher in quantitative or related field.\n",
       " ,\n",
       " requirements into reporting designs, predictive and statistical analysis, data cleansing, and visualizing business data.One (1) year of experience using analytics environments necessary for specific job duties (Tableau, R, Python, etc.)Eligible to obtain a SECRET level security clearance (final SECRET clearance required if tasking includes access to classified systems).\n",
       " ,\n",
       " key requirements.\n",
       " Some of the job responsibilities include, but not limited to:\n",
       " Developing multiple aspects of graphics software driver development and simulation environment development.\n",
       " Works with various partners to enhance and improve graphics performance on upcoming processor graphics devices by analyzing performance issues in software drivers and applications, implementing software performance improvements, and recommending future hardware & software improvements.\n",
       " Providing internal and external feedback to implement upcoming graphics features in yet-to-be- released OSes to ensure our hardware and software will function and perform as expected on next generation platforms as well as designing/developing/implementing graphics system-level software for future platforms.\n",
       " This is an entry level position and will be compensated accordingly.\n",
       " ,\n",
       " requirements underlying feature requests, recommend alternative technical and business approaches, and lead engineering efforts to meet aggressive timelines with optimal solutionsExcellent communication, presentation, and interpersonal skills.\n",
       " ,\n",
       " requirements, ability to translate & implement solutions in a scalable and consistent way using applicable tools Ability to translate business requirements, work with various levels of business stakeholders to create innovative design solutions Design, develop & own, team collaboration sites, portal, periodic content modifications Automate team dashboards, metrics delivery & executive presentation using tools outlined Drive operational excellence activities required to ensure a streamlined production process of our data science deliveries Role will be a hybrid of project management, process improvement & tooling for Global Data Sciences (GDS) Drive coordinated management of inter-dependent projects in Agile and waterfall environments Manage project/program level communications both between and across GDS & its customers Ensure timely delivery of projects & measurable KPIs are documented\n",
       " ,\n",
       " ideal candidate will have a strong background working with data, experience applying machine learning and deep learning techniques to real-world problems, and a natural curiosity and desire to experiment, evaluate and solve problems as part of a fast-paced and growing, product-driven technology team.\n",
       " ,\n",
       " ideal candidate will have extensive experience with design, development and operations that leverages deep knowledge in the use of services like Amazon Kinesis, Apache Kafka, Apache Spark, Amazon Sagemaker, Amazon EMR, NoSQL technologies and other 3rd parties.\n",
       " ,\n",
       " requirement. Two to three years of professional post-baccalaureate experience preferred\n",
       " ,\n",
       " ideal candidate has a broad and deep background in machine learning and deep learning, is passionate about science, is highly driven to learn and deploy new technologies, thrives in a fast-paced environment that requires the development of solutions to ambiguous and challenging problems, and enjoys collaborating with both technical and nontechnical peers.\n",
       " ,\n",
       " ideal candidate has a rich experience across the domains of Marketing, Sales and Product as a data scientist / decision scientist. You will leverage business data, big data, statistical analysis, machine learning and other advanced techniques to help DocuSign drive customer acquisition, upsell, cross-sell and retention. You will partner closely with other data scientists and analysts in marketing, sales, customer success, product engineering and finance.\n",
       " ,\n",
       " requirements from stakeholders into clear and concise machine learning requirements.\n",
       " Significant experience working with relational databases and SQL.\n",
       " Experience with Neural machine translation (NMT) is a plus.\n",
       " Experience working with continuous integration (e.g. Jenkins) is a plus.\n",
       " Expert in identifying algorithmic solutions and implementing them to solve business problems.\n",
       " Expert in working with computer vision and/or signals processing.\n",
       " Expert development skills in Java, Python, C++, and R.\n",
       " Experience in managing large numbers of stakeholders on complex projects with varying timelines and multiple deliverables.\n",
       " Expertise in synthesizing results of complex topics to share with non-technical audiences.\n",
       " Strong theoretical understanding of linear algebra, multivariate calculus, differential equations, and multilayer perceptrons.\n",
       " Demonstrable knowledge working on large computer vision and signal processing problems.\n",
       " Demonstrable expertise in algorithm design.\n",
       " Strong knowledge of automated regression testing.\n",
       " Love of TV, Movies, Games, and Comics is a Plus!\n",
       " ,\n",
       " ideal candidate typically loves (and is capable of) testing and proving complex theorems and conjectures of her/his own, but prefers industry over academia as she/he is eager and impatient to see the impact of her/his work in real-life. She/he never shies away from finding closed-form solutions to complex mathematical problems, but she/he can also gauge the merits of numerical methods as an alternative when appropriate. As much as this is not an engineering role, the ideal candidate should be able to write prototype-quality Python code to test found mathematical results.\n",
       " ,\n",
       " requirements, processes as well as limitations of existing systems.\n",
       "  Apply data mining, quantitative analysis and visualization techniques to examine existing business status and identify opportunities for improvements.\n",
       "  Analyze and validate real-world data, work with engineering and product management teams to design solutions to improve data quality.\n",
       "  Identify key drivers for business growth through data driven processes and create insights for enhancement strategies using data driven progresses.\n",
       "  Build prototypes to demonstrate and validate improvement proposals.\n",
       "  Summarize and document findings to communicate with senior leaderships.\n",
       " \n",
       " ,\n",
       " requirements, propose AI software solutions to meet the business requirements, deliver and present AI software to clients\n",
       " Understand the data set used for the modeling, prepare and preprocess data sets, train and test models and perform model feature engineering\n",
       " Document data dictionary, data understanding, modeling strategy and approaches, and build company’s knowledge base of data and models\n",
       " Communicate effectively with team members, management, and clients\n",
       " Requirements\n",
       " 5-8 years of the latest machine learning/AI technology\n",
       " Proven ability to work with large structured and unstructured datasets\n",
       " Demonstrable, hands-on experience in developing advanced analytics algorithms/models, including time series forecasting, machine learning and deep learning, image processing, natural language processing, and speech recognition\n",
       " Excellent hands-on code development skills in Python\n",
       " Good Knowledge of Machine Learning frameworks and packages, including Keras, TensorFlow, MXnet, Scikit-Learn and cloud technology (Amazon, Azure, etc.)\n",
       " Experiences in Machine Learning, Deep Learning, Computer Vision, and Natural Language Processing\n",
       " PhD degree in Mathematics, Statistics, Computer Science, or related disciplines\n",
       " At least 3 years of Artificial Intelligence\n",
       " At least 3 years of Machine Learning\n",
       " Background in Property and Casulity Insurance a big plus!\n",
       " You must be able to work out of our Houston office\n",
       " Additional Qualifications\n",
       " Parallel and distributed processing experience is a plus\n",
       " Expertise in data Extraction Transformation and Loading (ETL) is a strong plus (Spark, Hadoop, SQL) in big data environments.\n",
       " Domain knowledge in financial and insurance industries is a big plus\n",
       " The candidate must be able to work out of the Houston Texas office but remote work will be considered for extremly strong candidate\n",
       " Relocation reimbursement is available for the right candidate\n",
       " ,\n",
       " requirements that our customers have for data analytics based on current needs and cutting-edge industry trends.\n",
       " Selecting and developing data science and analytics tools that will fulfill our customers? needs and strengthen ThinkIQ’s position as a leader.\n",
       " Assembling data analytics solutions from commercially available or open source components and systems.\n",
       " Guiding our customers and partners in how to use ThinkIQ’s system to do data analytics. Be the external thought leader that our customers? trust.\n",
       " Working with product management to create a roadmap for ThinkIQ data analytics that will map into our overall roadmap and properly leverage new technologies.\n",
       " ,\n",
       " ideal candidate for Data Scientist at Alexa should have strong data mining and modeling skills and is comfortable facilitating idealization and working from concept to execution. The candidate will be an individual contributor who is comfortable with ambiguity and able to successfully drive projects to completion. In addition to the modeling and technical skills, the candidate should possess strong written and verbal communication skills, strong focus on internal customers and high intellectual curiosity with the ability to learn new concepts/frameworks, algorithms, and technology rapidly as changes arise.\n",
       " Data Scientist at Alexa will design, evangelize, and implement solutions to address complex, business questions using advanced statistical techniques, experimentation, and big data. You will be interacting with science and research teams to define metrics that drive key business decisions, and working with program managers, quality assurance engineers and software developers, to develop data pipelines, build tools to drive continuous experimentation to generate data set, conduct statistical analyses, and provide actionable insights for business decisions. Key responsibilities:\n",
       " Adopt best practices and implement strategies for data audit, data integrity, and validationUtilize code (Python, R, Scala, etc.) for analyzing data and building statistical models to solve specific business problemsApply or design highly innovative models for predictive learning, content ranking, and anomaly detectionAnalyze and extract relevant information from large amounts of historical data to help automate and optimize key processesAnalyze key metrics to uncover trends and root causes of issuesCommunicate verbally and in writing to business customers and leadership team with various levels of technical knowledge, and share insights and recommendations\n",
       " ,\n",
       " ideal candidate will have previous experience leading data scientists and engineers perfecting machine learning products, and a passion for building agile, high-performing teams.\n",
       " Responsibilities:\n",
       " Build and direct your team of data scientists in the ML evaluation work of our AI Drive Through Product\n",
       " Collaborate with technology, engineering, and other data science team leaders to define success of machine learning software development lifecycle.\n",
       " Create and own overall ML model and system evaluation datasets, methodology, process and frameworks\n",
       " Craft test cases and regressions suites for ML models operating at petabyte scale.\n",
       " Employ data mining and statistical techniques to tackle diverse and large-scale ML data challenges.\n",
       " Provide cross-functional teams and leadership with regular updates and strategic guidance regarding ML model quality through evaluation test framework\n",
       " ,\n",
       " ideal candidate will be comfortable working with datasets across a variety of systems (SQL, Firebase,...).\n",
       " ,\n",
       " ideal candidate is a bioinformatician / computational biologist with success in leading research studies combining next-generation sequencing data with various forms of phenotypic, transcriptomic, metabolomic, and other clinical data. She or he will have an extremely strong background in statistics and data analysis including techniques for the quality control of NGS data and the proper handling of missing data.\n",
       " ,\n",
       " requirements\n",
       " Curriculum Vitae - Your most recently updated C.V.\n",
       " Cover Letter\n",
       " ,\n",
       " requirements to help manage overall project scope.\n",
       " 8. Discover, explore, analyze and document data from all source and target systems to better understand the total scope of data availability at IEHP.\n",
       " 9. Identify, analyze and interpret trends or patterns in complex data sets, draw meaningful business insight and translate them to a self-service report.\n",
       " 10. Identify and communicate issues and risks to management in a timely manner.\n",
       " 11. Contribute towards reporting security requirements, architecture, design and implementation, including the definition of comprehensive security controls to enforce the IEHP security strategy.\n",
       " 12. Contribute to development and enforcement of IEHP reporting standards.\n",
       " 13. Gathers, selects, compiles and analyzes health plan data, with emphasis on data maintained with data warehouse.\n",
       " 14. Establish and maintain effective working relationships with others throughout the IEHP organization.\n",
       " 15. Provide ongoing proactive technical support for data science and reporting systems to ensure business continuity, analytic accessibility and reporting accuracy.\n",
       " 16. Demonstrate a commitment to support IEHP’s strategic priorities to become a 5-Star Health Plan and incorporate LEAN principles into daily work. Supervisory Responsibilities Leading: Self Experience Qualifications\n",
       " ,\n",
       " ideal candidate has proven ability to take on underspecified customer problems and lead the team from the formulation of concrete viable solution approaches to fully implemented and deployed solutions that ship in the product. You will work with product managers and development teams across ServiceNow to get partnerships in place, and solutions implemented. Having demonstrated experience working across functions while maintaining deep technical expertise is key to succeeding in this role. Ideally, you are someone who is known in the industry to successfully take on challenging problems that not many people have solved before.\n",
       " What you get to do in this role:\n",
       " Specifically, you will\n",
       " Understand the top AI/NLU/NLQ business use cases that ServiceNow product teams want to go to market with in their products.\n",
       " Work with other senior leaders in Predictive and Language intelligence team and other relevant teams to come up with concrete formulations that align the business process and customer objectives with what is feasible with state-of-the-art ML/AI/NLU/NLQ techniques\n",
       " Have a deep understanding of various ML/AI/NLU/NLQ techniques and technology stacks, in particular what is “enterprise-ready”, and guide the development team in its implementation choices with a view to delivering reliable solutions that customers can adopt quickly.\n",
       " Work with Strategy team to solidify a rubric to evaluate external offerings.\n",
       " Have an understanding of the full product development lifecycle from prototyping to development to deployment to support and make solution recommendations that deliver customer expectations while lowering support burden.\n",
       " Have enough technical depth to be hands-on and take on some of the more challenging tasks to help the team deliver\n",
       " Develop innovative patentable ideas that ensures the competitiveness of this product within the domain of similar work being done in the industry\n",
       " Lead by example and deliver key asks from internal constituents\n",
       " Communicate extensively with internal and external stakeholders\n",
       " ,\n",
       " Requirements\n",
       " The team operates in a production setting. An ideal candidate has strong software engineering practices and is very comfortable with Python programming, debugging/profiling, and version control.\n",
       " We train neural networks on a cluster in large-scale distributed settings. An ideal candidate is very comfortable in cluster environments and understands the related computer systems concepts (CPU/GPU interactions/transfers, latency/throughput bottlenecks during training of neural networks, CUDA, pipelining/multiprocessing, etc).\n",
       " We are at the cutting edge of deep learning applications. The ideal candidate has a strong understanding of the under the hood fundamentals of deep learning (layer details, backpropagation, etc). Additional requirements include the ability to read and implement related academic literature and experience in applying state of the art deep learning models to computer vision (e.g. segmentation, detection) or a closely related area (speech, NLP).\n",
       " Experience with PyTorch, or at least another major deep learning framework such as TensorFlow, MXNet.\n",
       " Some experience with data science tools including Python scripting, numpy, scipy, matplotlib, scikit-learn, jupyter notebooks, bash scripting, Linux environment.\n",
       " ,\n",
       " requirements and understand business problems. Uses advanced mathematical, statistical, querying, and reporting methods to develop solutions. Develops information tools, algorithms, dashboards, and queries to monitor and improve business performance. Creates solutions from initial concept to fully tested production, and communicates results to a broad range of audiences. Effectively uses current and emerging technologies.\n",
       " ,\n",
       " requirements and/or changing the way this job is performed, provided that such accommodations do not pose an undue hardship.\n",
       " Click the following link for more information on your rights as an Applicant : http://www.capgemini.com/resources/equal-employment-opportunity-is-the-law\n",
       " About Capgemini\n",
       " A global leader in consulting, technology services and digital transformation, Capgemini is at the forefront of innovation to address the entire breadth of clients’ opportunities in the evolving world of cloud, digital and platforms. Building on its strong 50 year heritage and deep industry-specific expertise, Capgemini enables organizations to realize their business ambitions through an array of services from strategy to operations. Capgemini is driven by the conviction that the business value of technology comes from and through people. It is a multicultural company of 200,000 team members in more than 40 countries. The Group reported 2018 global revenues of EUR 13.2 billion.\n",
       " ,\n",
       " Nice to have:\n",
       " ,\n",
       " Basic qualifications (by time of application):\n",
       " PhD (or equivalent international degree) or enrolled in a PhD (or equivalent international degree) program.\n",
       " ,\n",
       " requirements and oversee study, project, or integration programming efforts to ensure the timely delivery of high-quality output according to company and industry standards. Represent statistical programming in the review of key study and project documents and data set or reporting specifications. Recognize inconsistencies and initiate resolution of data problems when necessary. Assist programming management with or be the lead on cross-functional process improvement initiatives and resource allocation. May oversee activities performed by FSP or contract programmers.\n",
       " \n",
       " ,\n",
       " Nice to haves:\n",
       " ,\n",
       " requirements are highly desired\n",
       " ,\n",
       " requirements to define the strategy for data powered features across the Meraki platform\n",
       " Define the strategy for product analytics to establish a deep understanding of engagement and customer behavior\n",
       " Champion product insights to guide data informed decisions and product development across teams\n",
       " Develop an investment strategy on problems that should and should not be solved using machine learning methods and data infrastructure investments\n",
       " Work closely with our data science, data engineering, analytics, architects teams to continue to simplify our outstanding user experience\n",
       " Team up with our rapidly growing sales teams and partners to seek customer problems\n",
       " What we're looking for\n",
       " 5+ years of validated experience in a Product Management role\n",
       " Technical background working on products with an Al/ML component\n",
       " Deep expertise in product analytics (measurement, conversion funnels, customer retention)\n",
       " Have worked cross-functionally on large projects with multiple engineering teams\n",
       " BA/BS in Statistics, Mathematics, Computer Science, Information Systems, Engineering or related degree\n",
       " You have a real dedication for learning about networking, cloud, and emerging ground-breaking technologies\n",
       " You have a strong sense of customer empathy to care deeply about top customer problems\n",
       " You are able to easily communicate complicated concepts simply to multiple audiences\n",
       " You have a results-oriented, can-do demeanor with an intuitive understanding of product quality\n",
       " You love solving technical problems in innovative ways\n",
       " ,\n",
       " requirements:\n",
       " An inquisitive mind with the ability to learn where the data exists in a large and disparate system and what that data means\n",
       " The ability to create tools that programmatically turn data into usable information\n",
       " ,\n",
       " Requirements:\n",
       " Strong background in statistical theory and application\n",
       " Experience in data mining, machine learning, time-series analysis, or similar analytical disciplines\n",
       " 2+ years of experience with R and Python (special consideration for experience with pandas, NumPy, and SciPy and machine learning libraries such as scikit-learn, TensorFlow, and PyTorch)\n",
       " Experience with distributed computing, including frameworks such as Spark\n",
       " Excellent written and verbal communication skills\n",
       " Master’s or Ph.D. in geography, statistics, econometrics, computer science or related field, depending on position level\n",
       " The Company:\n",
       " Our passion for improving quality of life through geography is at the heart of everything we do. Esri’s geographic information system (GIS) technology inspires and enables governments, universities, and businesses worldwide to save money, lives, and our environment through a deeper understanding of the changing world around them.\n",
       " ,\n",
       " Requirements:\n",
       " Below are general guidelines on the position's physical, mental, and environmental working conditions.\n",
       " In accordance with applicable state and federal law, UCI provides reasonable accommodations for applicants with disabilities upon request. For more information, please contact Human Resources at (949) 824-0500.\n",
       " ,\n",
       " requirements, acceptance criteria and test cases\n",
       " Interpret data and analyze the results with statistical technical and provide ongoing reports\n",
       " Collaborate with the automatic bench marking team to extract data from our systems\n",
       " Pattern and Descriptive Analysis\n",
       " Generate exposure analysis\n",
       " Conduct research to support the requirements\n",
       " Develop and manage product-related documentation such as datasheet, application notes, customer survey\n",
       " Use data to interpret and analyze traffic conditions or patterns\n",
       " ,\n",
       " requirements into problem definitions, dealing with ambiguity and competing objectivesStrong communication and data presentation skills\n",
       " ,\n",
       " Requirements:\n",
       " Graduate (PhD preferred) degree in Statistics, Computer Science, Engineering, or equivalent experience\n",
       " 7+ years experience in Data Science, Business Analytics, Deep Learning, Statistical Research or a related field\n",
       " Hands on experience with large scale data processing software and tools (Hadoop, Spark, MapReduce etc)\n",
       " Strong coding experience and knowledge of object oriented programming\n",
       " #LI-WISHX\n",
       " ,\n",
       " Requirements:\n",
       " MA/MS or PhD degree in computer science, artificial intelligence, machine learning, speech recognition, natural language processing, operations research, or related technical field.\n",
       " 4+ years of Experience designing and implementing machine learning pipelines in production environments.\n",
       " Working knowledge of current techniques and approaches in machine learning and natural language processing: text categorization, text summarization, information retrieval, question answering, sentiment analysis, semantic parsing, etc.\n",
       " Strong Experience with one or more general purpose programming languages including but not limited to: Java, Scala, or Python.\n",
       " Experience with Apache Spark platform (including Datasets, SparkML) and/or experience with one or more deep learning libraries and platforms (e.g., TensorFlow, Caffe or PyTorch).\n",
       " Creative thinking and a keen interest in brainstorming ideas for the next generation of data products.\n",
       " Additional Details\n",
       " Experience with Cloud Native Frameworks tools and products is a plus\n",
       " ,\n",
       " requirements.\n",
       " Excellent communication & leadership.\n",
       " We develop real products. You need to be an expert in coding, including Java and Object-Oriented Programming. We also use Scala and Functional Programming principles.\n",
       " We prioritize professional industry experience; advanced degrees alone do not replace real world experience.\n",
       " We have massive scale. You need to have experience in distributed, scalable systems. Consistency / availability tradeoffs are made here. You’ve tinkered with modern data storage, messaging, and processing tools (Kafka, Spark, Hadoop, Cassandra, etc.) and demonstrated experience designing and coding in big-data components such as HBase, DynamoDB, or similar.\n",
       " ,\n",
       " Requirements\n",
       " Bachelor’s degree or higher in quantitative discipline (e.g. Statistics, Computer Science, Mathematics, Physics, Electrical Engineering, Industrial Engineering) or the equivalent in experience and evidence of exceptional ability\n",
       " Advanced knowledge of Python\n",
       " Strong knowledge of data structures, architectures and languages such as SQL\n",
       " Solid understanding of statistics (Weibull distribution, Maximum Likelihood Estimation, Bayesian methods, Monte Carlo analysis, etc.)\n",
       " General knowledge of physics and engineering principles\n",
       " Working knowledge of the Hadoop ecosystem (HDFS, Spark, Presto and HBase)\n",
       " Experience and interest in data visualization techniques (e.g. Matplotlib, Superset, Tableau)\n",
       " Ability to problem solve and adjust priorities with little advance notice to meet deadlines\n",
       " Strong verbal and written communication skills\n",
       " ,\n",
       " requirements, propose AI software solutions to meet the business requirements, deliver and present AI software to clients\n",
       " Understand the data set used for the modeling, prepare and preprocess data sets, train and test models and perform model feature engineering\n",
       " Document data dictionary, data understanding, modeling strategy and approaches, and build company’s knowledge base of data and models\n",
       " Communicate effectively with team members, management, and clients\n",
       " Requirements\n",
       " Proven ability to work with large structured and unstructured datasets\n",
       " Demonstrable, hands-on experience in developing advanced analytics algorithms/models, including time series forecasting, machine learning and deep learning, image processing, natural language processing, and speech recognition\n",
       " Excellent hands-on code development skills in Python\n",
       " Good Knowledge of Machine Learning frameworks and packages, including Keras, TensorFlow, MXnet, Scikit-Learn and cloud technology (Amazon, Azure, etc.)\n",
       " Experiences in Machine Learning, Deep Learning, Computer Vision, and Natural Language Processing\n",
       " PhD degree in Mathematics, Statistics, Computer Science, or related disciplines\n",
       " At least 3 years of Artificial Intelligence\n",
       " At least 3 years of Machine Learning\n",
       " Background in Property and Casulity Insurance a big plus!\n",
       " You must be able to work out of our Houston office\n",
       " Additional Qualifications\n",
       " Parallel and distributed processing experience is a plus\n",
       " Expertise in data Extraction Transformation and Loading (ETL) is a strong plus (Spark, Hadoop, SQL) in big data environments.\n",
       " Domain knowledge in financial and insurance industries is a big plus\n",
       " The candidate must be able to work out of the Houston Texas office but remote work will be considered for extremely strong candidate\n",
       " Relocation reimbursement is available for the right candidate\n",
       " ,\n",
       " requirements. This is an excellent opportunity to join Amazon’s world class technical teams, working with some of the best and brightest engineers while also developing your skills and furthering your career within one of the most innovative and progressive technology companies.\n",
       " ,\n",
       " requirements and are considered a plus factor in identifying top candidates. Experience listed below would be obtained through a combination of your work experience, graduate school, post-doc research and/or relevant internship experiences.\n",
       " Minimum qualifications and experience:\n",
       " PhD in computer science, electrical engineering or similar technical discipline\n",
       " Strong software engineering background\n",
       " Strong mathematical background\n",
       " At least 5 publications in first-tier, highly selective international conferences such as CVPR, ICCV, ECCV, ICML, NeurIPS, ICLR, or SIGGRAPH\n",
       " Minimum of 5+ years of research experience with two or more of the following areas:\n",
       " machine learning\n",
       " motor control\n",
       " robotics\n",
       " optimization\n",
       " computer vision\n",
       " image processing\n",
       " computer graphics\n",
       " three-dimensional modeling\n",
       " Preferred qualifications:\n",
       " Strong software engineering experience demonstrated through publicly available software systems\n",
       " 10+ publications in first-tier, highly selective international conferences such as CVPR, ICCV, ECCV, ICML, NeurIPS, ICLR, or SIGGRAPH\n",
       " **By applying to this posting your resume and profile will become visible to Intel Recruiters and will allow them to consider you for current and future job openings aligned with the skills and positions mentioned above.\n",
       " Inside this Business Group\n",
       " ,\n",
       " requirements, as well as hands on involvement working with the tools and systems used by the team during the product release process.\n",
       " The Business Systems Analyst Intern role will be working with Analysts and Developers to create test cases used to validate development work performed to support the configuration of new products and services within Oracle’s internal quoting application. Test case creation and management will involve working with multiple software applications, including Excel, Jira, Confluence.\n",
       " Preferred Education and Experience:\n",
       " US Veteran transitioning from active service or Military Spouse new to corporate experience preferred\n",
       " BA/BS or equivalent life experience and exposure to one or more of these subject areas: Business Analysis, Business Analytics, Program or Project Management, Communications or related subject areas\n",
       " Ability to learn quickly in a challenging environment and work as part of a team to achieve objectives\n",
       " Strong problem solving skills and technical aptitude\n",
       " Detail oriented\n",
       " Strong verbal and written communication skills\n",
       " Familiarity with software development and testing process\n",
       " Working knowledge of Microsoft Excel\n",
       " ,\n",
       " ideal candidate participates in the pre-sales cycle but also in design, development, and implementation of customer’s Data/AI solutions utilizing Microsoft technologies like Azure Data platform, AI, Machine Learning, cognitive services, SQL Server (on-prem and on Azure), Power BI, SSAS, SSIS, and other related technologies. The candidate will also work with clients to understand, analyze, and refine the application requirements and, where needed, provides guidance on selection of appropriate data technologies from the varied choices of Data and AI platform.\n",
       " ,\n",
       " Basic Qualifications:\n",
       " Experience\n",
       " N/A.\n",
       " ,\n",
       " Nice to Have\n",
       " Experience working with biological data\n",
       " Experience working with medium-to-large size datasets\n",
       " Experience with data processing pipelines\n",
       " Experience working in a cloud environment (AWS, GCP, etc.)\n",
       " Proficiency in Python programming\n",
       " Benefits at Denovium\n",
       " Work 100% remote\n",
       " Excellent medical, dental, and vision coverage\n",
       " Open vacation policy\n",
       " About Denovium\n",
       " ,\n",
       " qualification, bringing established sales methods to the sales process\n",
       " Develop organized and differentiated go to market activities\n",
       " Develop overview materials to support initial meetings/conversations\n",
       " Lead preparations for formal sales meetings and orals for qualified opportunities\n",
       " Provide support to core accounts without CREs as needed for critical opportunities\n",
       " Identify opportunities (sole source/up for bid) and bring it to the business (functional) partners, evaluate opportunity alignment with client strategy\n",
       " Identify and align appropriate firm resources to pursue, win, and manage opportunities\n",
       " Lead pursuit process, RFP responses, etc.\n",
       " Contribute to pursuit processes by leveraging relationships for insights and influence, including determining “win” themes, aligning messaging with client needs, supporting proposal/orals materials preparation, and participating in the orals session as appropriate\n",
       " Support pre-sales efforts leveraging depth of product knowledge / product demonstrations tailored to client environment\n",
       " Industry Expansion and Relationship Building\n",
       " Collaborate Alliance, Marketing and practice leads on messaging, events and eminence - both internal and external\n",
       " Identify ways the practice can expand/enhance visibility at key events and in the market\n",
       " Participate in key industry events to build relationships and develop business opportunities\n",
       " Identify key relationships across the industry which would benefit the AI I&E practice and develop plans to cultivate those relationships\n",
       " Utilize Deloitte eminence - including thoughtware, events, trainings, conferences, and memberships – to build and enhance relationships\n",
       " Utilize available offerings to develop and participate in activities and events focused on shared values and mission, e.g., Deloitte Greenhouse events, Client Experience labs etc.\n",
       " Market offering Support\n",
       " Support AI Managed Services market offering leadership in developing account and practice plans during the annual planning process\n",
       " Participate in market offering leadership calls and in person meetings, and assist with planning and preparation as needed\n",
       " \n",
       " \n",
       " \n",
       " \n",
       " ,\n",
       " requirements of the position. Having a conviction history will not automatically disqualify an applicant from being considered for employment.\n",
       " Work will be primarily performed at Lawrence Berkeley National Lab, 1 Cyclotron Road, Berkeley, CA.\n",
       " ,\n",
       " requirement. What and how you can contribute is what's most important to us which is why our consideration is not limited by the level of education you have.\n",
       " You have experience with big data technologies such as Spark or AWS; are able to write efficient SQL; and are proficient in one or more of the following programming languages: R, Python, Java, or Scala. Variety of technical challenge is one of the best things about working at The Trade Desk as a data scientist though which is why we do not expect you to know every technology we use when you start. What we care about is that you can learn quickly and solve complex problems using the best tools for the job.\n",
       " \n",
       " ,\n",
       " requirements and deliver insightful analysis and/or models; ability to synthesize, simplify and explain complex problems to different types of audiences, including executives\n",
       " What Give You An Edge:\n",
       " 7+ years relevant industry experience\n",
       " Experience building data warehousing and ETL pipelines\n",
       " Experience with Unix/Linux environment, Git.\n",
       " Experience in developing data apps with Python/Java, high charts, etc.\n",
       " Excellent communication skills, with the ability to synthesize, simplify and explain complex problems to different types of audiences, including executives\n",
       " Experience working with B2B data science domain: product analytics, CRM, sales effectiveness, propensity score,, segmentation, web analytics, attribution, funnel optimization, etc.\n",
       " #LI-MT1\n",
       " ,\n",
       " Requirements:\n",
       " 2+ years of practical machine learning experience or applicable academic/lab work\n",
       " Experience in building and optimizing supervised and unsupervised machine learning models including deep learning and various other modern data science techniques\n",
       " A fundamental understanding of mathematical and machine learning concepts such as calculus, back propagation, ReLU, Bayes’ theorem, Random Forests, time series analysis, etc.\n",
       " Experience with applied statistics concepts\n",
       " Experience developing software collaboratively in Python using version control\n",
       " Ability to perform data extraction, transformation, loading from multiple sources and sinks\n",
       " Ability to produce data visualizations using tools such as matplotlib\n",
       " Self-motivated, life-long learner\n",
       " Strong communication skills, including to non-technical audiences\n",
       " Bachelor's in mathematics, statistics, computer science, physics or a similar field, depending on position level (master's preferred)\n",
       " The Company:\n",
       " Our passion for improving quality of life through geography is at the heart of everything we do. Esri’s geographic information system (GIS) technology inspires and enables governments, universities, and businesses worldwide to save money, lives, and our environment through a deeper understanding of the changing world around them.\n",
       " ,\n",
       " requirements\n",
       " Drive partnerships for access to the most advanced technologies\n",
       " Build scalable tools for modeling and performance evaluation\n",
       " Architect ML solutions to best suit Waymo’s unique requirements\n",
       " ,\n",
       " requirements.\n",
       " Supervises staff of data analytics experts ensuring adequate mentoring, staff development and training. Performs the administrative and human resource management functions relative to the staff supervised. Provides advice and counsel to workers related to work and administrative matters.\n",
       " ,\n",
       " need to have a strong sense of self-confidence, as well as excellent oral, written, and presentation communication skills. He/she will be someone that describes himself/herself, and that is described by others, as data driven, culturally sensitive, thoughtful, methodical, empowering, and approachable, along with being results driven and forward leaning into new opportunities. He/she will be known for leading others by example, whether direct reports or indirect reports, to meet challenging goals and objectives, and to treating others, both inside and outside of the organization, with respect. While Freedom Financial Network has experienced tremendous growth over the past several years, individuals across the organization have a tremendous amount of contact, at times on a daily basis, with multiple members of the senior most leadership team. Therefore, finalist candidates for this role will need to be very comfortable being a hands-on “player-coach” in his/her role. Success in role will require an ability to embrace toggling on a daily basis between high level, strategic discussions, and “in the weeds” tactical/execution orientated discussions.\n",
       " ,\n",
       " requirements, and whitepapers to help internal teams understand what we are doing in this space\n",
       " Define, track, and analyze key product usage, adoption, and performance metrics to provide strategic recommendations\n",
       " Recommend and develop third-party data and software relationships to support market and product needs and work with contracts and legal team to establish agreements\n",
       " Support trade shows such as the Esri Partner Conference, Esri Developer Summit, and the Esri User Conference\n",
       " Requirements\n",
       " 3+ years working as a product manager, technical consultant, product owner, or similar capacity\n",
       " Experience with data science, business intelligence, analytics, or data-driven workflows\n",
       " Demonstrated experience creating and delivering compelling presentations to technical and non-technical audiences at varying levels of responsibility\n",
       " Excellent interpersonal, writing, and leadership skills\n",
       " Self-motivated, creative, and team-oriented\n",
       " Ability and willingness to travel up to 15%\n",
       " Bachelor’s or advanced degree in a relevant field, depending on position level\n",
       " Recommended Qualifications\n",
       " Experience with GIS\n",
       " Familiarity with the Pragmatic Marketing Framework\n",
       " About Esri\n",
       " Our passion for improving quality of life through geography is at the heart of everything we do. Esri’s geographic information system (GIS) technology inspires and enables governments, universities, and businesses worldwide to save money, lives, and our environment through a deeper understanding of the changing world around them.\n",
       " ,\n",
       " Requirements:\n",
       " M.S. or PhD in Computer Science or Machine Learning related degree; or equivalent work experience in the field\n",
       " 7+ years experience leading and delivering effective ML solutions for large scale production use cases.\n",
       " ,\n",
       " requirements.\n",
       " � The government may require that you certify your citizenship status.\n",
       " � If you are not a U.S. citizen, the government may require you to pass a security check before you can be approved to work on the project.\n",
       " � Please note that any offer by Intel for this position is conditioned upon meeting and/or passing the U.S. Government's security check requirements should the government impose these requirements.\n",
       " ,\n",
       " ideal candidate is highly collaborative, self-motivated, detail oriented and can easily help others understand complicated data.\n",
       " ,\n",
       " requirements. Evangelize customer requirements with SLSI marketing, planning, and engineering stakeholders. Ensure alignment of data center customer requirements and SLSI product roadmap\n",
       " Strategy - Research current and future data center customer and market segment trends. Develop and implement strategic plans for approaching new business opportunities, building internal consensus and partner relationships\n",
       " ,\n",
       " requirements:\n",
       " Experience in a Deep Learning framework such as Tensorflow or Pytorch\n",
       " Experience in applying Deep Learning on visual and/or geometric data\n",
       " Proficient in Python\n",
       " Here's what we can offer you:\n",
       " ,\n",
       " requirement, and to draw meaningful conclusion from the result.\n",
       " To assist the process owners in optimizing processes by analyzing information to identify areas for improvement, proposing alternative solutions to address the problems, and delivering information to measure the outcome.\n",
       " Automate the reporting function as far as possible to reduce time spent working on repetitive tasks.\n",
       " \n",
       " ,\n",
       " ideal candidate is a team player who is excited to work with people, with a variety of technologies, and enjoys solving many different problems.\n",
       " \n",
       " ,\n",
       " requirements of the San Francisco Fair Chance Ordinance. Applicants in need of special assistance or accommodation during the interview process or in accessing our website may contact us by sending an email to assistance(at)squareup.com. We will treat your request as confidentially as possible. In your email, please include your name and preferred method of contact, and we will respond as soon as possible.\n",
       " ,\n",
       " REQUIREMENTS: U.S. citizenship or permanent resident status required.\n",
       " ,\n",
       " requirements.\n",
       " Able to properly understand the business requirements and develop data models accordingly by taking care of the resources.\n",
       " Should have knowledge and experience in prototyping, designing, and requirement analysis.\n",
       " Should have knowledge and skills for secondary tools such as Microsoft Azure, SQL data warehouse, PolyBase, Visual Studio, etc.\n",
       " Able to integrate Power BI reports into other applications using embedded analytics like Power BI service (SaaS), or by API automation. Also, one must be experienced in developing custom visuals for Power BI.\n",
       " ,\n",
       " requirements into product roadmaps\n",
       " Excellent communication skills and ability to explain complex concepts to a non-technical audience\n",
       " A creative problem solver with passion, energy and enthusiasm to drive meaningful and transformational change\n",
       " ,\n",
       " Requirements:\n",
       " Bachelors of Science in Computer Science, Statistics, Engineering, Physics, or related quantitative field with strong record of academic achievement\n",
       " 3+ years of experience using machine learning and specifically natural language processing to mine unstructured data, extracting information from documents such as electronic filings, contracts, news, patents etc.\n",
       " Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.\n",
       " Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.\n",
       " Professional experience with one or more of Java, Hibernate, Python, Scala, C/C++.\n",
       " Experience with Numerical / Scientific Python (NumPy, SciPy, Pandas)\n",
       " Knowledge of machine learning pipelines using Scala / Spark or Python / scikit-learn\n",
       " Possess intellectual curiosity and a strong passion for investing and financial markets\n",
       "  Bonus points:\n",
       " Masters degree or higher in Computer Science or related quantitative field with specialization in natural language processing and/or machine learning\n",
       " Experience with distributed computing architectures\n",
       " Experience with tools for statistical computing (e.g. R, NumPy, SciPy).\n",
       " Experience with big data technologies like Apache Spark, Hadoop, Cassandra, etc.\n",
       " ,\n",
       " requirements for data and analytic solutions and collaborate with the Marketing team to ensure business requirements align with business needs.\n",
       " Analyze content promotions and surface insights that will help drive viewership and a more loyal customer base.\n",
       " Support day-to-day collaboration with Marketing to communicate insights and recommend data informed strategies.\n",
       " The Essentials\n",
       " BA/BS in statistics, mathematics, economics, industrial engineering or other quantitative discipline.\n",
       " 3+ years of experience building data science models (Regression, Decision Trees, K-Means, etc.).\n",
       " Experience with large data sets and analytical tools.\n",
       " Proficiency in scripting languages (SQL, Python, R, etc.).\n",
       " Knowledge of a dashboarding language (Tableau, looker, etc.) or equivalent report building experience not required but a plus Other desired qualifications: - Strong curiosity, leadership and business acumen.\n",
       " Passionate about using data to drive strategy and product recommendations.\n",
       " Experience in subscription-based businesses or eCommerce preferred.\n",
       " Background with CRM preferred.\n",
       " Strong interpersonal skills with the ability to motivate, collaborate and influence.\n",
       " Ability to deliver on multiple projects and meet tight deadlines.\n",
       " A developed creative taste and strong instinct for stories and experiences that will capture consumers.\n",
       " Actively engage in strategic conversations with social insights and community perspectives.\n",
       " Ability to adapt rapidly in a fast-moving environment with shifting priorities and the ability to react quickly, dynamically, and intelligently.\n",
       " Ability to effectively influence and communicate cross-functionally with all levels; exceptional verbal and written communication skills.\n",
       " Strong presentation skills are a must.\n",
       " The Perks\n",
       " Exclusive WarnerMedia events and advance screenings\n",
       " Paid time off every year to volunteer\n",
       " Access to well-being tools, resources, and freebies\n",
       " Access to in-house learning and development resources\n",
       " Part of the WarnerMedia family of powerhouse brands\n",
       " WarnerMedia is a leading media and entertainment company that creates and distributes premium and popular content from a diverse array of talented storytellers and journalists to global audiences through its consumer brands including: HBO, HBO Now, HBO Max, Warner Bros., TNT, TBS, truTV, CNN, DC Entertainment, New Line, Cartoon Network, Adult Swim, Turner Classic Movies and others.\n",
       " \n",
       " ,\n",
       " ideal candidate will have a blend of science and engineering skills, proven track record of solving critical business problems through data science and strong analytical/quantitative and engineering skills. The candidate will be expected to have strong communication skills and to be capable of cross-group collaborations.\n",
       " Come and help us blow away the boundaries of e-commerce through AI.\n",
       " ,\n",
       " ideal candidate will be responsible for developing overall architecture and high level design. The candidate must have extensive experience with Star Schemas, Dimensional Models, and Datamarts. The individual is expected to build efficient, flexible, extensible, and scalable ETL design and mappings. Excellent written and verbal communication skills are required as the candidate will work very closely with diverse teams.\n",
       " ,\n",
       " ideal candidate comes from a rapid development environment, publishing numerous dashboards, and managing multiple competing priorities and assignments. The candidate is expected to be current on modern BI technologies and have strong project management skills\n",
       " Responsibilities\n",
       " Work effectively with a broad range of users to interpret their needs and document User Stories.\n",
       " Invent creative and innovative ways to answer key questions by leveraging existing data assets or creating new ones.\n",
       " Design and implement proof of concept solutions and create advanced Tableau visualizations using action filters, user filters, advanced navigation techniques and Level-of-Detail (LOD) expressions.\n",
       " Advanced Tableau development including Tableau data model creation, customize dimensions, advanced calculations, and interactive dashboards.\n",
       " Performance tuning of Tableau Server dashboards to minimize the data and rendering refresh cycles and optimize the end user experience\n",
       " Enable and improve Tableau Natural Language Processing to empower users to ask probing and complex data questions.\n",
       " Drives innovation and creative interfaces for a visually appealing and intuitive user interface and experience.\n",
       " Keeps abreast of current trends related to Tableau and other BI technologies\n",
       " Drive effective teamwork, communication, and collaboration to achieve results\n",
       " Develop a strong understanding of the business, strategic direction, organizational structure, and overall organizational goals\n",
       " Promotes a risk-aware culture, ensure efficient and effective risk and compliance management practices by adhering to required standards and processes.\n",
       " ,\n",
       " ideal candidate is college student or recent college graduate just starting their career. This is part time position.\n",
       " ,\n",
       " Requirements:\n",
       " Knowledge of C, C++, and SQL\n",
       " Software development and quality assurance background\n",
       " Experience in writing clear, concise and comprehensive test plans and test cases\n",
       " Hands-on experience with both white box and black box testing\n",
       " Major in Computer Science, Engineering or a related subject\n",
       " ,\n",
       " Requirements\n",
       " Master's degree or above in mathematics, statistics, or computer science\n",
       " 5+ years applied experience in business intelligence, data mining, analytics, or statistical modeling in technology or mobile industries\n",
       " A passion for data analysis and presentation of data insights\n",
       " Ability to communicate effectively with technical developers and non-technical marketing business partners\n",
       " Programming experience (R, Python, Ruby)\n",
       " Experience implementing machine learning algorithms\n",
       " Good working knowledge of MongoDB or similar DB technologies\n",
       " Knowledge of statistical analysis toolsets (SAS, R, MATLAB) and techniques\n",
       " Strong proficiency with one or more statistical visualization or graphing toolkits (MS Excel, a Javascript framework like Highcharts or Tableau)\n",
       " Extra Credit!\n",
       " Enjoy working in small, fast-paced teams where you can take initiative and accountability, and generate results every day\n",
       " Detail-oriented, organized, and focused on delighting customers\n",
       " Understand / willingness to learn mobile app economy dynamics. Own a smartphone, download apps, and actively participate in the new mobile economy\n",
       " Comfortable with basic mobile industry metrics\n",
       " Familiarity with web application development and Git\n",
       " ,\n",
       " requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.\n",
       " ,\n",
       " Requirements):\n",
       " To be considered for this role, the minimum requirements must be evident on your resume.\n",
       " Bachelor’s degree required with a minimum of 7 years of clinical data/analysis experience with programming skills using SAS and/or R or advanced degree with a minimum of 5 years of clinical data/analysis experience with programming skills using SAS and/or R\n",
       "  Note: SAS (including SAS BASE, SAS/STAT, SAS Macro, SAS/SQL and SAS Graph) and R programming skills to create tables, listings, and figures (TLFs)\n",
       " ,\n",
       " Basic Qualifications:\n",
       " Experience\n",
       " Minimum eight (8) years of work experience.\n",
       " Education\n",
       " Bachelor's degree OR four (4) years work experience in a directly related field.High School Diploma or General Education Development (GED) required.\n",
       " License, Certification, Registration\n",
       " N/A.\n",
       " Additional Requirements:\n",
       " Thorough knowledge of policies, practices and systems.Regularly contributes to the development of new concepts, techniques, and standards.Considered functional expert in field within KP.Frequently contributes to the development of new theories and methods.Employs expertise as a generalist or specialist.Must be able to work in a Labor/Management Partnership environment.\n",
       " Preferred Qualifications:\n",
       " Bachelor's degree and seven (7) years of work experience OR a master's degree and five (5) years of work experience preferred.Knowledge of health care industry preferred.Familiarity with Kaiser Permanente health care system preferred.\n",
       " Expert SQL, PowerPoint, and Excel skills\n",
       " Background in leading and delivering deep-dive detailed root-cause analysis and data mining methods (structured and unstructured)\n",
       " Ability to conduct complex business modeling using statistical methods and tools\n",
       " Strong hands-on experience extracting multiple data-sets, writing complex SQL queries, and building data tables\n",
       " Experience conducting exploratory data analysis to generate hypotheses, identify patterns, and insights\n",
       " Excellent time-management skills with ad-hoc request, organizational agility to effectively balance multiple deliverables, cross-functional partners, and priorities under tight timelines\n",
       " Solid relationship builder, communicator, and storyteller\n",
       " ,\n",
       " requirements, and deliver innovative solutions into production that consolidate the AI team as thought leaders in the space.\n",
       " ,\n",
       " requirements, functional design, process design (including scenario design, flow mapping), prototyping, testing, training, defining support procedures.\n",
       " Formulate planning, budgeting, forecasting and reporting strategies.\n",
       " Manage full life cycle implementations.\n",
       " Develop statements of work and/or client proposals.\n",
       " Identify business opportunities to increase usability and profitability of information architecture.\n",
       " Experience with program leadership, governance and change enablement.\n",
       " Develop and manage vendor relationships.\n",
       " Lead workshops for client education.\n",
       " Manage resources and budget on client projects.\n",
       " Assist and drive the team by providing oversight.\n",
       " The team\n",
       " Analytics & Cognitive\n",
       " In this age of disruption, organizations need to navigate the future with confidence, embracing decision making with clear, data-driven choices that deliver enterprise value in a dynamic business environment.\n",
       " ,\n",
       " ideal candidate has significant expertise in the biomedical or clinical domain, and is eager to apply his or her skills to improve patient outcomes.\n",
       " ,\n",
       " Requirements:\n",
       " 3+ years working as a product manager, technical consultant, product owner, or similar capacity\n",
       " Experience with data science, business intelligence, analytics, or data-driven workflows\n",
       " Demonstrated experience creating and delivering compelling presentations to technical and non-technical audiences at varying levels of responsibility\n",
       " Excellent interpersonal, writing, and leadership skills\n",
       " Self-motivated, creative, and team-oriented\n",
       " Ability and willingness to travel up to 15%\n",
       " Bachelor’s or advanced degree in a relevant field, depending on position level\n",
       " The Company:\n",
       " Our passion for improving quality of life through geography is at the heart of everything we do. Esri’s geographic information system (GIS) technology inspires and enables governments, universities, and businesses worldwide to save money, lives, and our environment through a deeper understanding of the changing world around them.\n",
       " ,\n",
       " Requirements\n",
       " Document requirements\n",
       " Curriculum Vitae - Your most recently updated C.V.\n",
       " Cover Letter\n",
       " ,\n",
       " requirements listed below are representative of the knowledge, skill, and/or ability required.\n",
       "  Ability to calculate concentrations and accurately prepare chemical solutions.\n",
       "  Knowledge of safety precautions for handling chemicals and biological materials.\n",
       "  \n",
       " Skill in providing guidance and instruction in laboratory protocols and in the safe use of laboratory equipment.\n",
       "  Knowledge of experimental procedures, protocols, and preparation techniques.\n",
       "  Ability to maintain quality, safety, and/or infection control standards. Ability to set up, calibrate, operate, and maintain standard laboratory and test equipment.\n",
       "  Knowledge of the cleaning specifications of various laboratory and/or medical equipment, fixtures, utensils, and related materials.\n",
       "  Skill in the use of personal computers and related software applications.\n",
       "  Ability to plan, develop, and coordinate multiple projects.\n",
       "  Ability to read and write at a level appropriate to the duties of the position.\n",
       "  Ability to gather data, compile information, and prepare reports.\n",
       "  Strong interpersonal and communication skills and the ability to work effectively with a diverse faculty, staff and student body.\n",
       "  Ability to supervise and train student staff, including organizing, prioritizing, and scheduling work assignments.\n",
       "  Strong organizational skills and detailed oriented.\n",
       "  Ability to create, compose, and edit written materials.\n",
       "  \n",
       " Ability to develop and maintain recordkeeping systems and procedures.\n",
       "  Knowledge of standard budgeting and expenditure control procedures and documentation.\n",
       "  Ability to interpret, adapt, and apply guidelines and procedures.\n",
       "  Ability to make administrative/procedural decisions and judgments.\n",
       "  \n",
       " Ability to investigate and analyze information and to draw conclusions.\n",
       " Education and/or Experience\n",
       " Bachelor’s degree from four-year college or university; or one to two years’ related experience and/or training with experience in Chemistry, Biology, and Physics laboratories; or equivalent combination of education and experience. Must have a minimum of twenty (20) semester hours of college level physical and/or life science units including five (5) units of related laboratory classes.\n",
       " Open Date 02/21/2020\n",
       " ,\n",
       " Requirements\n",
       " Master's degree or above in mathematics, statistics, or computer science\n",
       " 2+ years applied experience in business intelligence, data mining, analytics, or statistical modeling in technology or mobile industries\n",
       " A passion for data analysis and presentation of data insights\n",
       " Ability to communicate effectively with technical developers and non-technical marketing business partners\n",
       " Programming experience (R, Python, Ruby)\n",
       " Experience implementing machine learning algorithms\n",
       " Good working knowledge of MongoDB or similar DB technologies\n",
       " Knowledge of statistical analysis toolsets (SAS, R, MATLAB) and techniques\n",
       " Strong proficiency with one or more statistical visualization or graphing toolkits (MS Excel, a Javascript framework like Highcharts or Tableau)\n",
       " Extra Credit!\n",
       " Enjoy working in small, fast-paced teams where you can take initiative and accountability, and generate results every day\n",
       " Detail-oriented, organized, and focused on delighting customers\n",
       " Understand / willingness to learn mobile app economy dynamics. Own a smartphone, download apps, and actively participate in the new mobile economy\n",
       " Comfortable with basic mobile industry metrics\n",
       " Familiarity with web application development and Git\n",
       " ,\n",
       " ideal candidate will have previous experience leading a team of data scientists delivering analytics for large-scale machine learning products and a passion for building agile, high-performing teams.\n",
       " Responsibilities:\n",
       " Build and lead a team of data scientists and analysts in a fast-moving and quickly growing organization\n",
       " Collaborate with key partners including Engineering, Product, Business, ML Evaluation and other data teams\n",
       " Employ advanced statistical modeling to analyze large data sets, derive insights and create visualizations and dashboards to guide key business and product decisions\n",
       " Analyze petabyte-scale data and identify patterns to inform and guide focus areas for evaluation and triage teams\n",
       " Work closely with engineering teams to ensure that data pipelines are scalable, repeatable, and secure\n",
       " Enables big data and batch/real-time analytical solutions that leverage state-of-the-art data and ML technologies\n",
       " Collect, connect, parse, manage, analyze and visualize large, diverse sets of data using multiple platforms\n",
       " ,\n",
       " ideal candidate has experience creating a working machine learning-powered project from the ground up, contributes innovative ideas and ingenious implementations to the team, and is capable of planning out scalable, maintainable data pipelines.\n",
       " Responsibilities\n",
       " Everything involved in analyzing a production data set, including:\n",
       " Writing code to transform massive raw data output into a structured, usable form\n",
       " Leveraging more traditional machine learning techniques to uncover hidden relationships in our data sets\n",
       " Conducting statistical analysis of results to prove / disprove hypotheses, and\n",
       " Write up reports that our other team members can use to deliver in a product\n",
       " Interface closely with the Product, Business Development, and Sales teams to answer questions about our data sets that our customers and partners are seeking solutions for\n",
       " Requirements\n",
       " You have an undergraduate or graduate degree in computer science or similar technical field, with significant coursework in mathematics or statistics\n",
       " You have 1-2 years of industry data science experience\n",
       " You have successfully worked with complex data sets and are familiar with Hadoop / Spark\n",
       " You know the ins and outs of Python, especially as it applies to the above data processing frameworks\n",
       " You are capable of quickly coding and prototyping data pipelines involving any combination of Python, Node, bash, and linux command-line tools, especially when applied to large data sets consisting of millions of files\n",
       " You have a working knowledge of the following technologies, or are not afraid of picking them up on the fly: C++, Scala / Spark, R, Matlab, SQL, Cassandra, Docker\n",
       " You are comfortable with running and interpreting common statistical tests, and also with common data science techniques including dimensionality reduction and supervised and unsupervised learning\n",
       " You have great communication skills and ability to work with others\n",
       " You are a strong team player, with a do-whatever-it-takes attitude\n",
       " What We Offer You\n",
       " ,\n",
       " need to have?\n",
       " Demonstrates a working knowledge of industry metadata submission\n",
       " STRONG SDTM experience required\n",
       " This position can be located anywhere in the US-Must be able to work Pacific Time hours.\n",
       " Must have a Four Year Degree.\n",
       " Seven plus years of programming experience.\n",
       " Experience with Oncology studies\n",
       " ,\n",
       " Requirements:\n",
       " Education and Experience\n",
       " ,\n",
       " ideal candidate will have a strong background in computational biology/bioinformatics with both scripting and data manipulation/visualization skills.\n",
       " ,\n",
       " Requirements\n",
       " Bachelor or advanced degree in data science, statistics, biological sciences, computer science or other equivalent quantitative discipline and experience. At least 6 years of programming experience and 1-2 years developing quantitative analyst team(s). Knowledge and experience with international clinical research and drug development preferred.\n",
       " ,\n",
       " requirements and are considered a plus factor in identifying top candidates. Experience listed below would be obtained through a combination of your school work/classes/research and/or relevant previous job and/or internship experiences.\n",
       " Qualifications:\n",
       " Must have a Bachelor's or Master's Degree in Computer Science or Computer Engineering.\n",
       " 1+ years of experience with:\n",
       " C++\n",
       " Developing applications with at least one modern graphics API such as DirectX, Metal, OpenCL, CUDA, Vulkan or experience in machine learning algorithm development.\n",
       " Windows* and/or Linux operating systems.\n",
       " Preferred Qualifications:\n",
       " Experience in GPGPU programming.\n",
       " Experience developing graphics device drivers and hardware/software interaction.\n",
       " Experience in compilers and/or performance analysis and optimization techniques is an added advantage\n",
       " Inside this Business Group\n",
       " ,\n",
       " requirements of the job include:\n",
       " Strong leadership, communication, and collaboration skills with an ability to summarize results from analysis to a diverse set of audiences with varying background and technical skills\n",
       " Experience with computer vision, image analysis, and machine learning to extract meaningful feature data from captured microscope images (e.g., feature extraction, object detection, segmentation, regression, survival analysis)\n",
       " Advanced degree, PhD preferred, in Engineering, Science, Mathematics, or related\n",
       " 7+ years and expert knowledge of statistical programming languages such as R, Python, SAS, and SQL\n",
       " 7+ years and expert knowledge of probability, statistics and machine learning theory including experience in: Clustering, Decision Trees, Logistic Regression, Dimensionality Reduction, Random Forests, and Neural Networks for prediction and recommendations\n",
       " Must have delivered data science components as part of an academic, industrial, or commercial solution\n",
       " 5-7+ years’ experience in at least one of the following specific areas of machine learning:\n",
       " Building image/video analysis models using Deep Learning techniques such as CNN and RNN, computer vision frameworks such as OpenCV and/or similar toolkits\n",
       " Practical hands-on experience with deep learning and machine learning: architecture design, parameter tuning, model evaluation, leveraging tools such as TensorFlow or similarIt would be a plus if you also possess previous experience in:\n",
       " Experience in an Agile development environment\n",
       " Medical device product development under FDA and global regulations\n",
       " Executing data science in the fields of life sciences, in vitro diagnostics, and biostatistics\n",
       " Expert knowledge of data visualization, using tools such as Tableau or PowerBI\n",
       " ,\n",
       " ideal candidate has a broad and deep background in machine learning, is passionate about science, is highly driven to learn and deploy new technologies, thrives in a fast-paced environment that requires the development of solutions to ambiguous and challenging problems, and enjoys collaborating with both technical and nontechnical peers.\n",
       " ,\n",
       " Ideal candidates will have...\n",
       " Have one or more years of industry experience, delivering quality software that matters to people that care\n",
       " Excellent coding skills in an object-oriented language (Go, Python, Rust, Java, C++, Ruby, etc...)\n",
       " Experience working with high volumes of data, ideally with machine learning playing a critical role\n",
       " Strong foundational knowledge of mathematics, bonus if related to machine learning or signals processing\n",
       " A breadth of technical skills and know how to use the right tool for the job\n",
       " High motivation and ability to learn new technologies and domains\n",
       " A positive can-do attitude and bring a passion for excellence to the workplace\n",
       " Excellent collaboration and communication skills\n",
       " Professional experience with AWS, Kubernetes a bonus\n",
       " Knowledge of cybersecurity, signals processing, or experience working with time-series data a bonus\n",
       " ,\n",
       " requirements to Data Engineering and build data sets for exploration to enable deep data exploration to uncover \"Why?\" and \"What?\"\n",
       " Leverage Python and other tools to run complex data analysis, statistical stat sig for A/B tests, regression models etc.\n",
       " Build automated data extracts for Tableau automation that supports dashboards and self-service\n",
       " Translate the results of an analysis into easily understood insights and recommendations to share with the business teams and executives\n",
       " QUALIFICATIONS:\n",
       " ,\n",
       " Requirements:\n",
       " 4+ years of object-oriented software development experience, 2+ with C#/C++, more experience welcome\n",
       " Experience using machine learning algorithms including e.g. CNNs and Gaussian processes\n",
       " Math skills including geometry, vector operations, linear algebra, nonlinear optimization, statistics, and probability; undergraduate level physics\n",
       " Experience with optics and image processing\n",
       " Proven ability to conceive, implement, and debug novel algorithms and systems\n",
       " Experience with multithreading, asynchronous operations, events, TPL (C# Tasks)\n",
       " Write testable/mockable code and run functional and unit tests\n",
       " Experience with Git\n",
       " Desirable Experiences:\n",
       " Performance optimization including native algorithm implementation (C++) and GPU programming\n",
       " Knowledge of solar thermal technologies\n",
       " Experience with PostgreSQL databases, database normalization, and Entity Framework\n",
       " Bachelor’s degree in a field of science, engineering, or mathematics\n",
       " Willingness to occasionally travel to projects around the world\n",
       " ,\n",
       " requirements and size delivery efforts.\n",
       " Consistently execute against a product roadmap to deliver multiple features\n",
       " Embrace test-driven development with complete code coverage and continuous integration\n",
       " Work closely with the test team manager to ensure a solid overall test strategy is in place for the solution\n",
       " Proactively encourage team members to increase the breadth and depth of their leadership, technical and soft skills.\n",
       " Collaborate with Senior Management and major stakeholders to establish and communicate a technical vision for the solution\n",
       " Work directly with our team comprised of the brightest minds in technology, research and life sciences\n",
       " Your Competencies:\n",
       " Proven leadership in driving and growing several agile software development teams\n",
       " Experience of operating in (or ideally adopting) a Devops environment & culture\n",
       " Proven experience at Director level engineering positions that includes managing managers\n",
       " Proven leadership scaling application development teams that are self-organizing, loosely coupled, yet highly aligned.\n",
       " Ability to translate business challenges into data pipelines & model framework, owning and driving successful projects\n",
       " Proven technical leadership regarding feature design, enhancement and implementation of complex commercial software solutions\n",
       " Full-Stack software development experience architecting and building robust distributed systems that scale well\n",
       " Strong technical expertise in .NET, front-end UI (React) and RESTful API development.\n",
       " Strong verbal and written communication; collaborative focus\n",
       " Experience in statistical tools and programming languages that allow you to understand complex clinical data (R, Python, SQL)\n",
       " Your Education & Experience:\n",
       " Bachelor’s of Science or Master’s degree in relevant field. Ph.D. a plus\n",
       " Proven track record at Director level engineering positions, preferably in a healthcare related company\n",
       " Experience leading & working with remote engineering teams and 3rd party vendors\n",
       " Experience with cloud technologies, such as AWS is desired\n",
       " Experience with the Google apps suite, GitHub, Git, MySQL are desired\n",
       " Medidata Solutions, Inc. is an Equal Opportunity Employer. Medidata Solutions provides equal employment opportunities to all employees and applicants for employment without regard to race, color, religion, gender, sexual orientation, gender identity, national origin, age, disability status, protected veteran status, or any other characteristic protected by the law. Medidata Solutions complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities.\n",
       " ,\n",
       " Requirements: Applicants with Ph.D. in a basic science or MD/ DO with research experience. Incumbent is expected to make scientific and scholarly contributions to the research enterprise, search for pertinent scientific literature as needed, and work with the CAIDM research groups in applying for intramural and extramural funding. Incumbent will be involved in collecting, preparing/curating research data; image preprocessing; machine learning algorithm implementation including design of custom neural network architectures; algorithm validation. Mastery of the English language is required. Excellent communication skills, both oral and written, are essential. Experience with medical research is a plus.\n",
       " Application procedure: To apply, please log onto UC Irvine’s recruitment site located at: https://recruit.ap.uci.edu/JPF05920\n",
       " Applicants must complete an online application profile and upload the following application materials electronically to be considered for the position:\n",
       " Document Requirements\n",
       " Curriculum Vitae – Your most recently updated CVResearch StatementStatement of Contributions to Diversity- Statement addressing how previous and/or past contributions to diversity, equity and inclusion will advance UCI’s Commitment to Inclusive Excellence\n",
       " Reference Requirements • Names and contact information for 3 references\n",
       " The University of California, Irvine is an Equal Opportunity/Affirmative Action Employer advancing inclusive excellence. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, age, protected veteran status, or other protected categories covered by the UC nondiscrimination policy.\n",
       " For further information pertaining to this recruitment please contact:\n",
       " Daniel S. Chow, MD\n",
       " Assistant Professor-in-Residence, Department of Radiological Sciences\n",
       " Co-Director, Center for Artificial Intelligence in Diagnostic Medicine (CAIDM)\n",
       " University of California, Irvine|\n",
       " email: chowd3@hs.uci.edu\n",
       " ,\n",
       " Requirement: None\n",
       " Access: None\n",
       " Polygraph: None\n",
       " Relocation Available: Yes\n",
       " Employment Type: Regular\n",
       " Work Schedule: Full Time\n",
       " ,\n",
       " ideal candidate must be an energetic, self-motivated individual with an orientation to explore and analyze data and seek to improve outputs to support customer success goals and objectives.\n",
       " ,\n",
       " requirements of the Los Angeles Fair Chance Initiative for Hiring.\n",
       " \n",
       " ,\n",
       " ideal candidate will possess both a partner background that enables them to drive successful partnerships, engage at the CXO level, as well as a sales background that enables them to easily interact with enterprise customers and AWS sales/field reps. She/he should also have a demonstrated ability to think strategically about business, product, and technical challenges, with the ability to build and convey compelling value propositions. The position also requires a strong technical acumen, along with working knowledge of the machine learning technology and consulting services landscape.\n",
       " ,\n",
       " requirements.\n",
       " Build data tools for analytics that go beyond current approaches to deliver insights to high-priority scientific problems.\n",
       " Identify, design, and implement process improvements: automating manual processes, optimizing data delivery, re-design infrastructure.\n",
       " Advocate transparency & action through data storytelling! Establish and execute strategies to increase usage and adoption of Data Science from project conceptualization to completion.\n",
       " ,\n",
       " requirements for modeling projects.\n",
       " ,\n",
       " requirements.\n",
       " As part of our team, you’ll enjoy:\n",
       " The hustle of a startup with the impact of a global businessTremendous opportunity to seek some of the industry’s most exciting problems Working with an outstanding team of creative, fun and highly motivated peopleComprehensive health coverage, competitive salary, and 401(k) matchDaily catered lunches, an endless supply of refreshments, basketball court, fitness classes, and social eventsA modern, uplifting work environment in an ideal location\n",
       " ,\n",
       " requirements\n",
       " Design & develop system software for our customers\n",
       " Explore new areas or program in new languages to deliver a complete product\n",
       " Support on-site meetings and deliveries to customers\n",
       " Analyze, troubleshoot, and optimize deployed web app/database systems\n",
       " ,\n",
       " qualification, bringing established sales methods to the sales process\n",
       " Develop organized and differentiated go to market activities\n",
       " Develop overview materials to support initial meetings/conversations\n",
       " Lead preparations for formal sales meetings and orals for qualified opportunities\n",
       " Provide support to core accounts without CREs as needed for critical opportunities\n",
       " Identify opportunities (sole source/up for bid) and bring it to the business (functional) partners, evaluate opportunity alignment with client strategy\n",
       " Identify and align appropriate firm resources to pursue, win, and manage opportunities\n",
       " Lead pursuit process, RFP responses, etc.\n",
       " Contribute to pursuit processes by leveraging relationships for insights and influence, including determining “win” themes, aligning messaging with client needs, supporting proposal/orals materials preparation, and participating in the orals session as appropriate\n",
       " Support pre-sales efforts leveraging depth of product knowledge / product demonstrations tailored to client environment\n",
       " Industry Expansion and Relationship Building\n",
       " Collaborate Alliance, Marketing and practice leads on messaging, events and eminence - both internal and external\n",
       " Identify ways the practice can expand/enhance visibility at key events and in the market\n",
       " Participate in key industry events to build relationships and develop business opportunities\n",
       " Identify key relationships across the industry which would benefit the AI I&E practice and develop plans to cultivate those relationships\n",
       " Utilize Deloitte eminence - including thoughtware, events, trainings, conferences, and memberships – to build and enhance relationships\n",
       " Utilize available offerings to develop and participate in activities and events focused on shared values and mission, e.g., Deloitte Greenhouse events, Client Experience labs etc.\n",
       " Market offering Support\n",
       " Support AI Managed Services market offering leadership in developing account and practice plans during the annual planning process\n",
       " Participate in market offering leadership calls and in person meetings, and assist with planning and preparation as needed\n",
       " \n",
       " \n",
       " \n",
       " \n",
       " ,\n",
       " requirements for data sciences research from LLNL programs and external government sponsors.Carry out development of data analysis algorithms to address program and sponsor data sciences requirements.Engage other developers frequently to share relevant knowledge, opinions, and recommendations, working to fulfill deliverables as a team.\n",
       " Contribute to technical solutions, participate as a member of a multidisciplinary team to analyze sponsor requirements and designs, and implement software and perform analyses to address these requirements.\n",
       " Develop and integrate components-such as web-based user interfaces, access control mechanisms, and commercial indexing products-for creating an operational information and knowledge discovery system.\n",
       " Perform other duties as assigned.\n",
       " Qualifications\n",
       " Bachelor’s degree in computer science, computer engineering, or related field, or the equivalent combination of education and related experience.Fundamental knowledge of one or more of the following: high performance computing, scientific data analysis, statistical analysis, knowledge discovery, computer security, systems programming, large-scale data management, and big data technologies.\n",
       " Skilled in all aspects of the software project life cycle: feasibility, requirements, design, implementation, integration, test and deployment.\n",
       " Fundamental experience developing software with C++, C, Java, Python, R, or Matlab, software applications in Linux, UNIX, Windows environments, data analysis algorithms, data management approaches, relational databases, or machine learning algorithms.\n",
       " Ability to effectively handle concurrent technical tasks with conflicting priorities, to approach difficult problems with enthusiasm and creativity and to change focus when necessary, and to work independently and implement research concepts in a multi-disciplinary team environment, where commitments and deadlines are important to project success.\n",
       " Sufficient interpersonal skills necessary to interact with all levels of personnel.\n",
       " Sufficient verbal and written communication skills necessary to effectively collaborate in a team environment and present and explain technical information.\n",
       " Pre-Employment Drug Test: External applicant(s) selected for this position will be required to pass a post-offer, pre-employment drug test. This includes testing for use of marijuana as Federal Law applies to us as a Federal Contractor.\n",
       " Security Clearance: This position requires a Department of Energy (DOE) Q-level clearance.\n",
       " If you are selected, we will initiate a Federal background investigation to determine if you meet eligibility requirements for access to classified information or matter. In addition, all L or Q cleared employees are subject to random drug testing. Q-level clearance requires U.S. citizenship. If you hold multiple citizenships (U.S. and another country), you may be required to renounce your non-U.S. citizenship before a DOE L or Q clearance will be processed/granted.\n",
       " Note: This listing has multiple openings; these are Career Indefinite positions. Lab employees and external candidates may be considered for these positions.\n",
       " About Us\n",
       " Lawrence Livermore National Laboratory (LLNL), located in the San Francisco Bay Area (East Bay), is a premier applied science laboratory that is part of the National Nuclear Security Administration (NNSA) within the Department of Energy (DOE). LLNL's mission is strengthening national security by developing and applying cutting-edge science, technology, and engineering that respond with vision, quality, integrity, and technical excellence to scientific issues of national importance. The Laboratory has a current annual budget of about $2.3 billion, employing approximately 6,900 employees.\n",
       " ,\n",
       " Requirement: 0-10%\n",
       " \n",
       " ,\n",
       " requirements, and communication to internal partners and senior management to achieve lofty goals\n",
       " The insight to take ambiguous problems and solve them in a structured, hypothesis-driven, data-supported way\n",
       " The determination to initiate and complete projects to completion in a scrappy environment\n",
       " Why You'll Love Working at DoorDash\n",
       " We are leaders - Leadership is not limited to our management team. It's something everyone at DoorDash embraces and embodies.\n",
       " We are doers - We believe the only way to predict the future is to build it. Creating solutions that will lead our company and our industry is what we do - on every project, every day.\n",
       " We are learners - We're not afraid to dig in and uncover the truth, even if it's scary or inconvenient. Everyone here is continually learning on the job, no matter if we've been in a role for one year or one minute.\n",
       " We are customer-obsessed - Our mission is to grow and empower local economies. We are committed to our customers, merchants, and dashers and believe in connecting people with possibility.\n",
       " We are all DoorDash - The magic of DoorDash is our people, together making our inspiring goals attainable and driving us to greater heights.\n",
       " We offer great compensation packages and comprehensive health benefits.\n",
       " About DoorDash\n",
       " ,\n",
       " Requirements:\n",
       " Bachelor’s degree or foreign equivalent in Computer Engineering or Computer Science Good understanding of: databases real-time data pipes batch processing Experience with/Knowledge of the following technologies: Distributed SW Architecture for SaaS solutions Database technologies (e.g. ElasticSearch,Titandb, Cassandra, influxdb) Hands-on coding using Python/Golang/ Java Open Source Technologies (e.g. Kafka, Flink/Spark) Data mining and statistical analysis\n",
       " Experience developing software for product and services that have been shipped Familiar with statistics, data science, machine learning\n",
       " Desirable: Development experience on web scale distributed systems on AWS/GCP Experience/Knowledge of Tensorflow/Keras based data modeling Development experience/Knowledge on Kubernetes/Kubeflow Experience in NLP related work Why Cisco\n",
       " At Cisco, each person brings their unrival talents to work as a team and make a difference.\n",
       " Yes, our technology changes the way the world works, lives, plays and learns, but our edge comes from our people. We connect everything – people, process, data and things – and we use those connections to change our world for the better. We innovate everywhere - From launching a new era of networking that adapts, learns and protects, to building Cisco Services that accelerate businesses and business results. Our technology powers entertainment, retail, healthcare, education and more – from Smart-Cities to your everyday devices. We benefit everyone - We do all of this while striving for a culture that empowers every person to be the difference, at work and in our communities.\n",
       " Colorful hair? Don’t care. Tattoos? Show off your ink. Like polka dots? That’s cool. Pop culture geek? Many of us are. Be you, with us! #WeAreCisco\n",
       " We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\n",
       " ,\n",
       " Basic Qualifications:\n",
       " Experience\n",
       " Three (3) years of programming in SAS, SQL, VBA, net, or equivalent statistical analytical programming language.Minimum two (2) or more years of related analytical consulting experience.\n",
       " Education\n",
       " Bachelor's degree in economics, finance, health care administration, public health administration, statistics, mathematics, operations\n",
       " research, or related field required OR four (4) years of experience in a directly related field.\n",
       " High School Diploma or General Education Development (GED) required.\n",
       " Licenses, Certifications, Registrations\n",
       " N/A.\n",
       " ,\n",
       " requirements to support experiments, and communication of results and recommendations\n",
       " Unify platform, tooling and data access for experimentation to dive ease of use\n",
       " Develop a mid-term roadmap that aligns with product roadmap and objectives\n",
       " Automate pipelines & dashboard for experimentation\n",
       " Develop self-serve tools for easy experimentation configuration and analysis\n",
       " Evangelize and educate others on experimentation best practices through periodic readouts and brown bag sessions\n",
       " Consolidation of critical documentation\n",
       " ,\n",
       " Requirements\n",
       " What we’re looking for:\n",
       " ,\n",
       " ideal candidate will have industry experience in developing detection systems and/or designing anti-abuse measures and algorithms. You’ll apply quantitative analysis, modeling and data mining to improve our pinners’ and partners’ experience.\n",
       " ,\n",
       " requirements to AWS customers.\n",
       " ,\n",
       " requirements gathering and data validations to improve data platforms\n",
       " Efficiently manage his/her own project queue and develop streamlined workflows\n",
       " ,\n",
       " requirements.\n",
       " Manages and coaches ORS Research Support Services Team - data analytical staff to accomplish project objectives and develop staff capabilities.\n",
       " Establishes and maintains effective working relationships with both internal and external stakeholders. Engages and sustains support among project participants, faculty and students. Represents the ORS Research Support Services Team data analyses to external partners and clients in communications related to projects.\n",
       " Advises the Research Manager on technical staff hiring decisions. Responsible for data project related training, supervision, coaching and evaluation of utility data care analyses healthcare data analysts.\n",
       " Applies analytic knowledge, skills and experience to perform project-related work, complete specific project tasks, and create project deliverables.\n",
       " ,\n",
       " Requirements:\n",
       " Strong working knowledge of SQL, Teradata preferredExtremely proficient with Tableau and other Data Visualization toolsStrong working knowledge of process automation using a scripting language (R / Python)\n",
       " •Solid understanding of fundamental statistical concepts and measurement methodologies•Web Analytics (Adobe preferred)\n",
       " ,\n",
       " ideal candidate is a highly quantitative, out of the box thinker who loves working with and analyzing data.\n",
       " ,\n",
       " ideal candidate will be instrumental in architecting commercial data strategy, data standards, stewardship and governance. He/she will deploy both strategy and operational considerations in scouting new sources of data, data generation, reporting, and annual data planning to advance actionable insights in support of our mission.\n",
       " Key Responsibilities\n",
       " o Establish Data Strategy and Implement Operating Model :\n",
       " Outline key design principles for data governance, including philosophy around data stewardship, aligned with the commercial and corporate strategy.\n",
       " Define operating model and change management considerations for data governance across commercial.\n",
       " Democratize data access across commercial by fostering a mindset of data stewardship over data ownership, and effectively ingesting external data. Select and implement the best tools for data democratization.\n",
       " Represent commercial interests in the internal Gilead cross functional data governance council.\n",
       " Conduct high level mapping of available data sources, including data flow and pipeline requirements. Develop an understanding of architecture needs.\n",
       " o Partner with the Business to Drive Commercial Value :\n",
       " Anticipate data needs across commercial and develop and annual planning data process. Collaborate with other functional leads to develop and implement a harmonized data acquisition process, data on-boarding, and utilization considerations.\n",
       " In collaboration with Marketing Sciences and the brand teams, determine and execute the most impactful use cases to illuminate new data acquisitions or new uses of existing data sources and analyses. Evaluate the use of Big Data and Artificial Intelligence to drive commercial value.\n",
       " Collaborate with Marketing Sciences as the data partner to deliver actional insights to the business.\n",
       " Continuously gather data insights to build business efficiencies and address gaps in capabilities.\n",
       " o Ensure Data Quality, Privacy and Protection :\n",
       " Harmonize key policies (e.g. Data Quality, Data Definition, Data Creation policies) and processes necessary to carry out those policies, in collaboration with cross functional data governance council.\n",
       " Partner with legal and compliance to account for and uphold diverse privacy and compliance requirements across geographies. Ensure appropriate protections for data integrity, privacy, and regulatory compliance, including assurances for analysis validity.\n",
       " o Leadership :\n",
       " Impeccable credibility as a thought leader and partner to the brand teams, country teams and other cross-functional partners.\n",
       " Empower internal and external data scientists and marketing sciences colleagues to leverage data available by providing resources, tools, and trainings.\n",
       " Negotiate “One Gilead” data contracts with third party providers.\n",
       " Qualifications:\n",
       " Bachelor's degree with 16+ years’ experience with extensive knowledge of technology led business strategy transformation; or 14+ years with MBA/MS with extensive knowledge of technology led business strategy transformation.\n",
       " Proven leadership in the pharmaceutical and or/health tech industry. Knowledge of analytics approaches in biopharma including descriptive and predictive analytics as well as primary research approaches in competitive intelligence, quantitative and qualitative market research.\n",
       " Understanding of emerging capabilities in natural language processing, unstructured data, etc. and potential application in pharma/health care.\n",
       " Ability to translate complex data insights into actionable business recommendations\n",
       " Recruited, developed, mentored and motivated executives as well as built teams of Data Analysts, Data Scientists and Data Designers that deliver results and achieve objectives to support business needs\n",
       " Excellent influencing and networking skills paired with stakeholder management experience in a multi-layered global environment\n",
       " Experience in Agile methodology and execution and design thinking\n",
       " Availability to travel internationally as required\n",
       " Competencies:\n",
       " Results orientation . The ideal candidate will thrive in a fast-paced, high-growth environment. He/She will have a strong drive to meet and exceed goals, even under adverse circumstances, and is willing to take ownership of problems and make decisions in order to move forward. The candidate will be adept at clearly defining objectives and priorities and establishing appropriate milestones through a strong understanding of the market and innovative approaches. He/She will assign accountability and incorporate disciplined processes to ensure success and nimbly handle ‘derailments’ with contingency plans and coordination.\n",
       " Team leadership. The successful candidate will have demonstrated the ability to build, develop, and motivate a team as evidenced by effective hiring, coaching, and mentoring of direct reports. Additionally, this individual will have a track record of successfully leveraging diversity of thought to achieve the highest level of results. The ideal candidate will develop an inclusive culture comfortable with challenging current market paradigms to achieve and exceed goals. He/She will also have constructed an appropriate succession plan and process.\n",
       " Strategic Orientation . The successful candidate will be able to articulate evolving priorities for the business, identify market opportunities and adapt short-term plans. This includes the ability to strategically assess customer needs and build/execute specific, segmented strategies to win business across a diverse set of customers. The successful candidate will have passion for, and success in, developing commercial strategies that have measurable business impact.\n",
       " Collaboration and Influence. The qualified candidate must be able to influence without ownership, which they will do by demonstrating competence and confidence, being personally accessible and likable, being a good listener, use fact-based persuasion, passion, and persistence as appropriate to the audience and issue at stake. Gaining the support and involvement of key internal constituencies will be critical to success, as will influencing those important constituencies external to the company. The successful candidate must therefore have excellent skills at influencing outcomes, and shaping and catalyzing dialogue across and outside the organization. Credibility and integrity are critical attributes to effectively command the respect and trust of key individuals.\n",
       " We’re an equal opportunity employer. Apply online today through the Workday “Career” worklet.\n",
       " ,\n",
       " requirements. The deliverables include SDTM and ADaM datasets, define.xml, tables, listings and figures.\n",
       " Perform conformance checking of SDTM and ADaM datasets using Pinnacle 21; recommend/implement solutions to identified issues; ensure datasets are in compliance with submission standards\n",
       " Review and validate deliverables produced by CROs, provide solutions to issues raised by CROs\n",
       " Create/review analysis file specification for ISS and ISE; program and validate ISS and ISE.\n",
       " Having advanced level of programming expertise, create and validate SAS macros and utilities to automate frequent tasks\n",
       " Create/oversee the creation of proper documentation related to statistical programs, datasets, review guides and QC documentation, ensure documentations are in compliance with SOPs and/or meeting submission requirements.\n",
       " Review and provide input on documents produced by other biostatistics functions such as: statistical analysis plans; TFL shells; data management plans; data transfer plans and case report forms.\n",
       " Effectively communicate in a team environment, within department and among functional groups\n",
       " Perform other programming duties as assigned\n",
       " ,\n",
       " Requirement:\n",
       " 1. Bachelor degree in Science or Engineering\n",
       " 2. Experienced with computer vision/graphics algorithms\n",
       " 3. Experienced with a deep learning library (Tensorflow/Pytorch/Caffe)\n",
       " 4. Experienced with basic algorithms and data structures, proficient in Python and C++\n",
       " ,\n",
       " requirements and coordinating with groups in and outside of the Transmission and Distribution group. You will be responsible for developing, presenting, and communicating results. You will also be responsible for leading and mentoring other Data Scientists.\n",
       " Typical Responsibilities:\n",
       " Lead data scientists on developing models that meet or exceed business requirements.\n",
       " Generate advanced analytical approaches using predictive modeling, optimization and simulation abilities.\n",
       " Apply statistical and pattern recognition techniques to perform description, prediction, and optimization.\n",
       " Develop and implement tools for data acquisition, extraction, transformation, management, and manipulation of large and complex data sets. Explore, model, mine, and experiment with data to answer critical business issues. And, generate and communicate business insights.\n",
       " Qualifications\n",
       " ,\n",
       " need to have a deep competency and experience with statistics, modeling, and synthesizing and interruption of the data and how to apply them to the real world of customer targeting and optimizing ROI.\n",
       " Primary Responsibilities\n",
       " Take full ownership in developing effective ways to do various analyses like customer modeling, engagement churn analysis and prediction, prediction, and otherwise process large volumes of contact and account data to gain actionable insights and make data-driven decisions.\n",
       " Provide technical guidance to other Data Analysts and ensure the team is progressing as a cohesive unit and producing results. Organizes leads and facilitates cross-functional project teams, and communicate the team’s progress\n",
       " Help multiple audiences – campaign managers, senior marketing managers- dig into and understand the output of the team’s analyses and models using visualization, presentations, etc.\n",
       " Constantly look for and adopt new techniques and tools to ensure the team stays at the forefront of modern large-scale data processing and analysis techniques\n",
       " Work with large data sets and have knowledge of data warehousing systems and marketing automation platforms\n",
       " Job Qualifications\n",
       " Who You Are\n",
       " Analytical and critical thinker with a proven track that you have done analyses and built models to explain and understand the underlying process, variable relationships, causality, etc.\n",
       " A leader who has the capacity to lead others to solve complex problems, use sophisticated analytical thoughts to exercise judgment and identify innovative solutions, and possess the ability to orchestrate value in coordination with multiple stakeholders.\n",
       " A communicator with strong interpersonal skills, ability to work effectively with all levels of the organization.\n",
       " A Self-motivator who is highly organized and able to prioritize and manage multiple projects simultaneously.\n",
       " Possess strong visualization skills using programmatic tools like DOMO or Seaborn\n",
       " Desired Skills and Qualifications\n",
       " You have 5+ years of industry experience in data science or advanced analytics role.\n",
       " BS/BA degree in Engineering in Marketing or equivalent discipline\n",
       " You are proficient in at least one programming language commonly used for data analysis (like R/Python), and SQL\n",
       " You have a wide range of statistical and modeling knowledge and in-depth practical insight to choose the best tools for a given problem. These include linear models for regression and classification, clustering algorithms, and so on.\n",
       " Degree in a quantitative field like statistics, computer science, is preferred\n",
       " Experience with DOMO, Snowflake, and Eloqua is a plus\n",
       " ,\n",
       " requirements, Conduct Advanced Analytics & Validation, Distill Insights, Develop Recommendations, and support business implementation and impact measurement).\n",
       " Identify currently available data sources and how to enrich them; strategize on new potential data sources and determine cost/benefit of acquiring or maintaining data.\n",
       " Build and lead a team of data and business professionals to accelerate insights and impact within the Pro channel.\n",
       " Develop and perpetually maintain Pro business intelligence reporting (e.g., Dashboards, KPIs) to measure pro performance and use reporting to identify opportunities to improve pro performance.\n",
       " Develop compelling presentations and storytelling to present insights, recommendations and strategies.\n",
       " Present and defend analyses to senior management.\n",
       " Assist the SVP, Company Strategy & Pro Strategy Deployment and Analytics with analytics-related projects across Behr Paint Company.\n",
       " Position / Candidate Requirements\n",
       " The successful candidate will need to have the following:\n",
       " Education:\n",
       " • Bachelor's, Master's, or PhD degree from an accredited college/university in a quantitative discipline, such as Computer Science, Engineering, or Mathematics.\n",
       " Work Experience:\n",
       " Minimum of 7 years of experience leading teams of five plus data scientists, engineers, and other data & analytics professionals, including working knowledge of modeling (regression, machine learning, feature selection, dimension reduction, validation), data (extracting, preparing, munging, validating), and building analytics pipelines; Minimum of two years of training and experience specific to machine learning and/or artificial intelligence.\n",
       " Proven experience developing and executing data and analytics strategies, not limited to securing data access, data maintenance, reporting (both ad hoc and perpetually refreshed), etc.\n",
       " Strong knowledge in design and building of machine learning pipelines, including data extraction, feature engineering from structured and unstructured data; Proficiency in delivering analytics projects using leading processes including skilled knowledge of data discovery, cleaning, model selection, validation, and deployment.\n",
       " Broad, versatile knowledge of analytics and data science landscape, combined with a strong business acumen, enabling the identification, design, and deployment of optimal analytics/machine learning solutions to meet the business objectives and the business constraints; Ability to discuss pros and cons of modeling approaches.\n",
       " Proficiency with sophisticated analytics tools and programming languages (SAS, R, Python, Java, Spark, Hadoop, Alteryx, SQL); proficiency with data visualization tools (Tableau, QlikView, Salesforce Einstein, and others).\n",
       " Hardware/ home improvement industry experience a plus.\n",
       " Skills, Knowledge and Abilities:\n",
       " Structured and logical thinking: the ability to dissect a problem into an organized approach and quickly form a hypothesis against which to run test analyses.\n",
       " Analytical rigor: the ability to run highly complicated quantitative and financial analysis in a defect-free manner and to interpret the results and business implications. Comfort with regression analysis and machine learning is highly relevant.\n",
       " Team leadership: Highly developed relationship-building skills to foster effective working relations across the Pro Sales Channel, IT, Sales Operations, Finance, Marketing, and other cross-functional peer relationships across BEHR Paint Company. Proven ability to identify talent, recruit, grow and manage a team of data and analytics professionals.\n",
       " Creative thinking: a combination of out of the box thinking and the ability to question status quo and generally accepted beliefs. Then the ability to apply a strong hypothesis driven approach to validate and/or disprove the thinking using data.\n",
       " Powerful communication: the ability to communicate insights persuasively, both verbally and on paper through the written words and clear graphics (e.g., charts, tables).\n",
       " Emotional intelligence: The candidate must possess strong interpersonal skills and a high level of emotional intelligence to interact with BPC team members at all levels.\n",
       " Considerable knowledge of data and analytics principles, frameworks, and methodologies across a broad range of structured and unstructured data types.\n",
       " Considerable financial and operational modeling capabilities, including regression, machine learning, and artificial intelligence.\n",
       " Deep knowledge of analytics tools and relevant programming languages.\n",
       " Ability to lead teams of data and analytics professionals and ability to collaborate cross-functionally.\n",
       " Knowledge of MS Office Suites and/or software applications related to function (particularly MS PPT, MS Excel, MS Word).\n",
       " Ability to independently scope work using a hypothesis driven approach and validate with leadership.\n",
       " Ability to independently plan, organize and complete projects as assigned.\n",
       " Ability to delegate tasks and check work in progress and upon completion.\n",
       " Ability to communicate effectively in a variety of environments.\n",
       " Ability to inspect products and work results for adherence to quality standards.\n",
       " Occasional travel out of state to attend internal or customer meetings, functions, seminars, etc.\n",
       " Behr Paint Company is an Equal Opportunity Employer with a culture that supports our commitment to diversity and inclusion\n",
       " Company\n",
       " Default Company\n",
       " Full or Part Time\n",
       " Full time\n",
       " Masco Corporation (the “Company”) is an equal opportunity employer and we want to have the best available persons in every job. The Company makes employment decisions only based on merit. It is the Company’s policy to prohibit discrimination in any employment opportunity (including but not limited to recruitment, employment, promotion, salary increases, benefits, termination and all other terms and conditions of employment) based on race, color, sex, sexual orientation, gender, gender identity, gender expression, genetic information, pregnancy, religious creed, national origin, ancestry, age, physical/mental disability, medical condition, marital/domestic partner status, military and veteran status, height, weight or any other such characteristic protected by federal, state or local law. The Company is committed to complying with all applicable laws providing equal employment opportunities. This commitment applies to all persons involved in the operations of the Company regardless of where the employee is located and prohibits unlawful discrimination by any employee of the Company.\n",
       " Masco Corporation is an E-Verify employer. E-Verify is an Internet based system operated by the Department of Homeland Security (DHS) in partnership with the Social Security Administration (SSA) that allows participating employers to electronically verify the employment eligibility of their newly hired employees in the United States. Please click on the following links for more information.\n",
       " E-Verify Participation Poster: English & Spanish\n",
       " ,\n",
       " requirements into custom-formatted data reports. The ideal candidate for this position is able to do complete life cycle data generation and outline critical information. We also need someone who is able to analyze business procedures and recommend specific types of data that can be used to improve upon them.\n",
       " ,\n",
       " Basic Qualifications:\n",
       " Graduate degree in engineering, computer science, or mathematics, and 10+ years of related experience OR a PhD and 5+ years of related work experienceTheoretical knowledge and hands-on experiences in speech recognition, natural language understanding and machine learning.Knowledge in multiple speech and natural language areas.Research track record with peer-reviewed publications in academic conferences and journals in the related areas.\n",
       " ,\n",
       " ideal candidate is someone focused on solving tough problems using data and loves doing so.\n",
       " ,\n",
       " ideal candidate will have in-depth experience with Data Science workflows and built scalable machine learning systems.\n",
       " Build systems and tools that enable data scientists to create machine learning applications using the C3.ai Platform.Enable scalable, end-to-end machine learning pipelines in a distributed system.Work with other platform engineering teams to enable streaming, batch, or ad-hoc data analysis.Collaborate with and support data scientists to understand the utility of the C3.ai Platform and define new requirements.Define and lead the development of longer-term C3.ai Platform capabilities.Mentor junior members of the team.\n",
       " ,\n",
       " requirements and implementation schedules\n",
       " Understanding and articulating customer challenges and participating in the prioritization process of new enhancements and methodologies\n",
       " Helping to build alerts and triggers for future data quality issues to help ensure premium data quality experience for customers\n",
       " Leading all App Annie data quality issues across all datasets including recommendations of best practices\n",
       " Collaboration with the Data Engineering to ensure timely and quality delivery of our data estimates\n",
       " Building the daily quality pipeline, creating reporting to automatically monitor for regressions and coordinate with instrumentation leads to surface and escalate data quality concerns\n",
       " ,\n",
       " requirements to the customer’s business processes. Interact with SME to develop understanding of data sets, analytics requirements, business problems, leadership objectives, external stakeholder objectives, and metrics and produce requirements specifications. Digitize processes and implement tools integrated with data sources. Provide data integration to enable the discovery and monitoring of correlations among disparate data sources and metrics, as well as the identification of causal factors associated with anomalous data observations. Develop and implement predictive algorithms to identify leading indicators. Implement artificial intelligence driven knowledge bases. Provide user training on analytics and reporting.\n",
       " ,\n",
       " ideal candidate should have an MS or PhD in HPC architectures, familiarity with Hardware Data Flow architectures and practical proven experience in building both modern scale-in and scale-out systems (Spark, Hadoop, tensorflow ) with familiarity of both SIMD as wells GP-GPU architectures. The person should also have an interest in the deep learning application space with the ability to map complex deep neural architectures to practical system implementations.\n",
       " ,\n",
       " requirements set by the business are achieved and create effective relationships with entire DIS organization and Diagnostics IT teams (near- and off-shore), Data Management Office, Business Development and Strategy functions, as well as forges an active working relationship with Data Science and Data Engineering groups across Roche group.\n",
       " You further expand the capabilities of the team and develop the team and while maintaining and continuously improving the quality system and achieving quality objectives through daily actions.\n",
       " ,\n",
       " requirements, timelines, objectives, and success criteria.\n",
       " Make conclusions from data. Examine relevant data and quickly develop an analytics plan that will answer key business questions and create value for clients.\n",
       " Analyze data. Work with data sets of varying degrees of size and complexity, including both structured and unstructured data.\n",
       " Present and analyze findings. Transform data into actionable insights and recommendations. Present clear and concise results. This includes processing, cleansing, and verifying the integrity of data used for analysis.\n",
       " Create lasting solutions. Develop analytical solutions by using and applying appropriate methodology – including, but not limited to, regression, forecasting, clustering, decision trees, simulation, optimization, machine learning, and neural networks. Manage Design systems and approaches to operationalize models for machine learning.\n",
       " \n",
       " ,\n",
       " ideal candidate will have passion on utilizing advanced AI technologies to solve real-world problems.\n",
       " \n",
       " ,\n",
       " requirements to improve our reporting suite\n",
       " ,\n",
       " requirements of the position. Having a conviction history will not automatically disqualify an applicant from being considered for employment.\n",
       " Work will be primarily performed at Lawrence Berkeley National Lab, 1 Cyclotron Road, Berkeley, CA.\n",
       " ,\n",
       " ideal candidate is also a natural problem-solver that enjoys working with large data sets and is proactive in exploring database tables and using data to make clear and convincing business cases.\n",
       " ,\n",
       " ideal candidate should be passionate about Wish and e-commerce, has a strong analytical and consultative mindset, deep understanding of databases, visualization, and modeling techniques, and the ability to thrive in a dynamic, fast-paced environment delivering against tight deadlines, and a passion for scaling transaction monitoring through automation.\n",
       " ,\n",
       " requirements and processes\n",
       " Work with data engineers to ensure the availability of accurate and timely data\n",
       " Perform impact assessment and deep-dive analysis in collaboration with stakeholders to ensure data integrity, consistency, usability, and completeness\n",
       " Write SQL for data support for business processes and ETL in Hadoop\n",
       " Identify patterns and trends and communicate them to stakeholders\n",
       " Assess usability of new data sources\n",
       " Apply statistical analysis to quantify impact of business processes.\n",
       " Extract patterns and actionable insights from data.\n",
       " ,\n",
       " requirements incorporating business knowledge and best practices\n",
       " Uses expected qualification and assurance of information to quantify the accuracy of metrics and analysis\n",
       " Works to ensure information is used in compliance with regulatory and security policies\n",
       " Provides on-going tracking and monitoring of performance decision systems and statistical models\n",
       " Qualifications:\n",
       " ,\n",
       " Requirements:\n",
       " 10+ years of software and product development experience, preferably in cloud computing or distributed systems and Big Data technologies such as Spark, Hadoop.\n",
       " 5+ years of experience in a similar role that displays strong leadership competencies and ability to foster technical strategy\n",
       " 3+ years of professional experience using machine learning frameworks such as scikit-learn, SparkML, or Tensorflow, and tools such as notebooks (Jupyter, Zepellin).\n",
       " 10+ years of experience deploying enterprise production systems in one of the following languages (Python, Java, Scala or C++ or GO).\n",
       " Strong Plus with experience with containers and orchestration technologies, such as Docker and Kubernetes.\n",
       " Bachelors in Computer Science or related fields.\n",
       " About Us\n",
       " ,\n",
       " Requirements\n",
       " Strong background in statistical theory and application\n",
       " Experience in data mining, machine learning, time-series analysis, or similar analytical disciplines\n",
       " 2+ years of experience with R and Python (special consideration for experience with pandas, NumPy, and SciPy and machine learning libraries such as scikit-learn, TensorFlow, and PyTorch)\n",
       " Experience with distributed computing, including frameworks such as Spark\n",
       " Excellent written and verbal communication skills\n",
       " Master’s or Ph.D. in geography, statistics, econometrics, computer science or related field, depending on position level\n",
       " Recommended Qualifications\n",
       " Ability to communicate complex concepts effectively, making spatial data science accessible and even fun\n",
       " Working experience in geostatistics, spatial statistics, or other statistical fields involving autocorrelated datasets\n",
       " Passion for storytelling using data visualization\n",
       " Familiarity with Esri GIS products\n",
       " Knowledge of or experience developing models or scripts in ArcGIS\n",
       " About Esri\n",
       " Our passion for improving quality of life through geography is at the heart of everything we do. Esri’s geographic information system (GIS) technology inspires and enables governments, universities, and businesses worldwide to save money, lives, and our environment through a deeper understanding of the changing world around them.\n",
       " ,\n",
       " requirements for data sciences research from LLNL programs and external government sponsors.Carry out development of data analysis algorithms to address program and sponsor data sciences requirements.Engage other developers frequently to share relevant knowledge, opinions, and recommendations, working to fulfill deliverables as a team.Design technical solutions independently, participate as a member of a multidisciplinary team to analyze sponsor requirements and designs, and implement software and perform analyses to address these requirements.Develop and integrate components-such as web-based user interfaces, access control mechanisms, and commercial indexing products-for creating an operational information and knowledge discovery system.Perform other duties as assigned.\n",
       " In Addition at the SES.3 Level\n",
       " Lead multiple parallel tasks and priorities of customers and partners to ensure complex deadlines are met.Responsible for various complex projects, use team members’ skills to complete complex projects/tasks, and solve abstract complex problems/ideas and convert them into useable algorithms/software modules.Provide solutions that require in-depth analysis of multiple factors and the creative use of established methods.\n",
       " ,\n",
       " ideal candidate will be a goal driven problem solver having a mastery of\n",
       " statistical, mathematical, and programming tools and techniques and experience\n",
       " in digital analytics who can work equally well independently and in\n",
       " collaboration with a team.\n",
       " Active participation in a range of market strategy projects essential to KP's membership and margin goals. Market Strategy&Analysis Consultants provide analytical/strategic-thinking and leadership skills that enable project teams to: 1) isolate business issues; 2) design and execute analytics for studying business issues (market research, scenario planning, forecasting, market share, profitability, etc); 3) bring technical/content expertise (competitive intelligence, utilization, financial analysis, deep data analysis & programming); 4) vet findings and make formal recommendations to senior levels of KP leadership; 5) create documents (strategic segment plans, utilization reports) that inform critical strategic issues.\n",
       " \n",
       " ,\n",
       " requirements, propose AI software solutions to meet the business requirements, deliver and present AI software to clients\n",
       " Understand the data set used for the modeling, prepare and preprocess data sets, train and test models and perform model feature engineering\n",
       " Document data dictionary, data understanding, modeling strategy and approaches, and build company’s knowledge base of data and models\n",
       " Communicate effectively with team members, management, and clients\n",
       " Requirements\n",
       " Proven ability to work with large structured and unstructured datasets\n",
       " Demonstrable, hands-on experience in developing advanced analytics algorithms/models, including time series forecasting, machine learning and deep learning, image processing, natural language processing, and speech recognition\n",
       " Excellent hands-on code development skills in Python\n",
       " Good Knowledge of Machine Learning frameworks and packages, including Keras, TensorFlow, MXnet, Scikit-Learn and cloud technology (Amazon, Azure, etc.)\n",
       " Experiences in Machine Learning, Deep Learning, Computer Vision, and Natural Language Processing\n",
       " PhD degree in Mathematics, Statistics, Computer Science, or related disciplines\n",
       " At least 3 years of Artificial Intelligence\n",
       " At least 3 years of Machine Learning\n",
       " Background in Property and Casulity Insurance a big plus!\n",
       " You must be able to work out of our Houston office\n",
       " Additional Qualifications\n",
       " Parallel and distributed processing experience is a plus\n",
       " Expertise in data Extraction Transformation and Loading (ETL) is a strong plus (Spark, Hadoop, SQL) in big data environments.\n",
       " Domain knowledge in financial and insurance industries is a big plus\n",
       " The candidate must be able to work out of the Houston Texas office but remote work will be considered for extremely strong candidate\n",
       " Relocation reimbursement is available for the right candidate\n",
       " ,\n",
       " ideal candidate is an experienced ML technology scientist who has a track-record of performing analysis and applying statistical techniques to solve real business problems. They will have great leadership and communication skills, and are motivated to achieve results in a fast-paced environment. The position offers an exceptional opportunity to grow your technical and non-technical skills and make a real difference to Alexa customers.\n",
       " ,\n",
       " Requirements:\n",
       " A degree in Computer Science or a similarly technical field of study or equivalent practical experience.\n",
       " Expertise in applied machine learning\n",
       " Strong technical knowledge of classical machine learning approaches as well as novel Deep Learning methods\n",
       " Coding experience\n",
       " Ability to work and thrive in a diverse cross-disciplinary team that includes software engineers with different backgrounds, physicians, and UX researchers\n",
       " Nice-To-Haves:\n",
       " Expertise with healthcare data\n",
       " Masters or PhD in CS with a focus in AI/ML\n",
       " Publications in the AI/ML field\n",
       " Coding experience in production-grade systems\n",
       " Experience with Tensorflow/Pytorch and other Deep Learning frameworks\n",
       " Python/C++ experience\n",
       " More about Curai:\n",
       " ,\n",
       " nice to have. They must have machine learning experience and general service oriented architecture. Previous experience in SEM nice to have but not required.\n",
       " ,\n",
       " requirements and develop software for running ML solutions on Saildrones in the field as well as in the cloud\n",
       " ,\n",
       " ideal candidate is adept at using large data sets to find opportunities for product and process optimization and can use models to test the effectiveness of different courses of action. Other responsibilities will include (but are not limited to) data visualization, data- driven problem solving, They have a passion for discovering solutions hidden in data sets and can brainstorm ways to improve business outcomes/determine future project focus. They must also have experience and interest in content analysis.\n",
       " ,\n",
       " requirements, functional design, process design (including scenario design, flow mapping), prototyping, testing, training, defining support procedures.\n",
       " Formulate planning, budgeting, forecasting and reporting strategies.\n",
       " Manage full life cycle implementations.\n",
       " Develop statements of work and/or client proposals.\n",
       " Identify business opportunities to increase usability and profitability of information architecture.\n",
       " Experience with program leadership, governance and change enablement.\n",
       " Develop and manage vendor relationships.\n",
       " Lead workshops for client education.\n",
       " Manage resources and budget on client projects.\n",
       " Assist and drive the team by providing oversight.\n",
       " ,\n",
       " ideal candidate has experience working with large scale data sets and driving projects from conception to completion. Additionally they are able to take models or analysis one step farther and use data to tell stories and create understanding both within the analytics team and across the entire company. If doing a deep dive into the latest cutting edge literature on neural networks or probabilistic programming in the morning and working with game designers or engineers to turn findings into product in the afternoon sounds fun then you’ll fit right in at Jam City.\n",
       " RESPONSIBILITIES:\n",
       " Use your knowledge of data cleaning, statistical analysis and visualization to turn numbers into results that make Jam City’s games better.\n",
       " Collaborate with stakeholders ranging from marketers to product managers and artists to make sure that data informs decisions at all levels of Jam City.\n",
       " Work on a mixture of short term tactical analysis that deals with immediate needs and long term strategic projects that drive major change within the company.\n",
       " Create data visualizations and analysis pipelines that turn complicated problems into simple solutions for stakeholders.\n",
       " Experiment with cutting edge techniques to help drive the next generation of analytics at Jam City.\n",
       " QUALIFICATIONS:\n",
       " An advanced or postgraduate degree in a quantitative field.\n",
       " The ability to use SQL or a scripting language such as Python or Scala to generate, clean and explore complex datasets.\n",
       " A demonstrated track record of using statistical languages/packages such as R or Python to build features, create models and explore datasets.\n",
       " Experience presenting and describing complex datasets or statistical processes to audiences without a technical background.\n",
       " The ability to learn and use skills that you already have to tackle new problems in a creative way.\n",
       " NICE TO HAVE:\n",
       " Evidence of presentations/publications demonstrating the ability to drive research projects from start to finish.\n",
       " Experience with neural network frameworks such as Tensorflow/Torch.\n",
       " Knowledge of Apache Spark and associated products.\n",
       " Or some other unique skill that you can teach the team to help us level up our analytical capabilities!\n",
       " ABOUT JAM CITY\n",
       " Jam City is an award-winning mobile entertainment studio providing unique and deeply engaging games that appeal to a broad, global audience.\n",
       " ,\n",
       " ideal candidate will have previous experience leading a team of data analysts perfecting machine learning products, and a passion for building agile, high-performing teams.\n",
       " Responsibilities:\n",
       " Define methodology, tooling and framework to triage petabyte-scale ML data in partnership with other data science, engineering, business and product team leaders\n",
       " Define tools and technologies to be used by triage analysts in the ongoing evaluation of performance of the ML product in the store environment\n",
       " Manage work of triage analysts based on data and insights from performance analytics and ML teams\n",
       " Create analysis and derive insights to inform and guide leadership decision-making and strategic business and product development\n",
       " Recruit, develop and mentor a team of ML data analysts in a fast-moving and quickly growing organization\n",
       " ,\n",
       " Requirements include but are not limited to\n",
       " \n",
       " ,\n",
       " requirements\n",
       " Be aware of trends in the software industry and identify technologies that are applicable\n",
       " Develop highly scalable classifiers and tools leveraging machine learning, data regression, and rules based models\n",
       " Suggest, collect and synthesize requirements and create effective feature roadmap\n",
       " Code deliverables in tandem with the engineering team\n",
       " Adapt standard machine learning methods to best exploit modern parallel environments (e.g. distributed clusters, multicore SMP, and GPU)\n",
       " Be the entrepreneur and evangelist behind the ML for Operations initiative.\n",
       " Build and lead a world-class team of SW engineers capable of scaling for Bluescape through a period of continued high-growth while forging tight partnerships with managers and engineers across infrastructure.\n",
       " Demonstrate an ability to structure an organization and optimize it for execution, including attracting top tier talent and filing out gaps in the existing team quickly to accommodate growth.\n",
       " Able to lead from the front, prioritize, and drive the bigger mission forward by translating vision into results.\n",
       " Manage, mentor and grow SW engineering teams, able to manage as well as performance manage those who need more help.\n",
       " Measure and improve efficiency and effectiveness of processes that are working well and build the next level of improvements, set standards for SW development, prototyping, deployments at scale, infrastructure reliability, and scalability.\n",
       " Partner with relevant technical functions across the company to ensure all partnering teams are in sync.\n",
       " Continue to improve the thriving engineering culture across all tech functions.\n",
       " Build and lead an organization with customer focus, world-class quality, and effective communication with a focus on decisive, fast-moving solutions, quick and constructive resolutions to conflicts, and a \"no barriers\" mentality.\n",
       " Serve as an evangelist for the team and overall culture, both internally and externally.\n",
       " ,\n",
       " Requirements include but are not limited to\n",
       " ,\n",
       " requirements, define project OKRs and milestones, and communicate progress and results to a non-technical audience.\n",
       " Mentor and guide data-scientists on the team by helping with project planning, technical decisions, and code and document review.\n",
       " Build self-serving internal data products to make data simple within the company.\n",
       " Competencies\n",
       " Experience in applying Data Science / ML in production to build data-driven products for solving business problems.\n",
       " Familiarity with Product Analytics - understanding and tracking customer and user behaviour using lenses like adoption, churn, cohorts and funnel analysis.\n",
       " Experience collaborating with and understanding the needs of stakeholders from a variety of business functions. We work most closely with Product, Customer Success and Engineering at the moment, but also work with the Sales, Marketing and Finance organizations.\n",
       " Strong coding skills in general purpose languages like Scala or Python, and familiarity with software engineering principles around testing, code reviews and deployment.\n",
       " Proficient in data analysis and visualization using tools like R and Python.\n",
       " Experience with distributed data processing systems like Spark and Hadoop, and proficiency in SQL.\n",
       " BS/MS/PhD in Computer Science, or a related field\n",
       " Benefits\n",
       " Comprehensive health coverage including medical, dental, and vision\n",
       " 401(k) Plan\n",
       " Equity awards\n",
       " ,\n",
       " requirements for this roleMeets/exceeds Amazon’s functional/technical depth and complexity for this role\n",
       " Lab126 is part of the Amazon.com, Inc. group of companies and is an Equal Opportunity Employer – Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age.\n",
       " ,\n",
       " requirements of the department. Produce ad hoc reports as necessary in response to requests by senior management, the Board of Directors and as required by the Department of Health Care Services (DHCS). Provide data analysis and reporting as required in support of major CalOptima initiatives.\n",
       " \n",
       " ,\n",
       " ideal candidate is also a natural problem-solver that enjoys working with large data sets, is proactive in exploring database tables and using data to make clear and convincing business cases.\n",
       " ,\n",
       " ideal candidate demonstrates success in developing integrated machine learning solutions consisting of ISV products and SI services and bringing them to market. She/he should turn customer feedback and an understanding of IT industry trends to compelling value propositions and enable the AWS and partner field to communicate them effectively to their customers. The position also requires a strong technical understanding of machine learning technologies and solutions.\n",
       " ,\n",
       " ideal candidate will have a strong background working with data, experience applying machine learning and deep learning techniques to real-world problems, and a natural curiosity and desire to experiment, evaluate and solve problems as part of a fast-paced and growing, product-driven technology team.\n",
       " ,\n",
       " requirements.Identify and define complex problems stemming from programmatic research, propose methodologies, collect and analyze data, and document results.Adapt and apply existing statistical methods and theories to new problem domains.Identify, acquire, and maintain expertise in new subjects when necessary.Develop and maintain collaborations with researchers and/or stakeholders.Perform other duties as assigned.\n",
       " ,\n",
       " requirements.\n",
       " Education and experience\n",
       " 5 years of experience and a BS degree in Biostatistics/Computer Science or equivalent.\n",
       " 1 year of experience and a MS degree in Biostatistics/Computer Science or equivalent.\n",
       " PhD degree in Biostatistics/Computer Sciences or equivalent.\n",
       " ,\n",
       " Requirements:\n",
       " Degree in computer science, or related field\n",
       " Experience using computer vision, deep learning and deep reinforcement Learning, or natural language processing in a production environment\n",
       " Solid background in algorithms, data structures, and object-oriented programming\n",
       " Strong programing skills in Python or Javascript, experience in Tensorflow or PyTorch Nice to Haves:\n",
       " Graduate degree in Computer Science, Machine Learning or Artificial Intelligence specialization\n",
       " Experience working with cloud technology stack (eg. AWS or GCP) and developing machine learning models in a cloud environment\n",
       " ,\n",
       " ideal candidate has:\n",
       " 5+ years of machine learning management experience\n",
       " Passion for making a positive impact on the lives of millions of people\n",
       " Experience in web-scale/consumer-facing organizations\n",
       " Broad knowledge of machine learning approaches in general (expertise in NLP, Deep Learning, of the medical domain will be valued, but are not strictly necessary)\n",
       " Ability to work and thrive in a fast-paced, diverse and cross-disciplinary work environment that includes engineers with different backgrounds, physicians, and UX researchers\n",
       " ,\n",
       " requirements.\n",
       " Responsibilities\n",
       " Assemble large, complex data sets that meet functional / non-functional business requirements.\n",
       " Build tools, frameworks, infrastructure, and services to ensure high quality and availability of data for AI/machine learning purposes.\n",
       " Identify, design, and implement internal process improvements; automating manual processes, optimizing data delivery, standardizing and re-designing infrastructure for greater scalability.\n",
       " Develop, design, document, test, implement and manage clinical data collections and reporting systems that optimize statistical efficiency and data quality.\n",
       " Interpret data, analyze results using statistical techniques and provide clinical reports\n",
       " Create and write SQL code for reporting database based on customer and internal report specifications.\n",
       " Perform Oracle database maintenance and install patches and provide Oracle support with internal and external use of the Oracle database\n",
       " Troubleshoot data and data feed problems related to Oracle and other SQL driven applications\n",
       " Requirements\n",
       " Bachelor’s degree in Computer Science or related field, an additional 4 years of related experience in lieu of degree\n",
       " 1-3 years database experience with solid understanding of SQL query development\n",
       " Experience with UNIX and PC-based information systems, windows servers and workstations, network interfaces and modern office methods.\n",
       " Strong knowledge of SQL and databases (Oracle, MySQL, SQLite, PostgreSQL).\n",
       " Proficient with scripting (Bash, Perl, Python, etc.) and proficiency with MS Office Applications\n",
       " ,\n",
       " ideal candidate is a responsible, dedicated, and career-minded professional interested in growth opportunities. So if you’ve got the talent and if you are looking to start your career with a company with great culture who truly values their employees, empowers individual growth and would love to have a healthy work/life balance, we’d love to hear from you.\n",
       " ,\n",
       " Requirements\n",
       " Minimum Qualifications\n",
       " ,\n",
       " requirements necessary for AI/ML Engineer\n",
       " Familiarity/Experience with full ML/AI development life-cycle (e.g. data management, data curation, data pipelines, model development, model deployment, model auditing)\n",
       " Five or more years of progressively responsible experience in relevant Artificial Intelligence/ Machine learning or Data Science roles\n",
       " Expertise in Python, CUDA, and/or C++ programming languages\n",
       " Strong experience working with Unix/Linux operating systems\n",
       " This position requires the ability to obtain and maintain a Secret security clearance, which is issued by the U.S. government. U.S. citizenship is required to obtain a security clearance.\n",
       " ,\n",
       " requirement and propose solutions and lead them to completion.\n",
       " ]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "requirements of the role and your motivation behind applying.\n"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reqs[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "requirements_extractor(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = vacancy_dict['Data Scientist'][30]\n",
    "doc = nlp(s)\n",
    "# doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "pattern = [\n",
    "    {'LEMMA':'requirement'},\n",
    "    {'LEMMA':'skills'},\n",
    "    {'LEMMA':'experience'},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in pdict.values():\n",
    "    matcher.add('REQ_PATTERN', None, el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc[502:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accountabilities 600\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for el in doc[502:]:\n",
    "    if len(el.text.split(\"\\n\")) > 2 and (el.i) < len(doc):\n",
    "        print(doc[el.i+1], el.i+1)\n",
    "        c = el.i + 1\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Requirements:\n",
       "A Finance/Economics/Business/Mathematics graduate\n",
       "A demonstrated interest and knowledge in the financial markets\n",
       "A proven record of outstanding achievement in academic and extracurricular activities\n",
       "An independent thinker and decision maker who is able to contribute effectively to the team's success\n",
       "Superior interpersonal and analytical skills\n",
       "Ability to meet the challenges presented by a stressful, constantly changing work environment.\n",
       "Ideally available to start asap – individual will be expected to go to Toronto for training 13th August for 2 wks.\n",
       "\n",
       "\n",
       "\n",
       "\n"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[matches[0][1]:c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "for el in pdict.values():\n",
    "    matcher.add('REQ_PATTERN', None, el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def requirements_extractor(doc, matcher=matcher):\n",
    "    endpos = None\n",
    "    matches = matcher(doc)\n",
    "        \n",
    "    if len(matches) > 0 :\n",
    "        startpos = matches[0][1]\n",
    "        for el in doc[startpos:]:\n",
    "            if len(el.text.split(\"\\n\")) > 2 and (el.i) < len(doc):\n",
    "#                 print(doc[el.i+1], el.i+1)\n",
    "                endpos = el.i + 1\n",
    "                break\n",
    "    if endpos:\n",
    "        return doc[startpos:endpos]\n",
    "    else:\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2202e7e2859e4b42937956bdd71e7355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1833.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "[E155] The pipeline needs to include a tagger in order to use Matcher or PhraseMatcher with the attributes POS, TAG, or LEMMA. Try using nlp() instead of nlp.make_doc() or list(nlp.pipe()) instead of list(nlp.tokenizer.pipe()).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-0ae712be9426>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvacs_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequirements_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-98-0a6edfc38e43>\u001b[0m in \u001b[0;36mrequirements_extractor\u001b[0;34m(doc, matcher)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrequirements_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatcher\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmatcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mendpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatches\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmatcher.pyx\u001b[0m in \u001b[0;36mspacy.matcher.matcher.Matcher.__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: [E155] The pipeline needs to include a tagger in order to use Matcher or PhraseMatcher with the attributes POS, TAG, or LEMMA. Try using nlp() instead of nlp.make_doc() or list(nlp.pipe()) instead of list(nlp.tokenizer.pipe())."
     ]
    }
   ],
   "source": [
    "reqs = []\n",
    "for s in tqdm.notebook.tqdm(vacs_desc):\n",
    "    doc = nlp(s)\n",
    "    res = requirements_extractor(doc)\n",
    "    if res:\n",
    "        if len(res) > 4:\n",
    "#             print(\"_\"*10)\n",
    "#             print(res)\n",
    "#             print(len(res))\n",
    "            reqs.append(res)\n",
    "print(f\"Удалось извлечь потенциальных скилов {len(reqs)} шт.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "bv = vacs_dict['Agile coach'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "docbv = nlp(bv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Global Markets (Credit Products), High Yield Sector Strategist, VP, London, #152732\n",
       "United Kingdom-London-London | Full-time (FT) | Global Markets | Job ID 152732\n",
       "Credit Suisse is a leading global wealth manager with strong investment banking capabilities. Headquartered in Zurich, Switzerland, we have a global reach with operations in about 50 countries and employ more than 45,000 people from over 150 different nations. Embodying entrepreneurial spirit, Credit Suisse delivers holistic financial solutions to our clients, including innovative products and specially tailored advice. Striving for quality and excellence in our work, we recognize and reward extraordinary performance among our employees, provide wide-ranging training and development opportunities, and benefit from a diverse range of perspectives to create value for our clients, shareholders and communities. We are Credit Suisse.\n",
       "We Offer\n",
       "\n",
       "The Credit Suisse leverage finance trading desk is looking for a desk analyst at the VP/Director level. The desk is a leading market maker with a top 3 position across European High Yield and CDS. The desk sits on the fixed income floor and is part of Global Markets.\n",
       "\n",
       "\n",
       "The desk analyst role involves:\n",
       "Expressing credit views on HY issuers based on fundamental credit analysis.\n",
       "Provide executable trade ideas base on a deep understanding of industry trends, capital structure, relative value and event driven catalysts across cash and CDS.\n",
       "In addition, you will be monitoring news flow; share trade ideas and company specific commentaries and closely engage with trading, our institutional client base and assist our cap markets on primary market activity.\n",
       "The overall objective is to formulate and update investment recommendations both to the traders and the desk’s clients (including mutual funds, pension funds and hedge funds).\n",
       "We are opportunistic regarding sector focus. This gives our analysts a broader perspective on companies and allows them to select which companies they focus on.\n",
       "We work across Credit Default Swaps (CDS), Secured or Unsecured bonds, loans or PIK (paid in Kind) debt.\n",
       "The role is not a Mifid II publishing research role since desk analysts are not considered independent, given they work closely with the traders\n",
       "You Offer\n",
       "\n",
       "Requirements:\n",
       "\n",
       "\n",
       "Deep understanding of financial statement analysis, financial modelling, corporate finance and accounting.\n",
       "Familiarity with European HY bond structure and legal documentation.\n",
       "Excellent communication skills and attention to detail.\n",
       "Ability to assess risk/reward trade off and formulate executable trade ideas.\n",
       "Ability to carry out complex analysis in a fast paced environment.\n",
       "\n",
       "This role will require ongoing certification under the Certification Regime.\n",
       "\n",
       "Credit Suisse is an equal opportunity employer. Welcoming diversity gives us a competitive advantage in the global marketplace and drives our success."
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docbv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
